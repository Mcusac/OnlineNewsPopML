{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d1618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Classes and Functions\n",
    "\n",
    "# # Custom Logistic Regression\n",
    "# class LogisticRegressionModel:\n",
    "#     def __init__(self, C=0.05, penalty='l1', solver='saga'):\n",
    "#         self.model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=10000)\n",
    "\n",
    "#     def train(self, X, y, epochs=1000):\n",
    "#         self.model.fit(X, y)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         return self.model.predict(X)\n",
    "\n",
    "#     def score(self, X, y):\n",
    "#         # Calculate the accuracy of the model on the given data set.\n",
    "#         accuracy = np.mean(self.predict(X) == y)\n",
    "\n",
    "#         return accuracy\n",
    "\n",
    "# # Custom Support Vector Machine\n",
    "# class SupportVectorMachineModel:\n",
    "#     def __init__(self, C=1.0):\n",
    "#         self.model = SVC(C=C, kernel='linear')\n",
    "\n",
    "#     def train(self, X_train, y_train):\n",
    "#         self.model.fit(X_train, y_train)\n",
    "\n",
    "#     def predict(self, X_test):\n",
    "#         return self.model.predict(X_test)\n",
    "\n",
    "# # Custom Evaluation model\n",
    "# def evaluate_model(model, X_test, y_test):\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     accuracy = np.mean(y_pred == y_test)\n",
    "#     precision = np.mean(y_pred[y_test == 1] == 1)\n",
    "#     recall = np.mean(y_pred == y_test) if np.sum(y_test == 1) > 0 else 0\n",
    "#     # F1 score: A harmonic mean of precision and recall.\n",
    "#     f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "#     return accuracy, precision, recall, f1_score\n",
    "\n",
    "# # Custom Stochastic Gradient Descent\n",
    "# class StochasticGradientDescent:\n",
    "#     def __init__(self, learning_rate=0.01):\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.weights = None\n",
    "        \n",
    "#     # Initialize the model parameters to random values.\n",
    "#     def train(self, X, y, epochs=1000):\n",
    "#         # Initialize the weights\n",
    "#         self.weights = np.random.randn(X.shape[1])\n",
    "\n",
    "#         # Iterate over the training data in batches\n",
    "#         for epoch in range(epochs):\n",
    "#             for i in range(X.shape[0]):\n",
    "#                 # Get a batch of data\n",
    "#                 x_batch = X[i:i + 1, :]\n",
    "#                 y_batch = y[i:i + 1]\n",
    "\n",
    "#                 # Compute the predictions\n",
    "#                 y_pred = self.predict(x_batch)\n",
    "\n",
    "#                 # Compute the gradients of the loss function with respect to the model parameters\n",
    "#                 gradients = np.dot(x_batch.T, y_pred - y_batch)\n",
    "\n",
    "#                 # Update the model parameters using the gradients and a learning rate\n",
    "#                 self.weights -= self.learning_rate * gradients\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         # Compute the predictions\n",
    "#         y_pred = 1 / (1 + np.exp(-np.dot(X, self.weights)))\n",
    "\n",
    "#         return y_pred\n",
    "    \n",
    "#     def compute_gradients(self, X_train, y_train):\n",
    "#         # Compute the predictions\n",
    "#         y_pred = self.predict(X_train)\n",
    "\n",
    "#         # Compute the gradients of the loss function with respect to the model parameters\n",
    "#         gradients = np.dot(X_train.T, y_pred - y_train)\n",
    "\n",
    "#         return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f4a6b",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed2738",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# file path\n",
    "filepath = \"../1 - Visualization and Data Preprocessing/Data/ONPClean2.csv\"\n",
    "# Load the dataset\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a27abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop certain columns\n",
    "df1 = df.drop('url_name', axis=1) # was a string\n",
    "df1 = df1.drop('date', axis=1) # datetime change didnt even work.\n",
    "df1 = df1.drop('day_of_week', axis=1) # other categorical variable\n",
    "df1 = df1.drop('news_category', axis=1) # other categorical variable\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the `shares` column\n",
    "df1['shares'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column called `share_ranges` with categorical levels\n",
    "df1['share_ranges'] = pd.cut(df1['shares'], bins=[0, 2500, 5000, 7500, 10000, 20000, 100000, 1000000], labels=['<2500', '>2500 & <5000', '>5000 & <7500', '>7500 & <10000', '>10000 & <20000', '>20000 & <100000', '>100000'])\n",
    "\n",
    "# Print the DataFrame\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f3be3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572a458",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Describe the `shares` column\n",
    "# df1['share_ranges'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f849b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20bc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 80% training and 20% testing sets.\n",
    "X = df1.drop('share_ranges', axis=1)\n",
    "y = df1['share_ranges']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Scale the features in the training and testing sets.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa24e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaNs in the dataset\n",
    "for column in df1.columns:\n",
    "    if df1[column].isnull().any():\n",
    "        print('NaNs found in column:', column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c7dc8",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the logistic regression model\n",
    "# logistic_regression_model = LogisticRegressionModel()\n",
    "\n",
    "# # Train the logistic regression model on the training set.\n",
    "# logistic_regression_model.train(X_train, y_train)\n",
    "\n",
    "# # Calculate the cross-validated accuracy of the model.\n",
    "# logistic_regression_cross_validated_accuracy = cross_val_score(logistic_regression_model, X_train, y_train, cv=5)\n",
    "\n",
    "# # Print the cross-validated accuracy of the model.\n",
    "# print('Logistic regression cross-validated accuracy:', logistic_regression_cross_validated_accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cccd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model parameters.\n",
    "C = 0.05\n",
    "penalty = 'l1'\n",
    "solver = 'saga'\n",
    "max_iter=10000\n",
    "\n",
    "# Create a logistic regression model.\n",
    "logistic_regression_model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=max_iter)\n",
    "\n",
    "# Fit the model to the training data.\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data.\n",
    "y_pred = logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a6c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do cross validation\n",
    "# logistic_regression_cross_validated_accuracy = cross_val_score(logistic_regression_model, X_train, y_train, cv=5)\n",
    "\n",
    "# # Check accuracy from cross validation\n",
    "# print('Logistic regression cross-validated accuracy:', logistic_regression_cross_validated_accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ab076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the cross-validated accuracy.\n",
    "# plt.plot(logistic_regression_cross_validated_accuracy)\n",
    "\n",
    "# # Fit a line to the cross-validated accuracy.\n",
    "# # line, axes = plt.plot(logistic_regression_cross_validated_accuracy, 'r-')\n",
    "\n",
    "# # Set the title and labels of the plot.\n",
    "# plt.title('Logistic Regression Cross-Validated Accuracy')\n",
    "# plt.xlabel('Cross-Validation Chunk')\n",
    "# plt.ylabel('Accuracy')\n",
    "\n",
    "# # Add a label to the fit line.\n",
    "# # line.set_label('C=0.05, penalty=\\'l1\\', solver=\\'saga\\'')\n",
    "\n",
    "# # Show the plot.\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ab0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data.\n",
    "logistic_regression_accuracy = accuracy_score(y_test, y_pred)\n",
    "logistic_regression_precision = precision_score(y_test, y_pred, average='macro')\n",
    "logistic_regression_recall = recall_score(y_test, y_pred, average='macro')\n",
    "logistic_regression_f1_score = f1_score(y_test, y_pred, average='macro')\n",
    "# logistic_regression_roc_auc_score = roc_curve(y_test, y_pred[:, 1])\n",
    "\n",
    "\n",
    "# Print the metrics.\n",
    "print('Logistic regression accuracy:', logistic_regression_accuracy)\n",
    "print('Logistic regression precision:', logistic_regression_precision)\n",
    "print('Logistic regression recall:', logistic_regression_recall)\n",
    "print('Logistic regression F1 score:', logistic_regression_f1_score)\n",
    "# print('Logisticregression ROC AUC score:', logistic_regression_roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a364d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the y_pred array to a 2-dimensional array.\n",
    "# y_pred_2d = y_pred[:, 2]\n",
    "\n",
    "# # Calculate the ROC curve.\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_2d)\n",
    "\n",
    "# # Plot the ROC curve.\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f812dd",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41b5f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the support vector machine model\n",
    "support_vector_machine_model = SVC()\n",
    "\n",
    "# Train the support vector machine model on the training set using a linear kernel.\n",
    "support_vector_machine_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data.\n",
    "y_pred = support_vector_machine_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do cross validation\n",
    "# support_vector_machine_cross_validated_accuracy = cross_val_score(support_vector_machine_model, X_train, y_train, cv=5)\n",
    "\n",
    "# # Check accuracy from cross validation\n",
    "# print('SVM cross-validated accuracy:', support_vector_machine_cross_validated_accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the cross-validated accuracy.\n",
    "# plt.plot(support_vector_machine_cross_validated_accuracy)\n",
    "\n",
    "# # Fit a line to the cross-validated accuracy.\n",
    "# # line, axes = plt.plot(logistic_regression_cross_validated_accuracy, 'r-')\n",
    "\n",
    "# # Set the title and labels of the plot.\n",
    "# plt.title('SVM Cross-Validated Accuracy')\n",
    "# plt.xlabel('Cross-Validation Chunk')\n",
    "# plt.ylabel('Accuracy')\n",
    "\n",
    "# # Add a label to the fit line.\n",
    "# # line.set_label('C=0.05, penalty=\\'l1\\', solver=\\'saga\\'')\n",
    "\n",
    "# # Show the plot.\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed21317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data.\n",
    "support_vector_machine_accuracy = accuracy_score(y_test, y_pred)\n",
    "support_vector_machine_precision = precision_score(y_test, y_pred, average='macro')\n",
    "support_vector_machine_recall = recall_score(y_test, y_pred, average='macro')\n",
    "support_vector_machine_f1_score = f1_score(y_test, y_pred, average='macro')\n",
    "# support_vector_machine_roc_auc_score = roc_auc_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the metrics.\n",
    "print('Support vector machine accuracy:', support_vector_machine_accuracy)\n",
    "print('Support vector machine precision:', support_vector_machine_precision)\n",
    "print('Support vector machine recall:', support_vector_machine_recall)\n",
    "print('Support vector machine F1 score:', support_vector_machine_f1_score)\n",
    "# print('Support vector machine ROC AUC score:', support_vector_machine_roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b512496",
   "metadata": {},
   "source": [
    "### Adjusting parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084ecbb",
   "metadata": {},
   "source": [
    "To adjust the parameters of the logistic regression and support vector machine models, I would use a grid search approach. This involves training the models with a range of different parameter values and evaluating their performance on the testing set. \n",
    "The parameter values that produce the best performance on the testing set would then be selected as the final parameters for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843f833",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47452dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the logistic regression model\n",
    "# SGD = StochasticGradientDescent()\n",
    "\n",
    "# # Train the model\n",
    "# SGD.train(X, y)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = SGD.predict(X)\n",
    "\n",
    "# # Print the predictions\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "regularize_const = 0.1\n",
    "iterations = 5\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
    "        loss='hinge', n_iter_no_change=iterations, n_jobs=-1, penalty='l2')\n",
    "\n",
    "scl = StandardScaler()\n",
    "for train_idx, test_idx in cv.split(X,y):\n",
    "    svm_sgd.fit(scl.fit_transform(X[train_idx]),y[train_idx])\n",
    "    yhat = svm_sgd.predict(scl.transform(X[test_idx]))\n",
    "\n",
    "    conf = mt.confusion_matrix(y[test_idx],yhat)\n",
    "    acc = mt.accuracy_score(y[test_idx],yhat)\n",
    "\n",
    "print('SVM:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da5c70",
   "metadata": {},
   "source": [
    "### Evaluating model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88fa313",
   "metadata": {},
   "source": [
    "##### Accuracy: The proportion of predictions that are correct.\n",
    "\n",
    "##### Precision: The proportion of positive predictions that are correct.\n",
    "\n",
    "##### Recall: The proportion of positive examples that are correctly identified.\n",
    "\n",
    "##### ROC:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ce628",
   "metadata": {},
   "source": [
    "#### Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4998ab53",
   "metadata": {},
   "source": [
    "The Logistic Regression model takes longer to train than the SVM model\n",
    "Logistic Regression showed better numbers across each of the metrics recorded. In some cases this difference is very small.\n",
    "Accuracy was beter by ~0.02, precision by ~0.03, recall by ~0.001, and an F1 score difference of ~0.015."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86b875",
   "metadata": {},
   "source": [
    "#### Use the weights from logistic regression to interpret the importance of different\n",
    "features for each classification task. Explain your interpretation in detail. Why do you think\n",
    "some variables are more important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80203425",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "559540e4",
   "metadata": {},
   "source": [
    "#### Look at the chosen support vectors for the classification task. Do these provide\n",
    "any insight into the data? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec81a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf7aa1a8",
   "metadata": {},
   "source": [
    "##### From Google Bard:\n",
    "\n",
    "Which model to use?\n",
    "\n",
    "The best model to use for a particular classification task will depend on the specific characteristics of the data. Logistic regression is a good choice for tasks where the data is linearly separable and the dataset size is not too large. Support vector machines are a good choice for tasks where the data is not linearly separable, the dataset size is large, or there are outliers in the data.\n",
    "\n",
    "It is also important to note that support vector machines can be more computationally expensive to train than logistic regression models.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "To create a logistic regression model and a support vector machine model for the classification task involved with my dataset, I would follow the steps outlined above. I would then adjust the parameters of the models to improve their performance and evaluate their performance on the testing set. The model with the best performance on the testing set would then be selected as the final model.\n",
    "#####################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
