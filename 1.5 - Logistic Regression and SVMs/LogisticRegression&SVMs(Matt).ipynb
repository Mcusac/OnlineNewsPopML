{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "813cff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4d1618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Classes and Functions\n",
    "\n",
    "# # Custom Logistic Regression\n",
    "# class LogisticRegressionModel:\n",
    "#     def __init__(self, C=0.05, penalty='l1', solver='saga'):\n",
    "#         self.model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=10000)\n",
    "\n",
    "#     def train(self, X, y, epochs=1000):\n",
    "#         self.model.fit(X, y)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         return self.model.predict(X)\n",
    "\n",
    "#     def score(self, X, y):\n",
    "#         # Calculate the accuracy of the model on the given data set.\n",
    "#         accuracy = np.mean(self.predict(X) == y)\n",
    "\n",
    "#         return accuracy\n",
    "\n",
    "# # Custom Support Vector Machine\n",
    "# class SupportVectorMachineModel:\n",
    "#     def __init__(self, C=1.0):\n",
    "#         self.model = SVC(C=C, kernel='linear')\n",
    "\n",
    "#     def train(self, X_train, y_train):\n",
    "#         self.model.fit(X_train, y_train)\n",
    "\n",
    "#     def predict(self, X_test):\n",
    "#         return self.model.predict(X_test)\n",
    "\n",
    "# # Custom Evaluation model\n",
    "# def evaluate_model(model, X_test, y_test):\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     accuracy = np.mean(y_pred == y_test)\n",
    "#     precision = np.mean(y_pred[y_test == 1] == 1)\n",
    "#     recall = np.mean(y_pred == y_test) if np.sum(y_test == 1) > 0 else 0\n",
    "#     # F1 score: A harmonic mean of precision and recall.\n",
    "#     f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "#     return accuracy, precision, recall, f1_score\n",
    "\n",
    "# # Custom Stochastic Gradient Descent\n",
    "# class StochasticGradientDescent:\n",
    "#     def __init__(self, learning_rate=0.01):\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.weights = None\n",
    "        \n",
    "#     # Initialize the model parameters to random values.\n",
    "#     def train(self, X, y, epochs=1000):\n",
    "#         # Initialize the weights\n",
    "#         self.weights = np.random.randn(X.shape[1])\n",
    "\n",
    "#         # Iterate over the training data in batches\n",
    "#         for epoch in range(epochs):\n",
    "#             for i in range(X.shape[0]):\n",
    "#                 # Get a batch of data\n",
    "#                 x_batch = X[i:i + 1, :]\n",
    "#                 y_batch = y[i:i + 1]\n",
    "\n",
    "#                 # Compute the predictions\n",
    "#                 y_pred = self.predict(x_batch)\n",
    "\n",
    "#                 # Compute the gradients of the loss function with respect to the model parameters\n",
    "#                 gradients = np.dot(x_batch.T, y_pred - y_batch)\n",
    "\n",
    "#                 # Update the model parameters using the gradients and a learning rate\n",
    "#                 self.weights -= self.learning_rate * gradients\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         # Compute the predictions\n",
    "#         y_pred = 1 / (1 + np.exp(-np.dot(X, self.weights)))\n",
    "\n",
    "#         return y_pred\n",
    "    \n",
    "#     def compute_gradients(self, X_train, y_train):\n",
    "#         # Compute the predictions\n",
    "#         y_pred = self.predict(X_train)\n",
    "\n",
    "#         # Compute the gradients of the loss function with respect to the model parameters\n",
    "#         gradients = np.dot(X_train.T, y_pred - y_train)\n",
    "\n",
    "#         return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f4a6b",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ed2738",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_name</th>\n",
       "      <th>date</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>...</th>\n",
       "      <th>log_num_hrefs</th>\n",
       "      <th>log_num_self_hrefs</th>\n",
       "      <th>log_num_imgs</th>\n",
       "      <th>log_num_videos</th>\n",
       "      <th>log_kw_max_min</th>\n",
       "      <th>log_kw_min_max</th>\n",
       "      <th>log_kw_avg_avg</th>\n",
       "      <th>log_self_reference_min_shares</th>\n",
       "      <th>log_self_reference_max_shares</th>\n",
       "      <th>log_self_reference_avg_sharess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon-instant-video-browser/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reeddit-reddit/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>4.546154</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rage-comics-dying/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>4.759494</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>power-matters-alliance-organization/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>5.147748</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>polaroid-android-camera/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.424132</td>\n",
       "      <td>4.631390</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.302619</td>\n",
       "      <td>9.680406</td>\n",
       "      <td>8.140199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               url_name        date  timedelta  \\\n",
       "0         amazon-instant-video-browser/  2013-01-07      731.0   \n",
       "1                       reeddit-reddit/  2013-01-07      731.0   \n",
       "2                    rage-comics-dying/  2013-01-07      731.0   \n",
       "3  power-matters-alliance-organization/  2013-01-07      731.0   \n",
       "4              polaroid-android-camera/  2013-01-07      731.0   \n",
       "\n",
       "   n_tokens_title  n_unique_tokens  average_token_length  num_keywords  \\\n",
       "0            12.0         0.663594              4.680365           5.0   \n",
       "1             8.0         0.821705              4.546154           9.0   \n",
       "2             9.0         0.608602              4.759494           7.0   \n",
       "3            10.0         0.535390              5.147748          10.0   \n",
       "4             9.0         0.424132              4.631390           8.0   \n",
       "\n",
       "   kw_min_min  kw_avg_min  kw_max_max  ...  log_num_hrefs  log_num_self_hrefs  \\\n",
       "0         0.0         0.0         0.0  ...       1.609438            1.098612   \n",
       "1         0.0         0.0         0.0  ...       2.079442            1.609438   \n",
       "2         0.0         0.0         0.0  ...       2.484907            0.000000   \n",
       "3         0.0         0.0         0.0  ...       2.079442            1.945910   \n",
       "4         0.0         0.0         0.0  ...       3.091042            3.091042   \n",
       "\n",
       "   log_num_imgs  log_num_videos  log_kw_max_min  log_kw_min_max  \\\n",
       "0      0.693147             0.0             0.0             0.0   \n",
       "1      0.000000             0.0             0.0             0.0   \n",
       "2      0.693147             0.0             0.0             0.0   \n",
       "3      0.693147             0.0             0.0             0.0   \n",
       "4      3.044522             0.0             0.0             0.0   \n",
       "\n",
       "   log_kw_avg_avg  log_self_reference_min_shares  \\\n",
       "0             0.0                       6.208590   \n",
       "1             0.0                       7.170888   \n",
       "2             0.0                       0.000000   \n",
       "3             0.0                       7.550135   \n",
       "4             0.0                       6.302619   \n",
       "\n",
       "   log_self_reference_max_shares  log_self_reference_avg_sharess  \n",
       "0                       6.208590                        6.208590  \n",
       "1                       7.170888                        7.170888  \n",
       "2                       0.000000                        0.000000  \n",
       "3                       7.550135                        7.550135  \n",
       "4                       9.680406                        8.140199  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file path\n",
    "filepath = \"../1 - Visualization and Data Preprocessing/Data/ONPClean2.csv\"\n",
    "# Load the dataset\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a27abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>log_num_hrefs</th>\n",
       "      <th>log_num_self_hrefs</th>\n",
       "      <th>log_num_imgs</th>\n",
       "      <th>log_num_videos</th>\n",
       "      <th>log_kw_max_min</th>\n",
       "      <th>log_kw_min_max</th>\n",
       "      <th>log_kw_avg_avg</th>\n",
       "      <th>log_self_reference_min_shares</th>\n",
       "      <th>log_self_reference_max_shares</th>\n",
       "      <th>log_self_reference_avg_sharess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>4.546154</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>4.759494</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>5.147748</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.424132</td>\n",
       "      <td>4.631390</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.302619</td>\n",
       "      <td>9.680406</td>\n",
       "      <td>8.140199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_unique_tokens  average_token_length  \\\n",
       "0      731.0            12.0         0.663594              4.680365   \n",
       "1      731.0             8.0         0.821705              4.546154   \n",
       "2      731.0             9.0         0.608602              4.759494   \n",
       "3      731.0            10.0         0.535390              5.147748   \n",
       "4      731.0             9.0         0.424132              4.631390   \n",
       "\n",
       "   num_keywords  kw_min_min  kw_avg_min  kw_max_max  kw_avg_max  kw_min_avg  \\\n",
       "0           5.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1           9.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2           7.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3          10.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4           8.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   ...  log_num_hrefs  log_num_self_hrefs  log_num_imgs  log_num_videos  \\\n",
       "0  ...       1.609438            1.098612      0.693147             0.0   \n",
       "1  ...       2.079442            1.609438      0.000000             0.0   \n",
       "2  ...       2.484907            0.000000      0.693147             0.0   \n",
       "3  ...       2.079442            1.945910      0.693147             0.0   \n",
       "4  ...       3.091042            3.091042      3.044522             0.0   \n",
       "\n",
       "   log_kw_max_min  log_kw_min_max  log_kw_avg_avg  \\\n",
       "0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0   \n",
       "\n",
       "   log_self_reference_min_shares  log_self_reference_max_shares  \\\n",
       "0                       6.208590                       6.208590   \n",
       "1                       7.170888                       7.170888   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       7.550135                       7.550135   \n",
       "4                       6.302619                       9.680406   \n",
       "\n",
       "   log_self_reference_avg_sharess  \n",
       "0                        6.208590  \n",
       "1                        7.170888  \n",
       "2                        0.000000  \n",
       "3                        7.550135  \n",
       "4                        8.140199  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop certain columns\n",
    "df1 = df.drop('url_name', axis=1) # was a string\n",
    "df1 = df1.drop('date', axis=1) # datetime change didnt even work.\n",
    "df1 = df1.drop('day_of_week', axis=1) # other categorical variable\n",
    "df1 = df1.drop('news_category', axis=1) # other categorical variable\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6186be1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     39644.000000\n",
       "mean       3395.380184\n",
       "std       11626.950749\n",
       "min           1.000000\n",
       "25%         946.000000\n",
       "50%        1400.000000\n",
       "75%        2800.000000\n",
       "max      843300.000000\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the `shares` column\n",
    "df1['shares'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2463189b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>log_num_self_hrefs</th>\n",
       "      <th>log_num_imgs</th>\n",
       "      <th>log_num_videos</th>\n",
       "      <th>log_kw_max_min</th>\n",
       "      <th>log_kw_min_max</th>\n",
       "      <th>log_kw_avg_avg</th>\n",
       "      <th>log_self_reference_min_shares</th>\n",
       "      <th>log_self_reference_max_shares</th>\n",
       "      <th>log_self_reference_avg_sharess</th>\n",
       "      <th>share_ranges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>4.546154</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>4.759494</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>5.147748</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.424132</td>\n",
       "      <td>4.631390</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.302619</td>\n",
       "      <td>9.680406</td>\n",
       "      <td>8.140199</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_unique_tokens  average_token_length  \\\n",
       "0      731.0            12.0         0.663594              4.680365   \n",
       "1      731.0             8.0         0.821705              4.546154   \n",
       "2      731.0             9.0         0.608602              4.759494   \n",
       "3      731.0            10.0         0.535390              5.147748   \n",
       "4      731.0             9.0         0.424132              4.631390   \n",
       "\n",
       "   num_keywords  kw_min_min  kw_avg_min  kw_max_max  kw_avg_max  kw_min_avg  \\\n",
       "0           5.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1           9.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2           7.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3          10.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4           8.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   ...  log_num_self_hrefs  log_num_imgs  log_num_videos  log_kw_max_min  \\\n",
       "0  ...            1.098612      0.693147             0.0             0.0   \n",
       "1  ...            1.609438      0.000000             0.0             0.0   \n",
       "2  ...            0.000000      0.693147             0.0             0.0   \n",
       "3  ...            1.945910      0.693147             0.0             0.0   \n",
       "4  ...            3.091042      3.044522             0.0             0.0   \n",
       "\n",
       "   log_kw_min_max  log_kw_avg_avg  log_self_reference_min_shares  \\\n",
       "0             0.0             0.0                       6.208590   \n",
       "1             0.0             0.0                       7.170888   \n",
       "2             0.0             0.0                       0.000000   \n",
       "3             0.0             0.0                       7.550135   \n",
       "4             0.0             0.0                       6.302619   \n",
       "\n",
       "   log_self_reference_max_shares  log_self_reference_avg_sharess  share_ranges  \n",
       "0                       6.208590                        6.208590         <2500  \n",
       "1                       7.170888                        7.170888         <2500  \n",
       "2                       0.000000                        0.000000         <2500  \n",
       "3                       7.550135                        7.550135         <2500  \n",
       "4                       9.680406                        8.140199         <2500  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column called `share_ranges` with categorical levels\n",
    "df1['share_ranges'] = pd.cut(df1['shares'], bins=[0, 2500, 5000, 7500, 10000, 20000, 100000, 1000000], labels=['<2500', '>2500 & <5000', '>5000 & <7500', '>7500 & <10000', '>10000 & <20000', '>20000 & <100000', '>100000'])\n",
    "\n",
    "# Print the DataFrame\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f3be3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5572a458",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Describe the `shares` column\n",
    "# df1['share_ranges'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c0b05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>log_num_self_hrefs</th>\n",
       "      <th>log_num_imgs</th>\n",
       "      <th>log_num_videos</th>\n",
       "      <th>log_kw_max_min</th>\n",
       "      <th>log_kw_min_max</th>\n",
       "      <th>log_kw_avg_avg</th>\n",
       "      <th>log_self_reference_min_shares</th>\n",
       "      <th>log_self_reference_max_shares</th>\n",
       "      <th>log_self_reference_avg_sharess</th>\n",
       "      <th>share_ranges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>4.546154</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>4.759494</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>5.147748</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.424132</td>\n",
       "      <td>4.631390</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.302619</td>\n",
       "      <td>9.680406</td>\n",
       "      <td>8.140199</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.567227</td>\n",
       "      <td>4.313253</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>571200.000000</td>\n",
       "      <td>2170.324903</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.384495</td>\n",
       "      <td>9.994288</td>\n",
       "      <td>7.967156</td>\n",
       "      <td>8.071219</td>\n",
       "      <td>9.179984</td>\n",
       "      <td>8.771990</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.570136</td>\n",
       "      <td>4.589286</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>310130.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>8.131825</td>\n",
       "      <td>7.313887</td>\n",
       "      <td>7.946497</td>\n",
       "      <td>7.003974</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.424165</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39641</th>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>4.263403</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>224885.714286</td>\n",
       "      <td>1880.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.378384</td>\n",
       "      <td>8.366603</td>\n",
       "      <td>8.083845</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>&gt;2500 &amp; &lt;5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.506261</td>\n",
       "      <td>5.005172</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>88.857143</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>266628.571429</td>\n",
       "      <td>1558.755814</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.104793</td>\n",
       "      <td>9.752723</td>\n",
       "      <td>7.912769</td>\n",
       "      <td>7.244942</td>\n",
       "      <td>7.244942</td>\n",
       "      <td>7.244942</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>4.471338</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>366200.000000</td>\n",
       "      <td>3035.080555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.584967</td>\n",
       "      <td>12.233693</td>\n",
       "      <td>8.101044</td>\n",
       "      <td>7.650169</td>\n",
       "      <td>7.650169</td>\n",
       "      <td>7.650169</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39644 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timedelta  n_tokens_title  n_unique_tokens  average_token_length  \\\n",
       "0          731.0            12.0         0.663594              4.680365   \n",
       "1          731.0             8.0         0.821705              4.546154   \n",
       "2          731.0             9.0         0.608602              4.759494   \n",
       "3          731.0            10.0         0.535390              5.147748   \n",
       "4          731.0             9.0         0.424132              4.631390   \n",
       "...          ...             ...              ...                   ...   \n",
       "39639        9.0            12.0         0.567227              4.313253   \n",
       "39640        9.0            13.0         0.570136              4.589286   \n",
       "39641        9.0            12.0         0.514925              4.263403   \n",
       "39642        9.0            15.0         0.506261              5.005172   \n",
       "39643        8.0            10.0         0.701987              4.471338   \n",
       "\n",
       "       num_keywords  kw_min_min  kw_avg_min  kw_max_max     kw_avg_max  \\\n",
       "0               5.0         0.0    0.000000         0.0       0.000000   \n",
       "1               9.0         0.0    0.000000         0.0       0.000000   \n",
       "2               7.0         0.0    0.000000         0.0       0.000000   \n",
       "3              10.0         0.0    0.000000         0.0       0.000000   \n",
       "4               8.0         0.0    0.000000         0.0       0.000000   \n",
       "...             ...         ...         ...         ...            ...   \n",
       "39639           5.0        -1.0   42.600000    843300.0  571200.000000   \n",
       "39640          10.0        -1.0  511.000000    843300.0  310130.000000   \n",
       "39641           7.0        -1.0  525.000000    843300.0  224885.714286   \n",
       "39642           7.0        -1.0   88.857143    843300.0  266628.571429   \n",
       "39643           4.0        -1.0   23.500000    843300.0  366200.000000   \n",
       "\n",
       "        kw_min_avg  ...  log_num_self_hrefs  log_num_imgs  log_num_videos  \\\n",
       "0         0.000000  ...            1.098612      0.693147        0.000000   \n",
       "1         0.000000  ...            1.609438      0.000000        0.000000   \n",
       "2         0.000000  ...            0.000000      0.693147        0.000000   \n",
       "3         0.000000  ...            1.945910      0.693147        0.000000   \n",
       "4         0.000000  ...            3.091042      3.044522        0.000000   \n",
       "...            ...  ...                 ...           ...             ...   \n",
       "39639  2170.324903  ...            1.098612      0.693147        0.693147   \n",
       "39640  1500.000000  ...            2.079442      0.693147        0.693147   \n",
       "39641  1880.000000  ...            1.386294      1.386294        0.000000   \n",
       "39642  1558.755814  ...            1.098612      1.386294        0.000000   \n",
       "39643  3035.080555  ...            0.693147      0.000000        1.098612   \n",
       "\n",
       "       log_kw_max_min  log_kw_min_max  log_kw_avg_avg  \\\n",
       "0            0.000000        0.000000        0.000000   \n",
       "1            0.000000        0.000000        0.000000   \n",
       "2            0.000000        0.000000        0.000000   \n",
       "3            0.000000        0.000000        0.000000   \n",
       "4            0.000000        0.000000        0.000000   \n",
       "...               ...             ...             ...   \n",
       "39639        5.384495        9.994288        7.967156   \n",
       "39640        8.131825        7.313887        7.946497   \n",
       "39641        7.378384        8.366603        8.083845   \n",
       "39642        6.104793        9.752723        7.912769   \n",
       "39643        4.584967       12.233693        8.101044   \n",
       "\n",
       "       log_self_reference_min_shares  log_self_reference_max_shares  \\\n",
       "0                           6.208590                       6.208590   \n",
       "1                           7.170888                       7.170888   \n",
       "2                           0.000000                       0.000000   \n",
       "3                           7.550135                       7.550135   \n",
       "4                           6.302619                       9.680406   \n",
       "...                              ...                            ...   \n",
       "39639                       8.071219                       9.179984   \n",
       "39640                       7.003974                       7.550135   \n",
       "39641                       7.170888                       7.170888   \n",
       "39642                       7.244942                       7.244942   \n",
       "39643                       7.650169                       7.650169   \n",
       "\n",
       "       log_self_reference_avg_sharess   share_ranges  \n",
       "0                            6.208590          <2500  \n",
       "1                            7.170888          <2500  \n",
       "2                            0.000000          <2500  \n",
       "3                            7.550135          <2500  \n",
       "4                            8.140199          <2500  \n",
       "...                               ...            ...  \n",
       "39639                        8.771990          <2500  \n",
       "39640                        7.424165          <2500  \n",
       "39641                        7.170888  >2500 & <5000  \n",
       "39642                        7.244942          <2500  \n",
       "39643                        7.650169          <2500  \n",
       "\n",
       "[39644 rows x 49 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "820f849b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39644 entries, 0 to 39643\n",
      "Data columns (total 49 columns):\n",
      " #   Column                          Non-Null Count  Dtype   \n",
      "---  ------                          --------------  -----   \n",
      " 0   timedelta                       39644 non-null  float64 \n",
      " 1   n_tokens_title                  39644 non-null  float64 \n",
      " 2   n_unique_tokens                 39644 non-null  float64 \n",
      " 3   average_token_length            39644 non-null  float64 \n",
      " 4   num_keywords                    39644 non-null  float64 \n",
      " 5   kw_min_min                      39644 non-null  float64 \n",
      " 6   kw_avg_min                      39644 non-null  float64 \n",
      " 7   kw_max_max                      39644 non-null  float64 \n",
      " 8   kw_avg_max                      39644 non-null  float64 \n",
      " 9   kw_min_avg                      39644 non-null  float64 \n",
      " 10  kw_max_avg                      39644 non-null  float64 \n",
      " 11  is_weekend                      39644 non-null  float64 \n",
      " 12  LDA_00                          39644 non-null  float64 \n",
      " 13  LDA_01                          39644 non-null  float64 \n",
      " 14  LDA_02                          39644 non-null  float64 \n",
      " 15  LDA_03                          39644 non-null  float64 \n",
      " 16  LDA_04                          39644 non-null  float64 \n",
      " 17  global_subjectivity             39644 non-null  float64 \n",
      " 18  global_sentiment_polarity       39644 non-null  float64 \n",
      " 19  global_rate_positive_words      39644 non-null  float64 \n",
      " 20  global_rate_negative_words      39644 non-null  float64 \n",
      " 21  rate_positive_words             39644 non-null  float64 \n",
      " 22  rate_negative_words             39644 non-null  float64 \n",
      " 23  avg_positive_polarity           39644 non-null  float64 \n",
      " 24  min_positive_polarity           39644 non-null  float64 \n",
      " 25  max_positive_polarity           39644 non-null  float64 \n",
      " 26  avg_negative_polarity           39644 non-null  float64 \n",
      " 27  min_negative_polarity           39644 non-null  float64 \n",
      " 28  max_negative_polarity           39644 non-null  float64 \n",
      " 29  title_subjectivity              39644 non-null  float64 \n",
      " 30  title_sentiment_polarity        39644 non-null  float64 \n",
      " 31  abs_title_subjectivity          39644 non-null  float64 \n",
      " 32  abs_title_sentiment_polarity    39644 non-null  float64 \n",
      " 33  shares                          39644 non-null  int64   \n",
      " 34  year                            39644 non-null  int64   \n",
      " 35  month                           39644 non-null  int64   \n",
      " 36  log_shares                      39644 non-null  float64 \n",
      " 37  log_n_tokens_content            39644 non-null  float64 \n",
      " 38  log_num_hrefs                   39644 non-null  float64 \n",
      " 39  log_num_self_hrefs              39644 non-null  float64 \n",
      " 40  log_num_imgs                    39644 non-null  float64 \n",
      " 41  log_num_videos                  39644 non-null  float64 \n",
      " 42  log_kw_max_min                  39644 non-null  float64 \n",
      " 43  log_kw_min_max                  39644 non-null  float64 \n",
      " 44  log_kw_avg_avg                  39644 non-null  float64 \n",
      " 45  log_self_reference_min_shares   39644 non-null  float64 \n",
      " 46  log_self_reference_max_shares   39644 non-null  float64 \n",
      " 47  log_self_reference_avg_sharess  39644 non-null  float64 \n",
      " 48  share_ranges                    39644 non-null  category\n",
      "dtypes: category(1), float64(45), int64(3)\n",
      "memory usage: 14.6 MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a20bc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 80% training and 20% testing sets.\n",
    "X = df1.drop('share_ranges', axis=1)\n",
    "y = df1['share_ranges']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Scale the features in the training and testing sets.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa24e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaNs in the dataset\n",
    "for column in df1.columns:\n",
    "    if df1[column].isnull().any():\n",
    "        print('NaNs found in column:', column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c7dc8",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd6a8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the logistic regression model\n",
    "# logistic_regression_model = LogisticRegressionModel()\n",
    "\n",
    "# # Train the logistic regression model on the training set.\n",
    "# logistic_regression_model.train(X_train, y_train)\n",
    "\n",
    "# # Calculate the cross-validated accuracy of the model.\n",
    "# logistic_regression_cross_validated_accuracy = cross_val_score(logistic_regression_model, X_train, y_train, cv=5)\n",
    "\n",
    "# # Print the cross-validated accuracy of the model.\n",
    "# print('Logistic regression cross-validated accuracy:', logistic_regression_cross_validated_accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23cccd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05, max_iter=10000, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model parameters.\n",
    "C = 0.05\n",
    "penalty = 'l1'\n",
    "solver = 'saga'\n",
    "max_iter=10000\n",
    "\n",
    "# Create a logistic regression model.\n",
    "logistic_regression_model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=max_iter)\n",
    "\n",
    "# Fit the model to the training data.\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data.\n",
    "y_pred = logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "000a6c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do cross validation\n",
    "# logistic_regression_cross_validated_accuracy = cross_val_score(logistic_regression_model, X_train, y_train, cv=5)\n",
    "\n",
    "# # Check accuracy from cross validation\n",
    "# print('Logistic regression cross-validated accuracy:', logistic_regression_cross_validated_accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "372ab076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the cross-validated accuracy.\n",
    "# plt.plot(logistic_regression_cross_validated_accuracy)\n",
    "\n",
    "# # Fit a line to the cross-validated accuracy.\n",
    "# # line, axes = plt.plot(logistic_regression_cross_validated_accuracy, 'r-')\n",
    "\n",
    "# # Set the title and labels of the plot.\n",
    "# plt.title('Logistic Regression Cross-Validated Accuracy')\n",
    "# plt.xlabel('Cross-Validation Chunk')\n",
    "# plt.ylabel('Accuracy')\n",
    "\n",
    "# # Add a label to the fit line.\n",
    "# # line.set_label('C=0.05, penalty=\\'l1\\', solver=\\'saga\\'')\n",
    "\n",
    "# # Show the plot.\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "939ab0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.9713709168873754\n",
      "Logistic regression precision: 0.9253480421239193\n",
      "Logistic regression recall: 0.8188545675735109\n",
      "Logistic regression F1 score: 0.8354224838309382\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data.\n",
    "logistic_regression_accuracy = accuracy_score(y_test, y_pred)\n",
    "logistic_regression_precision = precision_score(y_test, y_pred, average='macro')\n",
    "logistic_regression_recall = recall_score(y_test, y_pred, average='macro')\n",
    "logistic_regression_f1_score = f1_score(y_test, y_pred, average='macro')\n",
    "# logistic_regression_roc_auc_score = roc_curve(y_test, y_pred[:, 1])\n",
    "\n",
    "\n",
    "# Print the metrics.\n",
    "print('Logistic regression accuracy:', logistic_regression_accuracy)\n",
    "print('Logistic regression precision:', logistic_regression_precision)\n",
    "print('Logistic regression recall:', logistic_regression_recall)\n",
    "print('Logistic regression F1 score:', logistic_regression_f1_score)\n",
    "# print('Logisticregression ROC AUC score:', logistic_regression_roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76a364d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the y_pred array to a 2-dimensional array.\n",
    "# y_pred_2d = y_pred[:, 2]\n",
    "\n",
    "# # Calculate the ROC curve.\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_2d)\n",
    "\n",
    "# # Plot the ROC curve.\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f812dd",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b41b5f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the support vector machine model\n",
    "support_vector_machine_model = SVC()\n",
    "\n",
    "# Train the support vector machine model on the training set using a linear kernel.\n",
    "support_vector_machine_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data.\n",
    "y_pred = support_vector_machine_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do cross validation\n",
    "# support_vector_machine_cross_validated_accuracy = cross_val_score(support_vector_machine_model, X_train, y_train, cv=5)\n",
    "\n",
    "# # Check accuracy from cross validation\n",
    "# print('SVM cross-validated accuracy:', support_vector_machine_cross_validated_accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the cross-validated accuracy.\n",
    "# plt.plot(support_vector_machine_cross_validated_accuracy)\n",
    "\n",
    "# # Fit a line to the cross-validated accuracy.\n",
    "# # line, axes = plt.plot(logistic_regression_cross_validated_accuracy, 'r-')\n",
    "\n",
    "# # Set the title and labels of the plot.\n",
    "# plt.title('SVM Cross-Validated Accuracy')\n",
    "# plt.xlabel('Cross-Validation Chunk')\n",
    "# plt.ylabel('Accuracy')\n",
    "\n",
    "# # Add a label to the fit line.\n",
    "# # line.set_label('C=0.05, penalty=\\'l1\\', solver=\\'saga\\'')\n",
    "\n",
    "# # Show the plot.\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ed21317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector machine accuracy: 0.9509395888510531\n",
      "Support vector machine precision: 0.8921229820194464\n",
      "Support vector machine recall: 0.8176104771864495\n",
      "Support vector machine F1 score: 0.849605018971621\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data.\n",
    "support_vector_machine_accuracy = accuracy_score(y_test, y_pred)\n",
    "support_vector_machine_precision = precision_score(y_test, y_pred, average='macro')\n",
    "support_vector_machine_recall = recall_score(y_test, y_pred, average='macro')\n",
    "support_vector_machine_f1_score = f1_score(y_test, y_pred, average='macro')\n",
    "# support_vector_machine_roc_auc_score = roc_auc_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the metrics.\n",
    "print('Support vector machine accuracy:', support_vector_machine_accuracy)\n",
    "print('Support vector machine precision:', support_vector_machine_precision)\n",
    "print('Support vector machine recall:', support_vector_machine_recall)\n",
    "print('Support vector machine F1 score:', support_vector_machine_f1_score)\n",
    "# print('Support vector machine ROC AUC score:', support_vector_machine_roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b512496",
   "metadata": {},
   "source": [
    "### Adjusting parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084ecbb",
   "metadata": {},
   "source": [
    "To adjust the parameters of the logistic regression and support vector machine models, I would use a grid search approach. This involves training the models with a range of different parameter values and evaluating their performance on the testing set. \n",
    "The parameter values that produce the best performance on the testing set would then be selected as the final parameters for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843f833",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47452dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the logistic regression model\n",
    "# SGD = StochasticGradientDescent()\n",
    "\n",
    "# # Train the model\n",
    "# SGD.train(X, y)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = SGD.predict(X)\n",
    "\n",
    "# # Print the predictions\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e63e447",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1360\\3511882819.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mscl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0msvm_sgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_sgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "regularize_const = 0.1\n",
    "iterations = 5\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
    "        loss='hinge', n_iter_no_change=iterations, n_jobs=-1, penalty='l2')\n",
    "\n",
    "scl = StandardScaler()\n",
    "for train_idx, test_idx in cv.split(X,y):\n",
    "    svm_sgd.fit(scl.fit_transform(X[train_idx]),y[train_idx])\n",
    "    yhat = svm_sgd.predict(scl.transform(X[test_idx]))\n",
    "\n",
    "    conf = mt.confusion_matrix(y[test_idx],yhat)\n",
    "    acc = mt.accuracy_score(y[test_idx],yhat)\n",
    "\n",
    "print('SVM:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da5c70",
   "metadata": {},
   "source": [
    "### Evaluating model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88fa313",
   "metadata": {},
   "source": [
    "##### Accuracy: The proportion of predictions that are correct.\n",
    "\n",
    "##### Precision: The proportion of positive predictions that are correct.\n",
    "\n",
    "##### Recall: The proportion of positive examples that are correctly identified.\n",
    "\n",
    "##### ROC:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ce628",
   "metadata": {},
   "source": [
    "#### Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4998ab53",
   "metadata": {},
   "source": [
    "The Logistic Regression model takes longer to train than the SVM model\n",
    "Logistic Regression showed better numbers across each of the metrics recorded. In some cases this difference is very small.\n",
    "Accuracy was beter by ~0.02, precision by ~0.03, recall by ~0.001, and an F1 score difference of ~0.015."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86b875",
   "metadata": {},
   "source": [
    "#### Use the weights from logistic regression to interpret the importance of different\n",
    "features for each classification task. Explain your interpretation in detail. Why do you think\n",
    "some variables are more important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80203425",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "559540e4",
   "metadata": {},
   "source": [
    "#### Look at the chosen support vectors for the classification task. Do these provide\n",
    "any insight into the data? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec81a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf7aa1a8",
   "metadata": {},
   "source": [
    "##### From Google Bard:\n",
    "\n",
    "Which model to use?\n",
    "\n",
    "The best model to use for a particular classification task will depend on the specific characteristics of the data. Logistic regression is a good choice for tasks where the data is linearly separable and the dataset size is not too large. Support vector machines are a good choice for tasks where the data is not linearly separable, the dataset size is large, or there are outliers in the data.\n",
    "\n",
    "It is also important to note that support vector machines can be more computationally expensive to train than logistic regression models.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "To create a logistic regression model and a support vector machine model for the classification task involved with my dataset, I would follow the steps outlined above. I would then adjust the parameters of the models to improve their performance and evaluate their performance on the testing set. The model with the best performance on the testing set would then be selected as the final model.\n",
    "#####################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
