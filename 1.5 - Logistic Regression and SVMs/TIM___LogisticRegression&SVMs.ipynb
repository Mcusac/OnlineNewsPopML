{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "813cff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# this import allows you train and test you test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# this import allows you to standardize your data, scaling so that all features have a mean of zero and a standard deviation of 1. \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# this import allows you to create a logistic regression model; type of machine learning model that can be used for classification tasks \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# this import allows you to create a support vector machine SVM model, a type of ML model that can be used for classification tasks. \n",
    "from sklearn.svm import SVC\n",
    "# this import allows you to perform CV on your model, a technique for evaluating the performance of a ML on unseen data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# these imports allow you to calculate various evaluation metrics for your ML model. Eval metrics are used to asses the performance of a ML on held-out test set. \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f4a6b",
   "metadata": {},
   "source": [
    "### In this mini-project the team decided to reuse the Mashable dataset from Project 1. As you recall the data was gathered between 2013-2014 in order to learn more about their readers in the hopes of creating more ad revenue. The data collected monitored a range quantified features such as sentiment, polarity, and number of shares per article.\n",
    "\n",
    "### Here we load in our data and drop a few other columns that are categorical that will not be used in our models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43ed2738",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_name</th>\n",
       "      <th>date</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>news_category</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>log_shares</th>\n",
       "      <th>log_n_tokens_content</th>\n",
       "      <th>log_num_hrefs</th>\n",
       "      <th>log_num_self_hrefs</th>\n",
       "      <th>log_num_imgs</th>\n",
       "      <th>log_num_videos</th>\n",
       "      <th>log_kw_max_min</th>\n",
       "      <th>log_kw_min_max</th>\n",
       "      <th>log_kw_avg_avg</th>\n",
       "      <th>log_self_reference_min_shares</th>\n",
       "      <th>log_self_reference_max_shares</th>\n",
       "      <th>log_self_reference_avg_sharess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon-instant-video-browser/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.378279</td>\n",
       "      <td>0.040005</td>\n",
       "      <td>0.041263</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>593</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>6.386879</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reeddit-reddit/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>4.546154</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.022446</td>\n",
       "      <td>0.022276</td>\n",
       "      <td>0.251465</td>\n",
       "      <td>0.681548</td>\n",
       "      <td>0.381987</td>\n",
       "      <td>0.152189</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.353939</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1300</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Tech</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>4.875197</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rage-comics-dying/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>4.759494</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.199626</td>\n",
       "      <td>0.028615</td>\n",
       "      <td>0.714611</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.542580</td>\n",
       "      <td>0.122370</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.357269</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.338889</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1100</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.003974</td>\n",
       "      <td>6.163315</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>power-matters-alliance-organization/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>5.147748</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>0.117255</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.822410</td>\n",
       "      <td>0.425089</td>\n",
       "      <td>0.128515</td>\n",
       "      <td>0.039640</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.337965</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.225794</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Tech</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.378384</td>\n",
       "      <td>6.320768</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>polaroid-android-camera/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.424132</td>\n",
       "      <td>4.631390</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.327017</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.597981</td>\n",
       "      <td>0.506520</td>\n",
       "      <td>0.279769</td>\n",
       "      <td>0.071749</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.417055</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.212354</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>2400</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Tech</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.783641</td>\n",
       "      <td>7.017506</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.302619</td>\n",
       "      <td>9.680406</td>\n",
       "      <td>8.140199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               url_name        date  timedelta  \\\n",
       "0         amazon-instant-video-browser/  2013-01-07      731.0   \n",
       "1                       reeddit-reddit/  2013-01-07      731.0   \n",
       "2                    rage-comics-dying/  2013-01-07      731.0   \n",
       "3  power-matters-alliance-organization/  2013-01-07      731.0   \n",
       "4              polaroid-android-camera/  2013-01-07      731.0   \n",
       "\n",
       "   n_tokens_title  n_unique_tokens  average_token_length  num_keywords  \\\n",
       "0            12.0         0.663594              4.680365           5.0   \n",
       "1             8.0         0.821705              4.546154           9.0   \n",
       "2             9.0         0.608602              4.759494           7.0   \n",
       "3            10.0         0.535390              5.147748          10.0   \n",
       "4             9.0         0.424132              4.631390           8.0   \n",
       "\n",
       "   kw_min_min  kw_avg_min  kw_max_max  kw_avg_max  kw_min_avg  kw_max_avg  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   is_weekend    LDA_00    LDA_01    LDA_02    LDA_03    LDA_04  \\\n",
       "0         0.0  0.500331  0.378279  0.040005  0.041263  0.040123   \n",
       "1         0.0  0.022265  0.022446  0.022276  0.251465  0.681548   \n",
       "2         0.0  0.028575  0.199626  0.028615  0.714611  0.028572   \n",
       "3         0.0  0.020011  0.020317  0.117255  0.020007  0.822410   \n",
       "4         0.0  0.025001  0.327017  0.025001  0.025001  0.597981   \n",
       "\n",
       "   global_subjectivity  global_sentiment_polarity  global_rate_positive_words  \\\n",
       "0             0.521617                   0.092562                    0.045662   \n",
       "1             0.381987                   0.152189                    0.038462   \n",
       "2             0.542580                   0.122370                    0.063291   \n",
       "3             0.425089                   0.128515                    0.039640   \n",
       "4             0.506520                   0.279769                    0.071749   \n",
       "\n",
       "   global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "0                    0.013699             0.769231             0.230769   \n",
       "1                    0.007692             0.833333             0.166667   \n",
       "2                    0.025316             0.714286             0.285714   \n",
       "3                    0.012613             0.758621             0.241379   \n",
       "4                    0.013453             0.842105             0.157895   \n",
       "\n",
       "   avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "0               0.378636               0.100000                    0.7   \n",
       "1               0.353939               0.033333                    0.7   \n",
       "2               0.357269               0.050000                    0.6   \n",
       "3               0.337965               0.050000                    0.7   \n",
       "4               0.417055               0.100000                    1.0   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.350000                   -0.6                 -0.200   \n",
       "1              -0.400000                   -0.4                 -0.400   \n",
       "2              -0.338889                   -1.0                 -0.050   \n",
       "3              -0.225794                   -0.4                 -0.125   \n",
       "4              -0.212354                   -0.5                 -0.050   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0            0.500000                   -0.1875                0.000000   \n",
       "1            0.250000                    0.2000                0.250000   \n",
       "2            0.650000                   -0.5000                0.150000   \n",
       "3            0.500000                   -0.1000                0.000000   \n",
       "4            0.333333                    0.2500                0.166667   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares day_of_week  news_category  year  \\\n",
       "0                        0.1875     593      Monday  Entertainment  2013   \n",
       "1                        0.2000    1300      Monday           Tech  2013   \n",
       "2                        0.5000    1100      Monday  Uncategorized  2013   \n",
       "3                        0.1000    1600      Monday           Tech  2013   \n",
       "4                        0.2500    2400      Monday           Tech  2013   \n",
       "\n",
       "   month  log_shares  log_n_tokens_content  log_num_hrefs  log_num_self_hrefs  \\\n",
       "0      1    6.386879              5.393628       1.609438            1.098612   \n",
       "1      1    7.170888              4.875197       2.079442            1.609438   \n",
       "2      1    7.003974              6.163315       2.484907            0.000000   \n",
       "3      1    7.378384              6.320768       2.079442            1.945910   \n",
       "4      1    7.783641              7.017506       3.091042            3.091042   \n",
       "\n",
       "   log_num_imgs  log_num_videos  log_kw_max_min  log_kw_min_max  \\\n",
       "0      0.693147             0.0             0.0             0.0   \n",
       "1      0.000000             0.0             0.0             0.0   \n",
       "2      0.693147             0.0             0.0             0.0   \n",
       "3      0.693147             0.0             0.0             0.0   \n",
       "4      3.044522             0.0             0.0             0.0   \n",
       "\n",
       "   log_kw_avg_avg  log_self_reference_min_shares  \\\n",
       "0             0.0                       6.208590   \n",
       "1             0.0                       7.170888   \n",
       "2             0.0                       0.000000   \n",
       "3             0.0                       7.550135   \n",
       "4             0.0                       6.302619   \n",
       "\n",
       "   log_self_reference_max_shares  log_self_reference_avg_sharess  \n",
       "0                       6.208590                        6.208590  \n",
       "1                       7.170888                        7.170888  \n",
       "2                       0.000000                        0.000000  \n",
       "3                       7.550135                        7.550135  \n",
       "4                       9.680406                        8.140199  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file path\n",
    "filepath = \"../1 - Visualization and Data Preprocessing/Data/ONPClean2.csv\"\n",
    "# Load the dataset\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "# Set the maximum number of columns to display to None\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a27abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>log_shares</th>\n",
       "      <th>log_n_tokens_content</th>\n",
       "      <th>log_num_hrefs</th>\n",
       "      <th>log_num_self_hrefs</th>\n",
       "      <th>log_num_imgs</th>\n",
       "      <th>log_num_videos</th>\n",
       "      <th>log_kw_max_min</th>\n",
       "      <th>log_kw_min_max</th>\n",
       "      <th>log_kw_avg_avg</th>\n",
       "      <th>log_self_reference_min_shares</th>\n",
       "      <th>log_self_reference_max_shares</th>\n",
       "      <th>log_self_reference_avg_sharess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.378279</td>\n",
       "      <td>0.040005</td>\n",
       "      <td>0.041263</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>593</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>6.386879</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>4.546154</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.022446</td>\n",
       "      <td>0.022276</td>\n",
       "      <td>0.251465</td>\n",
       "      <td>0.681548</td>\n",
       "      <td>0.381987</td>\n",
       "      <td>0.152189</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.353939</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1300</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>4.875197</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>4.759494</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.199626</td>\n",
       "      <td>0.028615</td>\n",
       "      <td>0.714611</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.542580</td>\n",
       "      <td>0.122370</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.357269</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.338889</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1100</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.003974</td>\n",
       "      <td>6.163315</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>5.147748</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>0.117255</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.822410</td>\n",
       "      <td>0.425089</td>\n",
       "      <td>0.128515</td>\n",
       "      <td>0.039640</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.337965</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.225794</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.378384</td>\n",
       "      <td>6.320768</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.424132</td>\n",
       "      <td>4.631390</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.327017</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.597981</td>\n",
       "      <td>0.506520</td>\n",
       "      <td>0.279769</td>\n",
       "      <td>0.071749</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.417055</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.212354</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>2400</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.783641</td>\n",
       "      <td>7.017506</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.302619</td>\n",
       "      <td>9.680406</td>\n",
       "      <td>8.140199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_unique_tokens  average_token_length  \\\n",
       "0      731.0            12.0         0.663594              4.680365   \n",
       "1      731.0             8.0         0.821705              4.546154   \n",
       "2      731.0             9.0         0.608602              4.759494   \n",
       "3      731.0            10.0         0.535390              5.147748   \n",
       "4      731.0             9.0         0.424132              4.631390   \n",
       "\n",
       "   num_keywords  kw_min_min  kw_avg_min  kw_max_max  kw_avg_max  kw_min_avg  \\\n",
       "0           5.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1           9.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2           7.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3          10.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4           8.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   kw_max_avg  is_weekend    LDA_00    LDA_01    LDA_02    LDA_03    LDA_04  \\\n",
       "0         0.0         0.0  0.500331  0.378279  0.040005  0.041263  0.040123   \n",
       "1         0.0         0.0  0.022265  0.022446  0.022276  0.251465  0.681548   \n",
       "2         0.0         0.0  0.028575  0.199626  0.028615  0.714611  0.028572   \n",
       "3         0.0         0.0  0.020011  0.020317  0.117255  0.020007  0.822410   \n",
       "4         0.0         0.0  0.025001  0.327017  0.025001  0.025001  0.597981   \n",
       "\n",
       "   global_subjectivity  global_sentiment_polarity  global_rate_positive_words  \\\n",
       "0             0.521617                   0.092562                    0.045662   \n",
       "1             0.381987                   0.152189                    0.038462   \n",
       "2             0.542580                   0.122370                    0.063291   \n",
       "3             0.425089                   0.128515                    0.039640   \n",
       "4             0.506520                   0.279769                    0.071749   \n",
       "\n",
       "   global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "0                    0.013699             0.769231             0.230769   \n",
       "1                    0.007692             0.833333             0.166667   \n",
       "2                    0.025316             0.714286             0.285714   \n",
       "3                    0.012613             0.758621             0.241379   \n",
       "4                    0.013453             0.842105             0.157895   \n",
       "\n",
       "   avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "0               0.378636               0.100000                    0.7   \n",
       "1               0.353939               0.033333                    0.7   \n",
       "2               0.357269               0.050000                    0.6   \n",
       "3               0.337965               0.050000                    0.7   \n",
       "4               0.417055               0.100000                    1.0   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.350000                   -0.6                 -0.200   \n",
       "1              -0.400000                   -0.4                 -0.400   \n",
       "2              -0.338889                   -1.0                 -0.050   \n",
       "3              -0.225794                   -0.4                 -0.125   \n",
       "4              -0.212354                   -0.5                 -0.050   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0            0.500000                   -0.1875                0.000000   \n",
       "1            0.250000                    0.2000                0.250000   \n",
       "2            0.650000                   -0.5000                0.150000   \n",
       "3            0.500000                   -0.1000                0.000000   \n",
       "4            0.333333                    0.2500                0.166667   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares  year  month  log_shares  \\\n",
       "0                        0.1875     593  2013      1    6.386879   \n",
       "1                        0.2000    1300  2013      1    7.170888   \n",
       "2                        0.5000    1100  2013      1    7.003974   \n",
       "3                        0.1000    1600  2013      1    7.378384   \n",
       "4                        0.2500    2400  2013      1    7.783641   \n",
       "\n",
       "   log_n_tokens_content  log_num_hrefs  log_num_self_hrefs  log_num_imgs  \\\n",
       "0              5.393628       1.609438            1.098612      0.693147   \n",
       "1              4.875197       2.079442            1.609438      0.000000   \n",
       "2              6.163315       2.484907            0.000000      0.693147   \n",
       "3              6.320768       2.079442            1.945910      0.693147   \n",
       "4              7.017506       3.091042            3.091042      3.044522   \n",
       "\n",
       "   log_num_videos  log_kw_max_min  log_kw_min_max  log_kw_avg_avg  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   log_self_reference_min_shares  log_self_reference_max_shares  \\\n",
       "0                       6.208590                       6.208590   \n",
       "1                       7.170888                       7.170888   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       7.550135                       7.550135   \n",
       "4                       6.302619                       9.680406   \n",
       "\n",
       "   log_self_reference_avg_sharess  \n",
       "0                        6.208590  \n",
       "1                        7.170888  \n",
       "2                        0.000000  \n",
       "3                        7.550135  \n",
       "4                        8.140199  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop certain columns\n",
    "df1 = df.drop('url_name', axis=1) # was a string\n",
    "df1 = df1.drop('date', axis=1) # datetime change didnt even work.\n",
    "df1 = df1.drop('day_of_week', axis=1) # other categorical variable\n",
    "df1 = df1.drop('news_category', axis=1) # other categorical variable\n",
    "\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef80c32",
   "metadata": {},
   "source": [
    "### For the logistic regression model we take the number of shares per article as our response variable and categorize them by range. Shares equate to popularity and by understanding which features are needed to create an accurate model that can predict whether an article is popular or not may provide some insight into what about the article is driving popularity. Mashable could then share the findings with their journalists in order to adjust to their readers and hopefully create more ad revenue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6186be1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     39644.000000\n",
       "mean       3395.380184\n",
       "std       11626.950749\n",
       "min           1.000000\n",
       "25%         946.000000\n",
       "50%        1400.000000\n",
       "75%        2800.000000\n",
       "max      843300.000000\n",
       "Name: shares, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the `shares` column\n",
    "df1['shares'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced8ac52",
   "metadata": {},
   "source": [
    "### Now that we have our new categorical column 'share_ranges' some data cleaning and sanity checks are done to avoid errors as we create our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2463189b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>log_shares</th>\n",
       "      <th>log_n_tokens_content</th>\n",
       "      <th>log_num_hrefs</th>\n",
       "      <th>log_num_self_hrefs</th>\n",
       "      <th>log_num_imgs</th>\n",
       "      <th>log_num_videos</th>\n",
       "      <th>log_kw_max_min</th>\n",
       "      <th>log_kw_min_max</th>\n",
       "      <th>log_kw_avg_avg</th>\n",
       "      <th>log_self_reference_min_shares</th>\n",
       "      <th>log_self_reference_max_shares</th>\n",
       "      <th>log_self_reference_avg_sharess</th>\n",
       "      <th>share_ranges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.378279</td>\n",
       "      <td>0.040005</td>\n",
       "      <td>0.041263</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>593</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>6.386879</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>4.546154</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.022446</td>\n",
       "      <td>0.022276</td>\n",
       "      <td>0.251465</td>\n",
       "      <td>0.681548</td>\n",
       "      <td>0.381987</td>\n",
       "      <td>0.152189</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.353939</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1300</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>4.875197</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>4.759494</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.199626</td>\n",
       "      <td>0.028615</td>\n",
       "      <td>0.714611</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.542580</td>\n",
       "      <td>0.122370</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.357269</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.338889</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1100</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.003974</td>\n",
       "      <td>6.163315</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>5.147748</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>0.117255</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.822410</td>\n",
       "      <td>0.425089</td>\n",
       "      <td>0.128515</td>\n",
       "      <td>0.039640</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.337965</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.225794</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.378384</td>\n",
       "      <td>6.320768</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.424132</td>\n",
       "      <td>4.631390</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.327017</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.597981</td>\n",
       "      <td>0.506520</td>\n",
       "      <td>0.279769</td>\n",
       "      <td>0.071749</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.417055</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.212354</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>2400</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.783641</td>\n",
       "      <td>7.017506</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.302619</td>\n",
       "      <td>9.680406</td>\n",
       "      <td>8.140199</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_unique_tokens  average_token_length  \\\n",
       "0      731.0            12.0         0.663594              4.680365   \n",
       "1      731.0             8.0         0.821705              4.546154   \n",
       "2      731.0             9.0         0.608602              4.759494   \n",
       "3      731.0            10.0         0.535390              5.147748   \n",
       "4      731.0             9.0         0.424132              4.631390   \n",
       "\n",
       "   num_keywords  kw_min_min  kw_avg_min  kw_max_max  kw_avg_max  kw_min_avg  \\\n",
       "0           5.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1           9.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2           7.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3          10.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4           8.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   kw_max_avg  is_weekend    LDA_00    LDA_01    LDA_02    LDA_03    LDA_04  \\\n",
       "0         0.0         0.0  0.500331  0.378279  0.040005  0.041263  0.040123   \n",
       "1         0.0         0.0  0.022265  0.022446  0.022276  0.251465  0.681548   \n",
       "2         0.0         0.0  0.028575  0.199626  0.028615  0.714611  0.028572   \n",
       "3         0.0         0.0  0.020011  0.020317  0.117255  0.020007  0.822410   \n",
       "4         0.0         0.0  0.025001  0.327017  0.025001  0.025001  0.597981   \n",
       "\n",
       "   global_subjectivity  global_sentiment_polarity  global_rate_positive_words  \\\n",
       "0             0.521617                   0.092562                    0.045662   \n",
       "1             0.381987                   0.152189                    0.038462   \n",
       "2             0.542580                   0.122370                    0.063291   \n",
       "3             0.425089                   0.128515                    0.039640   \n",
       "4             0.506520                   0.279769                    0.071749   \n",
       "\n",
       "   global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "0                    0.013699             0.769231             0.230769   \n",
       "1                    0.007692             0.833333             0.166667   \n",
       "2                    0.025316             0.714286             0.285714   \n",
       "3                    0.012613             0.758621             0.241379   \n",
       "4                    0.013453             0.842105             0.157895   \n",
       "\n",
       "   avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "0               0.378636               0.100000                    0.7   \n",
       "1               0.353939               0.033333                    0.7   \n",
       "2               0.357269               0.050000                    0.6   \n",
       "3               0.337965               0.050000                    0.7   \n",
       "4               0.417055               0.100000                    1.0   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.350000                   -0.6                 -0.200   \n",
       "1              -0.400000                   -0.4                 -0.400   \n",
       "2              -0.338889                   -1.0                 -0.050   \n",
       "3              -0.225794                   -0.4                 -0.125   \n",
       "4              -0.212354                   -0.5                 -0.050   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0            0.500000                   -0.1875                0.000000   \n",
       "1            0.250000                    0.2000                0.250000   \n",
       "2            0.650000                   -0.5000                0.150000   \n",
       "3            0.500000                   -0.1000                0.000000   \n",
       "4            0.333333                    0.2500                0.166667   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares  year  month  log_shares  \\\n",
       "0                        0.1875     593  2013      1    6.386879   \n",
       "1                        0.2000    1300  2013      1    7.170888   \n",
       "2                        0.5000    1100  2013      1    7.003974   \n",
       "3                        0.1000    1600  2013      1    7.378384   \n",
       "4                        0.2500    2400  2013      1    7.783641   \n",
       "\n",
       "   log_n_tokens_content  log_num_hrefs  log_num_self_hrefs  log_num_imgs  \\\n",
       "0              5.393628       1.609438            1.098612      0.693147   \n",
       "1              4.875197       2.079442            1.609438      0.000000   \n",
       "2              6.163315       2.484907            0.000000      0.693147   \n",
       "3              6.320768       2.079442            1.945910      0.693147   \n",
       "4              7.017506       3.091042            3.091042      3.044522   \n",
       "\n",
       "   log_num_videos  log_kw_max_min  log_kw_min_max  log_kw_avg_avg  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   log_self_reference_min_shares  log_self_reference_max_shares  \\\n",
       "0                       6.208590                       6.208590   \n",
       "1                       7.170888                       7.170888   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       7.550135                       7.550135   \n",
       "4                       6.302619                       9.680406   \n",
       "\n",
       "   log_self_reference_avg_sharess share_ranges  \n",
       "0                        6.208590        <2500  \n",
       "1                        7.170888        <2500  \n",
       "2                        0.000000        <2500  \n",
       "3                        7.550135        <2500  \n",
       "4                        8.140199        <2500  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column called `share_ranges` with categorical levels\n",
    "df1['share_ranges'] = pd.cut(df1['shares'], bins=[0, 2500, 5000, 7500, 10000, 20000, 100000, 1000000], labels=['<2500', '>2500 & <5000', '>5000 & <7500', '>7500 & <10000', '>10000 & <20000', '>20000 & <100000', '>100000'])\n",
    "\n",
    "# Print the DataFrame\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5572a458",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<2500               28778\n",
      ">2500 & <5000        5794\n",
      ">5000 & <7500        1920\n",
      ">10000 & <20000      1367\n",
      ">7500 & <10000        967\n",
      ">20000 & <100000      760\n",
      ">100000                58\n",
      "Name: share_ranges, dtype: int64\n",
      "category\n"
     ]
    }
   ],
   "source": [
    "# Describe the `shares` column\n",
    "print(df1['share_ranges'].value_counts())\n",
    "print(df1['share_ranges'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41c0b05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>log_shares</th>\n",
       "      <th>log_n_tokens_content</th>\n",
       "      <th>log_num_hrefs</th>\n",
       "      <th>log_num_self_hrefs</th>\n",
       "      <th>log_num_imgs</th>\n",
       "      <th>log_num_videos</th>\n",
       "      <th>log_kw_max_min</th>\n",
       "      <th>log_kw_min_max</th>\n",
       "      <th>log_kw_avg_avg</th>\n",
       "      <th>log_self_reference_min_shares</th>\n",
       "      <th>log_self_reference_max_shares</th>\n",
       "      <th>log_self_reference_avg_sharess</th>\n",
       "      <th>share_ranges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.378279</td>\n",
       "      <td>0.040005</td>\n",
       "      <td>0.041263</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>593</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>6.386879</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>4.546154</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.022446</td>\n",
       "      <td>0.022276</td>\n",
       "      <td>0.251465</td>\n",
       "      <td>0.681548</td>\n",
       "      <td>0.381987</td>\n",
       "      <td>0.152189</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.353939</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1300</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>4.875197</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>4.759494</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.199626</td>\n",
       "      <td>0.028615</td>\n",
       "      <td>0.714611</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.542580</td>\n",
       "      <td>0.122370</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.357269</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.338889</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1100</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.003974</td>\n",
       "      <td>6.163315</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>5.147748</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>0.117255</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.822410</td>\n",
       "      <td>0.425089</td>\n",
       "      <td>0.128515</td>\n",
       "      <td>0.039640</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.337965</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.225794</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.378384</td>\n",
       "      <td>6.320768</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.424132</td>\n",
       "      <td>4.631390</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.327017</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.597981</td>\n",
       "      <td>0.506520</td>\n",
       "      <td>0.279769</td>\n",
       "      <td>0.071749</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.417055</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.212354</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>2400</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.783641</td>\n",
       "      <td>7.017506</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.302619</td>\n",
       "      <td>9.680406</td>\n",
       "      <td>8.140199</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.567227</td>\n",
       "      <td>4.313253</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>571200.000000</td>\n",
       "      <td>2170.324903</td>\n",
       "      <td>3385.393320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040020</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.040008</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.839967</td>\n",
       "      <td>0.440992</td>\n",
       "      <td>0.266721</td>\n",
       "      <td>0.040161</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.385909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.145833</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>7.003974</td>\n",
       "      <td>5.521461</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.384495</td>\n",
       "      <td>9.994288</td>\n",
       "      <td>7.967156</td>\n",
       "      <td>8.071219</td>\n",
       "      <td>9.179984</td>\n",
       "      <td>8.771990</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.570136</td>\n",
       "      <td>4.589286</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>310130.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>3900.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.219217</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.118088</td>\n",
       "      <td>0.622681</td>\n",
       "      <td>0.384271</td>\n",
       "      <td>0.197662</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.348636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>1400</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>7.244942</td>\n",
       "      <td>5.416100</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>8.131825</td>\n",
       "      <td>7.313887</td>\n",
       "      <td>7.946497</td>\n",
       "      <td>7.003974</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.424165</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39641</th>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>4.263403</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>224885.714286</td>\n",
       "      <td>1880.000000</td>\n",
       "      <td>6433.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.172060</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.742224</td>\n",
       "      <td>0.434468</td>\n",
       "      <td>0.169252</td>\n",
       "      <td>0.039627</td>\n",
       "      <td>0.016317</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.391176</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.179847</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3200</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>8.071219</td>\n",
       "      <td>6.063785</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.378384</td>\n",
       "      <td>8.366603</td>\n",
       "      <td>8.083845</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>&gt;2500 &amp; &lt;5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.506261</td>\n",
       "      <td>5.005172</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>88.857143</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>266628.571429</td>\n",
       "      <td>1558.755814</td>\n",
       "      <td>4966.668990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028579</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.792900</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.121376</td>\n",
       "      <td>0.428833</td>\n",
       "      <td>0.188667</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.407333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.115000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1700</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>7.438972</td>\n",
       "      <td>6.364751</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.104793</td>\n",
       "      <td>9.752723</td>\n",
       "      <td>7.912769</td>\n",
       "      <td>7.244942</td>\n",
       "      <td>7.244942</td>\n",
       "      <td>7.244942</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>4.471338</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>366200.000000</td>\n",
       "      <td>3035.080555</td>\n",
       "      <td>3613.512953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.799339</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050659</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.517893</td>\n",
       "      <td>0.104892</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.247338</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1300</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>5.062595</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.584967</td>\n",
       "      <td>12.233693</td>\n",
       "      <td>8.101044</td>\n",
       "      <td>7.650169</td>\n",
       "      <td>7.650169</td>\n",
       "      <td>7.650169</td>\n",
       "      <td>&lt;2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39644 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timedelta  n_tokens_title  n_unique_tokens  average_token_length  \\\n",
       "0          731.0            12.0         0.663594              4.680365   \n",
       "1          731.0             8.0         0.821705              4.546154   \n",
       "2          731.0             9.0         0.608602              4.759494   \n",
       "3          731.0            10.0         0.535390              5.147748   \n",
       "4          731.0             9.0         0.424132              4.631390   \n",
       "...          ...             ...              ...                   ...   \n",
       "39639        9.0            12.0         0.567227              4.313253   \n",
       "39640        9.0            13.0         0.570136              4.589286   \n",
       "39641        9.0            12.0         0.514925              4.263403   \n",
       "39642        9.0            15.0         0.506261              5.005172   \n",
       "39643        8.0            10.0         0.701987              4.471338   \n",
       "\n",
       "       num_keywords  kw_min_min  kw_avg_min  kw_max_max     kw_avg_max  \\\n",
       "0               5.0         0.0    0.000000         0.0       0.000000   \n",
       "1               9.0         0.0    0.000000         0.0       0.000000   \n",
       "2               7.0         0.0    0.000000         0.0       0.000000   \n",
       "3              10.0         0.0    0.000000         0.0       0.000000   \n",
       "4               8.0         0.0    0.000000         0.0       0.000000   \n",
       "...             ...         ...         ...         ...            ...   \n",
       "39639           5.0        -1.0   42.600000    843300.0  571200.000000   \n",
       "39640          10.0        -1.0  511.000000    843300.0  310130.000000   \n",
       "39641           7.0        -1.0  525.000000    843300.0  224885.714286   \n",
       "39642           7.0        -1.0   88.857143    843300.0  266628.571429   \n",
       "39643           4.0        -1.0   23.500000    843300.0  366200.000000   \n",
       "\n",
       "        kw_min_avg   kw_max_avg  is_weekend    LDA_00    LDA_01    LDA_02  \\\n",
       "0         0.000000     0.000000         0.0  0.500331  0.378279  0.040005   \n",
       "1         0.000000     0.000000         0.0  0.022265  0.022446  0.022276   \n",
       "2         0.000000     0.000000         0.0  0.028575  0.199626  0.028615   \n",
       "3         0.000000     0.000000         0.0  0.020011  0.020317  0.117255   \n",
       "4         0.000000     0.000000         0.0  0.025001  0.327017  0.025001   \n",
       "...            ...          ...         ...       ...       ...       ...   \n",
       "39639  2170.324903  3385.393320         0.0  0.040020  0.040004  0.040008   \n",
       "39640  1500.000000  3900.000000         0.0  0.020009  0.219217  0.020005   \n",
       "39641  1880.000000  6433.333333         0.0  0.028572  0.172060  0.028572   \n",
       "39642  1558.755814  4966.668990         0.0  0.028579  0.028573  0.792900   \n",
       "39643  3035.080555  3613.512953         0.0  0.050001  0.799339  0.050000   \n",
       "\n",
       "         LDA_03    LDA_04  global_subjectivity  global_sentiment_polarity  \\\n",
       "0      0.041263  0.040123             0.521617                   0.092562   \n",
       "1      0.251465  0.681548             0.381987                   0.152189   \n",
       "2      0.714611  0.028572             0.542580                   0.122370   \n",
       "3      0.020007  0.822410             0.425089                   0.128515   \n",
       "4      0.025001  0.597981             0.506520                   0.279769   \n",
       "...         ...       ...                  ...                        ...   \n",
       "39639  0.040000  0.839967             0.440992                   0.266721   \n",
       "39640  0.118088  0.622681             0.384271                   0.197662   \n",
       "39641  0.028572  0.742224             0.434468                   0.169252   \n",
       "39642  0.028571  0.121376             0.428833                   0.188667   \n",
       "39643  0.050659  0.050001             0.517893                   0.104892   \n",
       "\n",
       "       global_rate_positive_words  global_rate_negative_words  \\\n",
       "0                        0.045662                    0.013699   \n",
       "1                        0.038462                    0.007692   \n",
       "2                        0.063291                    0.025316   \n",
       "3                        0.039640                    0.012613   \n",
       "4                        0.071749                    0.013453   \n",
       "...                           ...                         ...   \n",
       "39639                    0.040161                    0.008032   \n",
       "39640                    0.044643                    0.004464   \n",
       "39641                    0.039627                    0.016317   \n",
       "39642                    0.025862                    0.008621   \n",
       "39643                    0.063694                    0.012739   \n",
       "\n",
       "       rate_positive_words  rate_negative_words  avg_positive_polarity  \\\n",
       "0                 0.769231             0.230769               0.378636   \n",
       "1                 0.833333             0.166667               0.353939   \n",
       "2                 0.714286             0.285714               0.357269   \n",
       "3                 0.758621             0.241379               0.337965   \n",
       "4                 0.842105             0.157895               0.417055   \n",
       "...                    ...                  ...                    ...   \n",
       "39639             0.833333             0.166667               0.385909   \n",
       "39640             0.909091             0.090909               0.348636   \n",
       "39641             0.708333             0.291667               0.391176   \n",
       "39642             0.750000             0.250000               0.407333   \n",
       "39643             0.833333             0.166667               0.247338   \n",
       "\n",
       "       min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0                   0.100000                   0.70              -0.350000   \n",
       "1                   0.033333                   0.70              -0.400000   \n",
       "2                   0.050000                   0.60              -0.338889   \n",
       "3                   0.050000                   0.70              -0.225794   \n",
       "4                   0.100000                   1.00              -0.212354   \n",
       "...                      ...                    ...                    ...   \n",
       "39639               0.136364                   1.00              -0.145833   \n",
       "39640               0.100000                   0.50              -0.071429   \n",
       "39641               0.166667                   0.75              -0.179847   \n",
       "39642               0.100000                   0.80              -0.115000   \n",
       "39643               0.100000                   0.50              -0.200000   \n",
       "\n",
       "       min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.600000              -0.200000            0.500000   \n",
       "1                  -0.400000              -0.400000            0.250000   \n",
       "2                  -1.000000              -0.050000            0.650000   \n",
       "3                  -0.400000              -0.125000            0.500000   \n",
       "4                  -0.500000              -0.050000            0.333333   \n",
       "...                      ...                    ...                 ...   \n",
       "39639              -0.166667              -0.125000            0.000000   \n",
       "39640              -0.071429              -0.071429            0.800000   \n",
       "39641              -0.312500              -0.025000            0.000000   \n",
       "39642              -0.125000              -0.100000            0.500000   \n",
       "39643              -0.200000              -0.200000            0.333333   \n",
       "\n",
       "       title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       -0.1875                0.000000   \n",
       "1                        0.2000                0.250000   \n",
       "2                       -0.5000                0.150000   \n",
       "3                       -0.1000                0.000000   \n",
       "4                        0.2500                0.166667   \n",
       "...                         ...                     ...   \n",
       "39639                    0.0000                0.500000   \n",
       "39640                    0.4000                0.300000   \n",
       "39641                    0.0000                0.500000   \n",
       "39642                    0.5000                0.000000   \n",
       "39643                    0.2500                0.166667   \n",
       "\n",
       "       abs_title_sentiment_polarity  shares  year  month  log_shares  \\\n",
       "0                            0.1875     593  2013      1    6.386879   \n",
       "1                            0.2000    1300  2013      1    7.170888   \n",
       "2                            0.5000    1100  2013      1    7.003974   \n",
       "3                            0.1000    1600  2013      1    7.378384   \n",
       "4                            0.2500    2400  2013      1    7.783641   \n",
       "...                             ...     ...   ...    ...         ...   \n",
       "39639                        0.0000    1100  2014     12    7.003974   \n",
       "39640                        0.4000    1400  2014     12    7.244942   \n",
       "39641                        0.0000    3200  2014     12    8.071219   \n",
       "39642                        0.5000    1700  2014     12    7.438972   \n",
       "39643                        0.2500    1300  2014     12    7.170888   \n",
       "\n",
       "       log_n_tokens_content  log_num_hrefs  log_num_self_hrefs  log_num_imgs  \\\n",
       "0                  5.393628       1.609438            1.098612      0.693147   \n",
       "1                  4.875197       2.079442            1.609438      0.000000   \n",
       "2                  6.163315       2.484907            0.000000      0.693147   \n",
       "3                  6.320768       2.079442            1.945910      0.693147   \n",
       "4                  7.017506       3.091042            3.091042      3.044522   \n",
       "...                     ...            ...                 ...           ...   \n",
       "39639              5.521461       1.609438            1.098612      0.693147   \n",
       "39640              5.416100       2.079442            2.079442      0.693147   \n",
       "39641              6.063785       1.386294            1.386294      1.386294   \n",
       "39642              6.364751       2.772589            1.098612      1.386294   \n",
       "39643              5.062595       0.693147            0.693147      0.000000   \n",
       "\n",
       "       log_num_videos  log_kw_max_min  log_kw_min_max  log_kw_avg_avg  \\\n",
       "0            0.000000        0.000000        0.000000        0.000000   \n",
       "1            0.000000        0.000000        0.000000        0.000000   \n",
       "2            0.000000        0.000000        0.000000        0.000000   \n",
       "3            0.000000        0.000000        0.000000        0.000000   \n",
       "4            0.000000        0.000000        0.000000        0.000000   \n",
       "...               ...             ...             ...             ...   \n",
       "39639        0.693147        5.384495        9.994288        7.967156   \n",
       "39640        0.693147        8.131825        7.313887        7.946497   \n",
       "39641        0.000000        7.378384        8.366603        8.083845   \n",
       "39642        0.000000        6.104793        9.752723        7.912769   \n",
       "39643        1.098612        4.584967       12.233693        8.101044   \n",
       "\n",
       "       log_self_reference_min_shares  log_self_reference_max_shares  \\\n",
       "0                           6.208590                       6.208590   \n",
       "1                           7.170888                       7.170888   \n",
       "2                           0.000000                       0.000000   \n",
       "3                           7.550135                       7.550135   \n",
       "4                           6.302619                       9.680406   \n",
       "...                              ...                            ...   \n",
       "39639                       8.071219                       9.179984   \n",
       "39640                       7.003974                       7.550135   \n",
       "39641                       7.170888                       7.170888   \n",
       "39642                       7.244942                       7.244942   \n",
       "39643                       7.650169                       7.650169   \n",
       "\n",
       "       log_self_reference_avg_sharess   share_ranges  \n",
       "0                            6.208590          <2500  \n",
       "1                            7.170888          <2500  \n",
       "2                            0.000000          <2500  \n",
       "3                            7.550135          <2500  \n",
       "4                            8.140199          <2500  \n",
       "...                               ...            ...  \n",
       "39639                        8.771990          <2500  \n",
       "39640                        7.424165          <2500  \n",
       "39641                        7.170888  >2500 & <5000  \n",
       "39642                        7.244942          <2500  \n",
       "39643                        7.650169          <2500  \n",
       "\n",
       "[39644 rows x 49 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "820f849b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39644 entries, 0 to 39643\n",
      "Data columns (total 49 columns):\n",
      " #   Column                          Non-Null Count  Dtype   \n",
      "---  ------                          --------------  -----   \n",
      " 0   timedelta                       39644 non-null  float64 \n",
      " 1   n_tokens_title                  39644 non-null  float64 \n",
      " 2   n_unique_tokens                 39644 non-null  float64 \n",
      " 3   average_token_length            39644 non-null  float64 \n",
      " 4   num_keywords                    39644 non-null  float64 \n",
      " 5   kw_min_min                      39644 non-null  float64 \n",
      " 6   kw_avg_min                      39644 non-null  float64 \n",
      " 7   kw_max_max                      39644 non-null  float64 \n",
      " 8   kw_avg_max                      39644 non-null  float64 \n",
      " 9   kw_min_avg                      39644 non-null  float64 \n",
      " 10  kw_max_avg                      39644 non-null  float64 \n",
      " 11  is_weekend                      39644 non-null  float64 \n",
      " 12  LDA_00                          39644 non-null  float64 \n",
      " 13  LDA_01                          39644 non-null  float64 \n",
      " 14  LDA_02                          39644 non-null  float64 \n",
      " 15  LDA_03                          39644 non-null  float64 \n",
      " 16  LDA_04                          39644 non-null  float64 \n",
      " 17  global_subjectivity             39644 non-null  float64 \n",
      " 18  global_sentiment_polarity       39644 non-null  float64 \n",
      " 19  global_rate_positive_words      39644 non-null  float64 \n",
      " 20  global_rate_negative_words      39644 non-null  float64 \n",
      " 21  rate_positive_words             39644 non-null  float64 \n",
      " 22  rate_negative_words             39644 non-null  float64 \n",
      " 23  avg_positive_polarity           39644 non-null  float64 \n",
      " 24  min_positive_polarity           39644 non-null  float64 \n",
      " 25  max_positive_polarity           39644 non-null  float64 \n",
      " 26  avg_negative_polarity           39644 non-null  float64 \n",
      " 27  min_negative_polarity           39644 non-null  float64 \n",
      " 28  max_negative_polarity           39644 non-null  float64 \n",
      " 29  title_subjectivity              39644 non-null  float64 \n",
      " 30  title_sentiment_polarity        39644 non-null  float64 \n",
      " 31  abs_title_subjectivity          39644 non-null  float64 \n",
      " 32  abs_title_sentiment_polarity    39644 non-null  float64 \n",
      " 33  shares                          39644 non-null  int64   \n",
      " 34  year                            39644 non-null  int64   \n",
      " 35  month                           39644 non-null  int64   \n",
      " 36  log_shares                      39644 non-null  float64 \n",
      " 37  log_n_tokens_content            39644 non-null  float64 \n",
      " 38  log_num_hrefs                   39644 non-null  float64 \n",
      " 39  log_num_self_hrefs              39644 non-null  float64 \n",
      " 40  log_num_imgs                    39644 non-null  float64 \n",
      " 41  log_num_videos                  39644 non-null  float64 \n",
      " 42  log_kw_max_min                  39644 non-null  float64 \n",
      " 43  log_kw_min_max                  39644 non-null  float64 \n",
      " 44  log_kw_avg_avg                  39644 non-null  float64 \n",
      " 45  log_self_reference_min_shares   39644 non-null  float64 \n",
      " 46  log_self_reference_max_shares   39644 non-null  float64 \n",
      " 47  log_self_reference_avg_sharess  39644 non-null  float64 \n",
      " 48  share_ranges                    39644 non-null  category\n",
      "dtypes: category(1), float64(45), int64(3)\n",
      "memory usage: 14.6 MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b3a87",
   "metadata": {},
   "source": [
    "### Next the data is split 80/20 training/testing splits to be in our machine learning models. The 80/20 split was chosen as it is a common practice in machine learning and is used to prevent overfitting. \n",
    "\n",
    "### To avoid redundancy our response variable 'share_ranges' and 'log shares' are removed from the dataset before the split. To improve the performance of our models, the data splits were scaled so that features are normalized to reduce the impact of features with large ranges of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a20bc638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timedelta', 'n_tokens_title', 'n_unique_tokens',\n",
      "       'average_token_length', 'num_keywords', 'kw_min_min', 'kw_avg_min',\n",
      "       'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg', 'is_weekend',\n",
      "       'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
      "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
      "       'global_rate_negative_words', 'rate_positive_words',\n",
      "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
      "       'max_positive_polarity', 'avg_negative_polarity',\n",
      "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
      "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
      "       'abs_title_sentiment_polarity', 'shares', 'year', 'month',\n",
      "       'log_n_tokens_content', 'log_num_hrefs', 'log_num_self_hrefs',\n",
      "       'log_num_imgs', 'log_num_videos', 'log_kw_max_min', 'log_kw_min_max',\n",
      "       'log_kw_avg_avg', 'log_self_reference_min_shares',\n",
      "       'log_self_reference_max_shares', 'log_self_reference_avg_sharess'],\n",
      "      dtype='object')\n",
      "0                <2500\n",
      "1                <2500\n",
      "2                <2500\n",
      "3                <2500\n",
      "4                <2500\n",
      "             ...      \n",
      "39639            <2500\n",
      "39640            <2500\n",
      "39641    >2500 & <5000\n",
      "39642            <2500\n",
      "39643            <2500\n",
      "Name: share_ranges, Length: 39644, dtype: category\n",
      "Categories (7, object): ['<2500' < '>2500 & <5000' < '>5000 & <7500' < '>7500 & <10000' < '>10000 & <20000' < '>20000 & <100000' < '>100000']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df1.drop(['share_ranges', 'log_shares'], axis=1)\n",
    "y = df1['share_ranges']\n",
    "print(X.columns)\n",
    "print(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Scale the features in the training and testing sets.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fa24e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check:  Check for NaNs in the dataset\n",
    "for column in df1.columns:\n",
    "    if df1[column].isnull().any():\n",
    "        print('NaNs found in column:', column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c7dc8",
   "metadata": {},
   "source": [
    "## Logistic Regression Model: \n",
    "\n",
    "### Tuning: \n",
    "### The model parameters are set below to have regularlization strength of 0.5 using the Lasso method (robust to noise, penalizes the abs value). The Stochastic Average Gradient Aggregation (saga) is used to train the logistic model with the max iterations to train the model at 10000. \n",
    "### \n",
    "\n",
    "### Model Advantages - Efficiency: \n",
    "### The models convergence rate was ~3 minutes. This is fast indicating our model is not all that complex. \n",
    "\n",
    "### Model Advantages - Performance\n",
    "### The logistic model performed well with an accuracy score of 0.9236978181359566. This is quite good compared to our other models. The model also had a relatively high precision score of 0.8666999401751474, so not too many false positives. A logistic regression recall of 0.6653267287562078 and a Logistic regression F1 score of 0.6989320153829033 are also decent metrics. Overall the model performed quite well in accurately classifying which articles were popular or not. \n",
    "\n",
    "\n",
    "### Interpret Feature Importance - Weighted Coefficients Explanation:\n",
    "### The weighted coefficients indicate that there are number of features with slight either negative or positive correlations with the response variable, however absolute subjectivity level stands out with a significant negative correlation with the response variable. This means that the more articles with higher subjective title rating are less likely to be popular. The weight for absolute subjectivity level is much larger than the other weighted coefficients which is another indication of how strong the correlation with the response variable is compared to that of other features. \n",
    "\n",
    "\n",
    "### Weights:\n",
    "#### abs_title_subjectivity has weight of -40.002251666066044 -- significant negative correlation \n",
    "#### n_tokens_title has weight of 0.04345191046903477 - a slight positive correlation \n",
    "#### kw_max_max has weight of -0.0830884140822451 - slight negative correlation \n",
    "#### kw_avg_max has weight of -0.006586796170454732 -- slight negative correlation \n",
    "#### kw_max_avg has weight of -0.0038725518653367702 -- slight negative correlation \n",
    "#### LDA_00 has weight of 0.009177095489831295 -- slight positive correlation \n",
    "#### LDA_03 has weight of -0.0020298069288597516 -- slight negative correlation \n",
    "#### rate_negative_words has weight of 0.0050291038262997275 -- slight positive correlation \n",
    "#### max_positive_polarity has weight of 0.00047534585207426207 -- slight positive correlation \n",
    "#### title_subjectivity has weight of -0.029442231869322325 -- slight negative correlation \n",
    "#### title_sentiment_polarity has weight of -0.03335660022306888 -- slight negative correlation \n",
    "#### abs_title_sentiment_polarity has weight of 0.012962789739766606 -- slight positive correlation \n",
    "#### news_category has weight of -0.012658141079296227 -- slight negative correlation \n",
    "#### log_num_hrefs has weight of 0.07071379633299095 -- slight positive correlation \n",
    "#### log_num_self_hrefs has weight of -0.041213652666091616 - slight negative correlation \n",
    "#### log_num_imgs has weight of -0.031108272502564076 -- slight negative correlation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23cccd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url_name has weight of 0.0\n",
      "date has weight of 0.0\n",
      "timedelta has weight of 0.0\n",
      "n_tokens_title has weight of 0.04345191046903477\n",
      "n_unique_tokens has weight of 0.0\n",
      "average_token_length has weight of 0.0\n",
      "num_keywords has weight of 0.0\n",
      "kw_min_min has weight of 0.0\n",
      "kw_avg_min has weight of 0.0\n",
      "kw_max_max has weight of -0.0830884140822451\n",
      "kw_avg_max has weight of -0.006586796170454732\n",
      "kw_min_avg has weight of 0.0\n",
      "kw_max_avg has weight of -0.0038725518653367702\n",
      "is_weekend has weight of 0.0\n",
      "LDA_00 has weight of 0.009177095489831295\n",
      "LDA_01 has weight of 0.0\n",
      "LDA_02 has weight of 0.0\n",
      "LDA_03 has weight of -0.0020298069288597516\n",
      "LDA_04 has weight of 0.0\n",
      "global_subjectivity has weight of 0.0\n",
      "global_sentiment_polarity has weight of 0.0\n",
      "global_rate_positive_words has weight of 0.0\n",
      "global_rate_negative_words has weight of 0.0\n",
      "rate_positive_words has weight of 0.0\n",
      "rate_negative_words has weight of 0.0050291038262997275\n",
      "avg_positive_polarity has weight of 0.0\n",
      "min_positive_polarity has weight of 0.0\n",
      "max_positive_polarity has weight of 0.00047534585207426207\n",
      "avg_negative_polarity has weight of 0.0\n",
      "min_negative_polarity has weight of 0.0\n",
      "max_negative_polarity has weight of 0.0\n",
      "title_subjectivity has weight of -0.029442231869322325\n",
      "title_sentiment_polarity has weight of -0.03335660022306888\n",
      "abs_title_subjectivity has weight of -40.002251666066044\n",
      "abs_title_sentiment_polarity has weight of 0.012962789739766606\n",
      "shares has weight of 0.0\n",
      "day_of_week has weight of 0.0\n",
      "news_category has weight of -0.012658141079296227\n",
      "year has weight of 0.0\n",
      "month has weight of 0.0\n",
      "log_shares has weight of 0.0\n",
      "log_n_tokens_content has weight of 0.0\n",
      "log_num_hrefs has weight of 0.07071379633299095\n",
      "log_num_self_hrefs has weight of -0.041213652666091616\n",
      "log_num_imgs has weight of -0.031108272502564076\n",
      "log_num_videos has weight of 0.0\n",
      "log_kw_max_min has weight of 0.0\n"
     ]
    }
   ],
   "source": [
    "# Set the model parameters.\n",
    "C = 0.05\n",
    "penalty = 'l1'\n",
    "solver = 'saga'\n",
    "max_iter=10000\n",
    "\n",
    "# Create a logistic regression model.\n",
    "logistic_regression_model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=max_iter)\n",
    "# Fit the model to the training data.\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data.\n",
    "y_pred = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Get the weights from the trained model.\n",
    "weights = logistic_regression_model.coef_.T\n",
    "\n",
    "# Print the weight of each variable.\n",
    "for weight, variable_name in zip(weights, df.columns[:-1]):\n",
    "    print(f'{variable_name} has weight of {weight[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94eecf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.9236978181359566\n",
      "Logistic regression precision: 0.8666999401751474\n",
      "Logistic regression recall: 0.6653267287562078\n",
      "Logistic regression F1 score: 0.6989320153829033\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_accuracy = accuracy_score(y_test, y_pred)\n",
    "logistic_regression_precision = precision_score(y_test, y_pred, average='macro')\n",
    "logistic_regression_recall = recall_score(y_test, y_pred, average='macro')\n",
    "logistic_regression_f1_score = f1_score(y_test, y_pred, average='macro')\n",
    "# logistic_regression_roc_auc_score = roc_curve(y_test, y_pred[:, 1])\n",
    "\n",
    "\n",
    "# Print the metrics.\n",
    "print('Logistic regression accuracy:', logistic_regression_accuracy)\n",
    "print('Logistic regression precision:', logistic_regression_precision)\n",
    "print('Logistic regression recall:', logistic_regression_recall)\n",
    "print('Logistic regression F1 score:', logistic_regression_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86202381",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model:\n",
    "\n",
    "### Tuning: \n",
    "### The model parameters are set below to have regularlization strength of 1.0, a linear kernal is used to train the SVM with the gamma set to 0.1 to avoid overfitting (a higher gamma more prone to overfitting as makes the decision boundary more complex). \n",
    "\n",
    "### Model Advantages - Efficiency: \n",
    "### The models convergence rate was ~14.4 seconds. This is fast indicating our model is not complex.  \n",
    "\n",
    "### Model Advantages - Performance\n",
    "### The logistic model performed extremely well with an accuracy score of 0.9860007567158532. This is quite good better than the logistic regression model. The model also had a high precision score of 0.9552859295192899, so not too many false positives. A logistic regression recall of 0.9381806456213155 and a Logistic regression F1 score of 0.9463855789589289 are also good metrics. Overall the model performed very well in accurately classifying which articles were popular or not. \n",
    "\n",
    "### Interpret Feature Importance - Weighted Coefficients Explanation:\n",
    "### Just as in the previous logistic regression model, the SVM weighted coefficients indicate that there are number of features with slight either negative or positive correlations with the response variable, however absolute subjectivity level stands out with a negative correlation with the response variable. This means that the more articles with higher subjective title rating are less likely to be popular. The weight for absolute subjectivity level is much larger than the other weighted coefficients which is another indication of how strong the correlation with the response variable is compared to that of other features.\n",
    "\n",
    "### Weights: \n",
    "#### abs_title_subjectivity has weight of -3.2124239921622424 -- negative correlation\n",
    "#### url_name has weight of -0.0002477970466832069 -- slight negative correlation \n",
    "#### date has weight of -4.39394437103946e-05 -- slight negative correlation \n",
    "#### timedelta has weight of -0.0191769821289276 -- slight negative correlation \n",
    "#### n_tokens_title has weight of 4.493937662020109e-05 -- slight positive correlation \n",
    "#### n_unique_tokens has weight of 1.5327936830900057e-05 -- slight positive correlation \n",
    "#### average_token_length has weight of 7.495918981410832e-05 -- slight negative correlation \n",
    "#### num_keywords has weight of 0.00010830315772131227 -- slight positive correlation \n",
    "#### kw_min_min has weight of -0.00012821209954989865 -- slight negative correlation \n",
    "#### kw_avg_min has weight of 7.950518713450982e-05 -- slight positive correlation \n",
    "#### kw_max_max has weight of 0.00020965278001855436 -- slight positive correlation \n",
    "#### kw_avg_max has weight of 0.00010072277917916317 -- slight positive correlation \n",
    "#### kw_min_avg has weight of -1.6646353786842205e-05 -- slight negative correlation \n",
    "#### kw_max_avg has weight of -4.983241174549846e-05 -- slight negative correlation \n",
    "#### is_weekend has weight of 5.22136165903575e-05 -- slight positive correlation \n",
    "#### LDA_00 has weight of 6.715899686149385e-06 -- slight positive correlation \n",
    "#### LDA_01 has weight of -3.15658796556928e-05 -- slight negative correlation \n",
    "#### LDA_02 has weight of 3.151243565957529e-05 -- slight positive correlation \n",
    "#### LDA_03 has weight of -4.9260978921439325e-05 -- slight negative correlation \n",
    "#### LDA_04 has weight of 1.984912670766059e-05 -- slight positive correlation \n",
    "#### global_subjectivity has weight of 3.9704001419726964e-05 -- slight positive correlation \n",
    "#### global_sentiment_polarity has weight of 3.0220859169177716e-05 -- slight positive correlation \n",
    "#### global_rate_positive_words has weight of 0.00116357875010481 -- slight positive correlation \n",
    "#### global_rate_negative_words has weight of 0.0009168286734000386 -- slight positive correlation \n",
    "#### rate_positive_words has weight of -6.196459336210713e-05 -- slight negative correlation \n",
    "#### rate_negative_words has weight of 8.7124657542903e-05 -- slight positive correlation \n",
    "#### avg_positive_polarity has weight of 0.00010739256754516147 -- slight positive correlation \n",
    "#### min_positive_polarity has weight of -2.555434414699964e-05 -- slight negative correlation \n",
    "#### max_positive_polarity has weight of -9.232031633643611e-05 -- slight negative correlation \n",
    "#### avg_negative_polarity has weight of 4.210584788089111e-05 -- slight negative correlation \n",
    "#### min_negative_polarity has weight of -3.960652437751122e-05 -- slight negative correlation \n",
    "#### max_negative_polarity has weight of 4.231652938280206e-06 -- slight positive correlation\n",
    "#### title_subjectivity has weight of -4.136044504865488e-05 -- slight negative correlation \n",
    "#### title_sentiment_polarity has weight of 2.041336979985431e-05 -- slight positive correlation\n",
    "#### abs_title_sentiment_polarity has weight of -0.0001411324053754992 -- slight negative correlation\n",
    "#### shares has weight of 6.559283931117932e-06 -- slight positive correlation\n",
    "#### day_of_week has weight of -0.0009180579626699714 -- slight negative correlation\n",
    "#### news_category has weight of 0.000159769646074448 -- slight positive correlation\n",
    "#### year has weight of -3.0124282420662674e-05 -- slight negative correlation\n",
    "#### month has weight of -9.601022543903603e-05 -- slight negative correlation\n",
    "#### log_shares has weight of -1.6978884219254198e-05 -- slight negative correlation\n",
    "#### log_n_tokens_content has weight of -0.0001350102171213674 -- slight negative correlation\n",
    "#### log_num_hrefs has weight of -0.00017773739868343075 -- slight negative correlation\n",
    "#### log_num_self_hrefs has weight of -8.007039585322673e-05 -- slight negative correlation\n",
    "#### log_num_imgs has weight of 0.00014782913837296796 -- slight positive correlation\n",
    "#### log_num_videos has weight of 0.0014105045214556355 -- slight positive correlation \n",
    "#### log_kw_max_min has weight of -0.0015946337719641157 -- slight negative correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c3ab1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url_name has weight of -0.0002477970466832069\n",
      "date has weight of -4.39394437103946e-05\n",
      "timedelta has weight of -0.0191769821289276\n",
      "n_tokens_title has weight of 4.493937662020109e-05\n",
      "n_unique_tokens has weight of 1.5327936830900057e-05\n",
      "average_token_length has weight of 7.495918981410832e-05\n",
      "num_keywords has weight of 0.00010830315772131227\n",
      "kw_min_min has weight of -0.00012821209954989865\n",
      "kw_avg_min has weight of 7.950518713450982e-05\n",
      "kw_max_max has weight of 0.00020965278001855436\n",
      "kw_avg_max has weight of 0.00010072277917916317\n",
      "kw_min_avg has weight of -1.6646353786842205e-05\n",
      "kw_max_avg has weight of -4.983241174549846e-05\n",
      "is_weekend has weight of 5.22136165903575e-05\n",
      "LDA_00 has weight of 6.715899686149385e-06\n",
      "LDA_01 has weight of -3.15658796556928e-05\n",
      "LDA_02 has weight of 3.151243565957529e-05\n",
      "LDA_03 has weight of -4.9260978921439325e-05\n",
      "LDA_04 has weight of 1.984912670766059e-05\n",
      "global_subjectivity has weight of 3.9704001419726964e-05\n",
      "global_sentiment_polarity has weight of 3.0220859169177716e-05\n",
      "global_rate_positive_words has weight of 0.00116357875010481\n",
      "global_rate_negative_words has weight of 0.0009168286734000386\n",
      "rate_positive_words has weight of -6.196459336210713e-05\n",
      "rate_negative_words has weight of 8.7124657542903e-05\n",
      "avg_positive_polarity has weight of 0.00010739256754516147\n",
      "min_positive_polarity has weight of -2.555434414699964e-05\n",
      "max_positive_polarity has weight of -9.232031633643611e-05\n",
      "avg_negative_polarity has weight of 4.210584788089111e-05\n",
      "min_negative_polarity has weight of -3.960652437751122e-05\n",
      "max_negative_polarity has weight of 4.231652938280206e-06\n",
      "title_subjectivity has weight of -4.136044504865488e-05\n",
      "title_sentiment_polarity has weight of 2.041336979985431e-05\n",
      "abs_title_subjectivity has weight of -3.2124239921622424\n",
      "abs_title_sentiment_polarity has weight of -0.0001411324053754992\n",
      "shares has weight of 6.559283931117932e-06\n",
      "day_of_week has weight of -0.0009180579626699714\n",
      "news_category has weight of 0.000159769646074448\n",
      "year has weight of -3.0124282420662674e-05\n",
      "month has weight of -9.601022543903603e-05\n",
      "log_shares has weight of -1.6978884219254198e-05\n",
      "log_n_tokens_content has weight of -0.0001350102171213674\n",
      "log_num_hrefs has weight of -0.00017773739868343075\n",
      "log_num_self_hrefs has weight of -8.007039585322673e-05\n",
      "log_num_imgs has weight of 0.00014782913837296796\n",
      "log_num_videos has weight of 0.0014105045214556355\n",
      "log_kw_max_min has weight of -0.0015946337719641157\n"
     ]
    }
   ],
   "source": [
    "# Set the model parameters\n",
    "C = 1.0\n",
    "# We cannot use rbf because it is a nonlinear kernal \n",
    "# kernel = 'rbf'\n",
    "kernel = 'linear'\n",
    "gamma = 0.1\n",
    "\n",
    "# Create the support vector machine model\n",
    "support_vector_machine_model = SVC(C=C, kernel=kernel, gamma=gamma)\n",
    "\n",
    "# Train the support vector machine model on the training set using a linear kernel.\n",
    "support_vector_machine_model.fit(X_train, y_train)\n",
    "# Make predictions on the test data.\n",
    "y_pred = support_vector_machine_model.predict(X_test)\n",
    "\n",
    "weights = support_vector_machine_model.coef_.T\n",
    "\n",
    "# # Print the weight of each variable.\n",
    "for weight, variable_name in zip(weights, df.columns[:-1]):\n",
    "    print(f'{variable_name} has weight of {weight[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "426fec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Support vector machine accuracy: 0.9860007567158532\n",
      "Support vector machine precision: 0.9552859295192899\n",
      "Support vector machine recall: 0.9381806456213155\n",
      "Support vector machine F1 score: 0.9463855789589289\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data.\n",
    "support_vector_machine_accuracy = accuracy_score(y_test, y_pred)\n",
    "support_vector_machine_precision = precision_score(y_test, y_pred, average='macro')\n",
    "support_vector_machine_recall = recall_score(y_test, y_pred, average='macro')\n",
    "support_vector_machine_f1_score = f1_score(y_test, y_pred, average='macro')\n",
    "# support_vector_machine_roc_auc_score = roc_auc_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Print the metrics.\n",
    "print('Support vector machine accuracy:', support_vector_machine_accuracy)\n",
    "\n",
    "print('Support vector machine precision:', support_vector_machine_precision)\n",
    "print('Support vector machine recall:', support_vector_machine_recall)\n",
    "print('Support vector machine F1 score:', support_vector_machine_f1_score)\n",
    "# print('Support vector machine ROC AUC score:', support_vector_machine_roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25042de",
   "metadata": {},
   "source": [
    "### SVM using SGD: ???? NEED TO Evaluate this section ??? SVM - SGD performed worse than the SVM model. \n",
    "\n",
    "### Tuning: \n",
    "### ### Ridge regularlization was used on teh SVM_SGD Model as Lasso shrunk all the weights to zero \n",
    "### Lasso l1, the model has weights \n",
    "### alpha 0.0001 versus 1 -- changes metrics \n",
    "\n",
    "### Model Advantages - Efficiency: \n",
    "### The models convergence rate was ~23.5 seconds. This is fast indicating our model is not complex.  \n",
    "\n",
    "### Model Advantages - Performance\n",
    "### The logistic model performed extremely well with an accuracy score of 0.814226258040106. This is quite good better than the logistic regression model. The model also had a high precision score of 0.4979519020952421, so not too many false positives. A logistic regression recall of 0.4592501273976919 and a Logistic regression F1 score of 0.45320351649627905 are also good metrics. Overall the model performed very well in accurately classifying which articles were popular or not. \n",
    "Support vector machine using SGD accuracy: 0.8122083490982469\n",
    "Support vector machine using SGD precision: 0.5037453755087606\n",
    "Support vector machine using SGD recall: 0.4628526565447935\n",
    "Support vector machine using SGD F1 score: 0.45440550615686714\n",
    "\n",
    "\n",
    "### Interpret Feature Importance - Weighted Coefficients Explanation:\n",
    "### Just as in the previous logistic regression model, the SVM weighted coefficients indicate that there are number of features with slight either negative or positive correlations with the response variable, however absolute subjectivity level stands out with a negative correlation with the response variable. This means that the more articles with higher subjective title rating are less likely to be popular. The weight for absolute subjectivity level is much larger than the other weighted coefficients which is another indication of how strong the correlation with the response variable is compared to that of other features.\n",
    "\n",
    "\n",
    "### Weights: \n",
    "#### url_name has weight of -0.22080652042033538\n",
    "#### date has weight of -0.007595301676654267\n",
    "#### timedelta has weight of -0.18988023109706784\n",
    "#### n_tokens_title has weight of 0.06180432150684208\n",
    "#### n_unique_tokens has weight of 0.002297777107482027\n",
    "#### average_token_length has weight of -0.015564282053148871\n",
    "#### num_keywords has weight of -0.01677362395921804\n",
    "#### kw_min_min has weight of -0.03574050396518777\n",
    "#### kw_avg_min has weight of 0.01284274194595419\n",
    "#### kw_max_max has weight of -0.10172491579455416\n",
    "#### kw_avg_max has weight of -0.008024281483641928\n",
    "#### kw_min_avg has weight of 0.0017795427769386198\n",
    "#### kw_max_avg has weight of 0.0052608863049452064\n",
    "#### is_weekend has weight of -0.0022931096309335196\n",
    "#### LDA_00 has weight of -0.02508134994649698\n",
    "#### LDA_01 has weight of 0.013626503563109276\n",
    "#### LDA_02 has weight of 0.008578510506548004\n",
    "#### LDA_03 has weight of -0.039078402223844\n",
    "#### LDA_04 has weight of 0.03929671710866691\n",
    "#### global_subjectivity has weight of 0.0267148363935909\n",
    "#### global_sentiment_polarity has weight of -0.04036971725499696\n",
    "#### global_rate_positive_words has weight of -0.0437937758694026\n",
    "#### global_rate_negative_words has weight of 0.0284408146367553\n",
    "#### rate_positive_words has weight of -0.010457974560344705\n",
    "#### rate_negative_words has weight of 0.009531619078503514\n",
    "#### avg_positive_polarity has weight of -0.031002443143928273\n",
    "#### min_positive_polarity has weight of -0.003814799206646656\n",
    "#### max_positive_polarity has weight of -8.004172743040603e-05\n",
    "#### avg_negative_polarity has weight of -0.003912544983939632\n",
    "#### min_negative_polarity has weight of 0.01803603316203229\n",
    "#### max_negative_polarity has weight of 0.006662030072321132\n",
    "#### title_subjectivity has weight of -0.02256924361898776\n",
    "#### title_sentiment_polarity has weight of -0.04740533717369407\n",
    "#### abs_title_subjectivity has weight of -23.79448560162115\n",
    "#### abs_title_sentiment_polarity has weight of -0.1669441901736163\n",
    "#### shares has weight of -0.12540709638301883\n",
    "#### day_of_week has weight of 0.05538718894703649\n",
    "#### news_category has weight of -0.028254025919727865\n",
    "#### year has weight of 0.01619159265421823\n",
    "#### month has weight of 0.02235037953280418\n",
    "#### log_shares has weight of 0.026116347826609695\n",
    "#### log_n_tokens_content has weight of 0.016996274710331376\n",
    "#### log_num_hrefs has weight of 0.08836445968013068\n",
    "#### log_num_self_hrefs has weight of -0.007762766267592073\n",
    "#### log_num_imgs has weight of -0.005799789526101167\n",
    "#### log_num_videos has weight of 0.1739530502727808\n",
    "#### log_kw_max_min has weight of -0.22503909337583722\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01ff3733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url_name has weight of -0.22080652042033538\n",
      "date has weight of -0.007595301676654267\n",
      "timedelta has weight of -0.18988023109706784\n",
      "n_tokens_title has weight of 0.06180432150684208\n",
      "n_unique_tokens has weight of 0.002297777107482027\n",
      "average_token_length has weight of -0.015564282053148871\n",
      "num_keywords has weight of -0.01677362395921804\n",
      "kw_min_min has weight of -0.03574050396518777\n",
      "kw_avg_min has weight of 0.01284274194595419\n",
      "kw_max_max has weight of -0.10172491579455416\n",
      "kw_avg_max has weight of -0.008024281483641928\n",
      "kw_min_avg has weight of 0.0017795427769386198\n",
      "kw_max_avg has weight of 0.0052608863049452064\n",
      "is_weekend has weight of -0.0022931096309335196\n",
      "LDA_00 has weight of -0.02508134994649698\n",
      "LDA_01 has weight of 0.013626503563109276\n",
      "LDA_02 has weight of 0.008578510506548004\n",
      "LDA_03 has weight of -0.039078402223844\n",
      "LDA_04 has weight of 0.03929671710866691\n",
      "global_subjectivity has weight of 0.0267148363935909\n",
      "global_sentiment_polarity has weight of -0.04036971725499696\n",
      "global_rate_positive_words has weight of -0.0437937758694026\n",
      "global_rate_negative_words has weight of 0.0284408146367553\n",
      "rate_positive_words has weight of -0.010457974560344705\n",
      "rate_negative_words has weight of 0.009531619078503514\n",
      "avg_positive_polarity has weight of -0.031002443143928273\n",
      "min_positive_polarity has weight of -0.003814799206646656\n",
      "max_positive_polarity has weight of -8.004172743040603e-05\n",
      "avg_negative_polarity has weight of -0.003912544983939632\n",
      "min_negative_polarity has weight of 0.01803603316203229\n",
      "max_negative_polarity has weight of 0.006662030072321132\n",
      "title_subjectivity has weight of -0.02256924361898776\n",
      "title_sentiment_polarity has weight of -0.04740533717369407\n",
      "abs_title_subjectivity has weight of -23.79448560162115\n",
      "abs_title_sentiment_polarity has weight of -0.1669441901736163\n",
      "shares has weight of -0.12540709638301883\n",
      "day_of_week has weight of 0.05538718894703649\n",
      "news_category has weight of -0.028254025919727865\n",
      "year has weight of 0.01619159265421823\n",
      "month has weight of 0.02235037953280418\n",
      "log_shares has weight of 0.026116347826609695\n",
      "log_n_tokens_content has weight of 0.016996274710331376\n",
      "log_num_hrefs has weight of 0.08836445968013068\n",
      "log_num_self_hrefs has weight of -0.007762766267592073\n",
      "log_num_imgs has weight of -0.005799789526101167\n",
      "log_num_videos has weight of 0.1739530502727808\n",
      "log_kw_max_min has weight of -0.22503909337583722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "# Set the model parameters\n",
    "alpha = 0.0001\n",
    "fit_intercept = True\n",
    "l1_ratio = 0.0\n",
    "learning_rate = 'optimal'\n",
    "loss = 'hinge' # gives a linear SVM \n",
    "n_iter_no_change = 10000\n",
    "# Ridge \n",
    "penalty = 'l2'\n",
    "# Lasso \n",
    "# penalty = 'l1'\n",
    "\n",
    "# Initialize the SVM model.\n",
    "support_vector_machine_model_sgd = SGDClassifier(alpha=alpha,fit_intercept=fit_intercept, l1_ratio=l1_ratio, learning_rate=learning_rate, loss=loss, n_iter_no_change=n_iter_no_change, penalty=penalty)\n",
    "\n",
    "# Train the support vector machine model on the training set using a linear kernel.\n",
    "support_vector_machine_model_sgd.fit(X_train, y_train)\n",
    "# Make predictions on the test data.\n",
    "y_pred = support_vector_machine_model_sgd.predict(X_test)\n",
    "\n",
    "# Get the weights from the trained model.\n",
    "weights = support_vector_machine_model_sgd.coef_.T\n",
    "\n",
    "# Print the weight of each variable.\n",
    "for weight, variable_name in zip(weights, df.columns[:-1]):\n",
    "    print(f'{variable_name} has weight of {weight[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ba6f3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Support vector machine using SGD accuracy: 0.8122083490982469\n",
      "Support vector machine using SGD precision: 0.5037453755087606\n",
      "Support vector machine using SGD recall: 0.4628526565447935\n",
      "Support vector machine using SGD F1 score: 0.45440550615686714\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data.\n",
    "support_vector_machine_accuracy_sgd = accuracy_score(y_test, y_pred)\n",
    "support_vector_machine_precision_sgd = precision_score(y_test, y_pred, average='macro')\n",
    "support_vector_machine_recall_sgd = recall_score(y_test, y_pred, average='macro')\n",
    "support_vector_machine_f1_score_sgd= f1_score(y_test, y_pred, average='macro')\n",
    "# support_vector_machine_roc_auc_score = roc_auc_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Print the metrics.\n",
    "print('Support vector machine using SGD accuracy:', support_vector_machine_accuracy_sgd)\n",
    "print('Support vector machine using SGD precision:', support_vector_machine_precision_sgd)\n",
    "print('Support vector machine using SGD recall:', support_vector_machine_recall_sgd)\n",
    "print('Support vector machine using SGD F1 score:', support_vector_machine_f1_score_sgd)\n",
    "# print('Support vector machine ROC AUC score:', support_vector_machine_roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9828cb",
   "metadata": {},
   "source": [
    "### Logistic Regression using SGD ???? NEED TO Evaluate this section and update the information here???\n",
    "\n",
    "### Tuning: \n",
    "### The model parameters are set below to have regularlization strength of 1.0, a linear kernal is used to train the SVM with the gamma set to 0.1 to avoid overfitting (a higher gamma more prone to overfitting as makes the decision boundary more complex). \n",
    "\n",
    "### Model Advantages - Efficiency: \n",
    "### The models convergence rate was ~36.7 seconds. This is fast indicating our model is not complex.  \n",
    "\n",
    "### Model Advantages - Performance\n",
    "### The logistic model performed extremely well with an accuracy score of 0.9860007567158532. This is quite good better than the logistic regression model. The model also had a high precision score of 0.9552859295192899, so not too many false positives. A logistic regression recall of 0.9381806456213155 and a Logistic regression F1 score of 0.9463855789589289 are also good metrics. Overall the model performed very well in accurately classifying which articles were popular or not. \n",
    "Logistic regression using SGD accuracy: 0.8854836675495018\n",
    "Logistic regression using SGD precision: 0.6068186224215949\n",
    "Logistic regression using SGD recall: 0.51684574036108\n",
    "Logistic regression using SGD F1 score: 0.4931996188232587\n",
    "\n",
    "### Interpret Feature Importance - Weighted Coefficients Explanation:\n",
    "### Just as in the previous logistic regression model, the SVM weighted coefficients indicate that there are number of features with slight either negative or positive correlations with the response variable, however absolute subjectivity level stands out with a negative correlation with the response variable. This means that the more articles with higher subjective title rating are less likely to be popular. The weight for absolute subjectivity level is much larger than the other weighted coefficients which is another indication of how strong the correlation with the response variable is compared to that of other features.\n",
    "\n",
    "### Weights: \n",
    "#### average_token_length has weight of 0.018883633294519746\n",
    "#### LDA_00 has weight of -0.015301510838099166\n",
    "#### global_subjectivity has weight of 0.017013692317738614\n",
    "#### title_subjectivity has weight of -0.031227404893417184\n",
    "#### abs_title_subjectivity has weight of -448.03103999522546\n",
    "#### day_of_week has weight of 0.04159595106887105\n",
    "#### log_num_imgs has weight of -0.06858863999471022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "875e7bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url_name has weight of 0.0\n",
      "date has weight of 0.0\n",
      "timedelta has weight of 0.0\n",
      "n_tokens_title has weight of 0.0\n",
      "n_unique_tokens has weight of 0.0\n",
      "average_token_length has weight of 0.018883633294519746\n",
      "num_keywords has weight of 0.0\n",
      "kw_min_min has weight of 0.0\n",
      "kw_avg_min has weight of 0.0\n",
      "kw_max_max has weight of 0.0\n",
      "kw_avg_max has weight of 0.0\n",
      "kw_min_avg has weight of 0.0\n",
      "kw_max_avg has weight of 0.0\n",
      "is_weekend has weight of 0.0\n",
      "LDA_00 has weight of -0.015301510838099166\n",
      "LDA_01 has weight of 0.0\n",
      "LDA_02 has weight of 0.0\n",
      "LDA_03 has weight of 0.0\n",
      "LDA_04 has weight of 0.0\n",
      "global_subjectivity has weight of 0.017013692317738614\n",
      "global_sentiment_polarity has weight of 0.0\n",
      "global_rate_positive_words has weight of 0.0\n",
      "global_rate_negative_words has weight of 0.0\n",
      "rate_positive_words has weight of 0.0\n",
      "rate_negative_words has weight of 0.0\n",
      "avg_positive_polarity has weight of 0.0\n",
      "min_positive_polarity has weight of 0.0\n",
      "max_positive_polarity has weight of 0.0\n",
      "avg_negative_polarity has weight of 0.0\n",
      "min_negative_polarity has weight of 0.0\n",
      "max_negative_polarity has weight of 0.0\n",
      "title_subjectivity has weight of -0.031227404893417184\n",
      "title_sentiment_polarity has weight of 0.0\n",
      "abs_title_subjectivity has weight of -448.03103999522546\n",
      "abs_title_sentiment_polarity has weight of 0.0\n",
      "shares has weight of 0.0\n",
      "day_of_week has weight of 0.04159595106887105\n",
      "news_category has weight of 0.0\n",
      "year has weight of 0.0\n",
      "month has weight of 0.0\n",
      "log_shares has weight of 0.0\n",
      "log_n_tokens_content has weight of 0.0\n",
      "log_num_hrefs has weight of 0.0\n",
      "log_num_self_hrefs has weight of 0.0\n",
      "log_num_imgs has weight of -0.06858863999471022\n",
      "log_num_videos has weight of 0.0\n",
      "log_kw_max_min has weight of 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "alpha = .0001\n",
    "fit_intercept = True\n",
    "l1_ratio = 0.0\n",
    "learning_rate = 'optimal'\n",
    "loss = 'log' #use log for logistic regression \n",
    "n_iter_no_change = 500\n",
    "# lasso \n",
    "penalty = 'l1'\n",
    "\n",
    "# Initialize the SVM model.\n",
    "support_vector_machine_model__log_sgd = SGDClassifier(alpha=alpha,fit_intercept=fit_intercept, l1_ratio=l1_ratio, learning_rate=learning_rate, loss=loss, n_iter_no_change=n_iter_no_change, penalty=penalty)\n",
    "\n",
    "# Train the support vector machine model on the training set using a linear kernel.\n",
    "support_vector_machine_model__log_sgd.fit(X_train, y_train)\n",
    "# Make predictions on the test data.\n",
    "y_pred = support_vector_machine_model__log_sgd.predict(X_test)\n",
    "\n",
    "# Get the weights from the trained model.\n",
    "weights = support_vector_machine_model__log_sgd.coef_.T\n",
    "\n",
    "# Print the weight of each variable.\n",
    "for weight, variable_name in zip(weights, df.columns[:-1]):\n",
    "    print(f'{variable_name} has weight of {weight[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc2237ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression using SGD accuracy: 0.8854836675495018\n",
      "Logistic regression using SGD precision: 0.6068186224215949\n",
      "Logistic regression using SGD recall: 0.51684574036108\n",
      "Logistic regression using SGD F1 score: 0.4931996188232587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_accuracy_sgd = accuracy_score(y_test, y_pred)\n",
    "logistic_regression_precision_sgd = precision_score(y_test, y_pred, average='macro')\n",
    "logistic_regression_recall_sgd = recall_score(y_test, y_pred, average='macro')\n",
    "logistic_regression_f1_score_sgd = f1_score(y_test, y_pred, average='macro')\n",
    "# logistic_regression_roc_auc_score = roc_curve(y_test, y_pred[:, 1])\n",
    "\n",
    "\n",
    "# Print the metrics.\n",
    "print('Logistic regression using SGD accuracy:', logistic_regression_accuracy_sgd)\n",
    "print('Logistic regression using SGD precision:', logistic_regression_precision_sgd)\n",
    "print('Logistic regression using SGD recall:', logistic_regression_recall_sgd)\n",
    "print('Logistic regression using SGD F1 score:', logistic_regression_f1_score_sgd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b8c9a",
   "metadata": {},
   "source": [
    "## SUBSETTING -- We need to do this section \n",
    "\n",
    "If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model— then analyze the support vectors from the subsampled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1bbd49",
   "metadata": {},
   "source": [
    "### Advantages/Disadvantages: \n",
    "### Does one model type offer superior performance in terms of prediction\n",
    "### In terms of training time or efficiency? In terms of training and efficiency the logistic regression was faster to train and had better results than the SVM model. Overall the acurracy... \n",
    "##### Accuracy: The proportion of predictions that are correct.\n",
    "\n",
    "##### Precision: The proportion of positive predictions that are correct.\n",
    "\n",
    "##### Recall: The proportion of positive examples that are correctly identified.\n",
    "\n",
    "##### ROC:\n",
    "\n",
    "#### Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8731cd2",
   "metadata": {},
   "source": [
    "### Use the weights from logistic regression to interpret the importance of different features for each classification task. Explain your interpretation in detail. Why do you think some variables are more important?\n",
    "\n",
    "\n",
    "we have this info above \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559540e4",
   "metadata": {},
   "source": [
    "### Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c99af6c",
   "metadata": {},
   "source": [
    "### Conclusion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
