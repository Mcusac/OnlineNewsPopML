{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Team Member Names\n",
    "- Name 1: Matthew D. Cusack\n",
    "- Name 2: Tim Cabaza\n",
    "- Name 3: Amy Adyanthaya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "________\n",
    "# Classification\n",
    "____\n",
    "\n",
    "## Contents\n",
    "* <a href=\"#DataPrep1\">Data Preparation Part 1</a>\n",
    "* <a href=\"#DataPrep2\">Data Preparation Part 2</a>\n",
    "* <a href=\"#ModelEval1\">Modeling and Evaluation 1</a>\n",
    "* <a href=\"#ModelEval2\">Modeling and Evaluation 2</a>\n",
    "* <a href=\"#ModelEval3\">Modeling and Evaluation 3</a>\n",
    "    * <a href=\"#RFmodel\">Random Forest Model</a>\n",
    "    * <a href=\"#KNNmodel\">KNN Model</a>\n",
    "    * <a href=\"#SVMmodel\">SVM Model</a>\n",
    "* <a href=\"#ModelEval4\">Modeling and Evaluation 4</a>\n",
    "* <a href=\"#ModelEval5\">Modeling and Evaluation 5</a>\n",
    "    * <a href=\"#TaskEval\">Comparing Task Performance Between Different Types of Models</a>\n",
    "        * <a href=\"#sqrTask\">On \"share_quantile_range\" Task</a>\n",
    "        * <a href=\"#dowTask\">On \"day_of_week\" Task</a>\n",
    "* <a href=\"#ModelEval6\">Modeling and Evaluation 6</a>\n",
    "* <a href=\"#Deployment\">Deployment</a>\n",
    "* <a href=\"#Exceptional\">Exceptional Work</a>\n",
    "    * <a href=\"#ncTask\">Comparing Task Performance Between Different Types of ModelsOn \"news_category\" Task</a>\n",
    "    * <a href=\"#ScalerEval\">Comparing the StandardScalar and QuantileTransformer Versions of The Models</a>\n",
    "        * <a href=\"#RFEval\">Random Forest Models</a>\n",
    "        * <a href=\"#KNNEval\">KNN Models</a>\n",
    "        * <a href=\"#SVMEval\">SVM Models</a>\n",
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "\n",
    "\n",
    "# Load Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# this import allows you train and test you test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# this import allows you to standardize your data, scaling so that all features have a mean of zero and a standard deviation of 1. \n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "# this import allows you to create a logistic regression model; type of machine learning model that can be used for classification tasks \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# this import allows you to create a support vector machine SVM model, a type of ML model that can be used for classification tasks. \n",
    "from sklearn.svm import SVC\n",
    "# this import allows you to perform CV on your model, a technique for evaluating the performance of a ML on unseen data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# these imports allow you to calculate various evaluation metrics for your ML model. Eval metrics are used to asses the performance of a ML on held-out test set. \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "# for testing differences with 95% confidence\n",
    "from scipy.stats import ttest_rel\n",
    "# for RandomForest models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# for KNN models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# for feature selection\n",
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_name</th>\n",
       "      <th>date</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>news_category</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>log_shares</th>\n",
       "      <th>log_n_tokens_content</th>\n",
       "      <th>log_num_hrefs</th>\n",
       "      <th>log_num_self_hrefs</th>\n",
       "      <th>log_num_imgs</th>\n",
       "      <th>log_num_videos</th>\n",
       "      <th>log_kw_max_min</th>\n",
       "      <th>log_kw_min_max</th>\n",
       "      <th>log_kw_avg_avg</th>\n",
       "      <th>log_self_reference_min_shares</th>\n",
       "      <th>log_self_reference_max_shares</th>\n",
       "      <th>log_self_reference_avg_sharess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon-instant-video-browser/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.378279</td>\n",
       "      <td>0.040005</td>\n",
       "      <td>0.041263</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>593</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>6.386879</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reeddit-reddit/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>4.546154</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.022446</td>\n",
       "      <td>0.022276</td>\n",
       "      <td>0.251465</td>\n",
       "      <td>0.681548</td>\n",
       "      <td>0.381987</td>\n",
       "      <td>0.152189</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.353939</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1300</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Tech</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>4.875197</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rage-comics-dying/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>4.759494</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.199626</td>\n",
       "      <td>0.028615</td>\n",
       "      <td>0.714611</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.542580</td>\n",
       "      <td>0.122370</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.357269</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.338889</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1100</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.003974</td>\n",
       "      <td>6.163315</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>power-matters-alliance-organization/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>5.147748</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>0.117255</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.822410</td>\n",
       "      <td>0.425089</td>\n",
       "      <td>0.128515</td>\n",
       "      <td>0.039640</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.337965</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.225794</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Tech</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.378384</td>\n",
       "      <td>6.320768</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>polaroid-android-camera/</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.424132</td>\n",
       "      <td>4.631390</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.327017</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.597981</td>\n",
       "      <td>0.506520</td>\n",
       "      <td>0.279769</td>\n",
       "      <td>0.071749</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.417055</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.212354</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>2400</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Tech</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.783641</td>\n",
       "      <td>7.017506</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.302619</td>\n",
       "      <td>9.680406</td>\n",
       "      <td>8.140199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               url_name        date  timedelta  \\\n",
       "0         amazon-instant-video-browser/  2013-01-07      731.0   \n",
       "1                       reeddit-reddit/  2013-01-07      731.0   \n",
       "2                    rage-comics-dying/  2013-01-07      731.0   \n",
       "3  power-matters-alliance-organization/  2013-01-07      731.0   \n",
       "4              polaroid-android-camera/  2013-01-07      731.0   \n",
       "\n",
       "   n_tokens_title  n_unique_tokens  average_token_length  num_keywords  \\\n",
       "0            12.0         0.663594              4.680365           5.0   \n",
       "1             8.0         0.821705              4.546154           9.0   \n",
       "2             9.0         0.608602              4.759494           7.0   \n",
       "3            10.0         0.535390              5.147748          10.0   \n",
       "4             9.0         0.424132              4.631390           8.0   \n",
       "\n",
       "   kw_min_min  kw_avg_min  kw_max_max  kw_avg_max  kw_min_avg  kw_max_avg  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   is_weekend    LDA_00    LDA_01    LDA_02    LDA_03    LDA_04  \\\n",
       "0         0.0  0.500331  0.378279  0.040005  0.041263  0.040123   \n",
       "1         0.0  0.022265  0.022446  0.022276  0.251465  0.681548   \n",
       "2         0.0  0.028575  0.199626  0.028615  0.714611  0.028572   \n",
       "3         0.0  0.020011  0.020317  0.117255  0.020007  0.822410   \n",
       "4         0.0  0.025001  0.327017  0.025001  0.025001  0.597981   \n",
       "\n",
       "   global_subjectivity  global_sentiment_polarity  global_rate_positive_words  \\\n",
       "0             0.521617                   0.092562                    0.045662   \n",
       "1             0.381987                   0.152189                    0.038462   \n",
       "2             0.542580                   0.122370                    0.063291   \n",
       "3             0.425089                   0.128515                    0.039640   \n",
       "4             0.506520                   0.279769                    0.071749   \n",
       "\n",
       "   global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "0                    0.013699             0.769231             0.230769   \n",
       "1                    0.007692             0.833333             0.166667   \n",
       "2                    0.025316             0.714286             0.285714   \n",
       "3                    0.012613             0.758621             0.241379   \n",
       "4                    0.013453             0.842105             0.157895   \n",
       "\n",
       "   avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "0               0.378636               0.100000                    0.7   \n",
       "1               0.353939               0.033333                    0.7   \n",
       "2               0.357269               0.050000                    0.6   \n",
       "3               0.337965               0.050000                    0.7   \n",
       "4               0.417055               0.100000                    1.0   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.350000                   -0.6                 -0.200   \n",
       "1              -0.400000                   -0.4                 -0.400   \n",
       "2              -0.338889                   -1.0                 -0.050   \n",
       "3              -0.225794                   -0.4                 -0.125   \n",
       "4              -0.212354                   -0.5                 -0.050   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0            0.500000                   -0.1875                0.000000   \n",
       "1            0.250000                    0.2000                0.250000   \n",
       "2            0.650000                   -0.5000                0.150000   \n",
       "3            0.500000                   -0.1000                0.000000   \n",
       "4            0.333333                    0.2500                0.166667   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares day_of_week  news_category  year  \\\n",
       "0                        0.1875     593      Monday  Entertainment  2013   \n",
       "1                        0.2000    1300      Monday           Tech  2013   \n",
       "2                        0.5000    1100      Monday  Uncategorized  2013   \n",
       "3                        0.1000    1600      Monday           Tech  2013   \n",
       "4                        0.2500    2400      Monday           Tech  2013   \n",
       "\n",
       "   month  log_shares  log_n_tokens_content  log_num_hrefs  log_num_self_hrefs  \\\n",
       "0      1    6.386879              5.393628       1.609438            1.098612   \n",
       "1      1    7.170888              4.875197       2.079442            1.609438   \n",
       "2      1    7.003974              6.163315       2.484907            0.000000   \n",
       "3      1    7.378384              6.320768       2.079442            1.945910   \n",
       "4      1    7.783641              7.017506       3.091042            3.091042   \n",
       "\n",
       "   log_num_imgs  log_num_videos  log_kw_max_min  log_kw_min_max  \\\n",
       "0      0.693147             0.0             0.0             0.0   \n",
       "1      0.000000             0.0             0.0             0.0   \n",
       "2      0.693147             0.0             0.0             0.0   \n",
       "3      0.693147             0.0             0.0             0.0   \n",
       "4      3.044522             0.0             0.0             0.0   \n",
       "\n",
       "   log_kw_avg_avg  log_self_reference_min_shares  \\\n",
       "0             0.0                       6.208590   \n",
       "1             0.0                       7.170888   \n",
       "2             0.0                       0.000000   \n",
       "3             0.0                       7.550135   \n",
       "4             0.0                       6.302619   \n",
       "\n",
       "   log_self_reference_max_shares  log_self_reference_avg_sharess  \n",
       "0                       6.208590                        6.208590  \n",
       "1                       7.170888                        7.170888  \n",
       "2                       0.000000                        0.000000  \n",
       "3                       7.550135                        7.550135  \n",
       "4                       9.680406                        8.140199  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "# file path\n",
    "file_path = \"../1 - Visualization and Data Preprocessing/Data/ONPClean2.csv\" # previously cleaned\n",
    "# file_path = '../1 - Visualization and Data Preprocessing/Data/OnlineNewsPopularity.csv' # unclean\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Set the maximum number of columns to display to None\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"DataPrep1\"></a>\n",
    "# Data Preparation Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39644 entries, 0 to 39643\n",
      "Data columns (total 52 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   url_name                        39644 non-null  object \n",
      " 1   date                            39644 non-null  object \n",
      " 2   timedelta                       39644 non-null  float64\n",
      " 3   n_tokens_title                  39644 non-null  float64\n",
      " 4   n_unique_tokens                 39644 non-null  float64\n",
      " 5   average_token_length            39644 non-null  float64\n",
      " 6   num_keywords                    39644 non-null  float64\n",
      " 7   kw_min_min                      39644 non-null  float64\n",
      " 8   kw_avg_min                      39644 non-null  float64\n",
      " 9   kw_max_max                      39644 non-null  float64\n",
      " 10  kw_avg_max                      39644 non-null  float64\n",
      " 11  kw_min_avg                      39644 non-null  float64\n",
      " 12  kw_max_avg                      39644 non-null  float64\n",
      " 13  is_weekend                      39644 non-null  float64\n",
      " 14  LDA_00                          39644 non-null  float64\n",
      " 15  LDA_01                          39644 non-null  float64\n",
      " 16  LDA_02                          39644 non-null  float64\n",
      " 17  LDA_03                          39644 non-null  float64\n",
      " 18  LDA_04                          39644 non-null  float64\n",
      " 19  global_subjectivity             39644 non-null  float64\n",
      " 20  global_sentiment_polarity       39644 non-null  float64\n",
      " 21  global_rate_positive_words      39644 non-null  float64\n",
      " 22  global_rate_negative_words      39644 non-null  float64\n",
      " 23  rate_positive_words             39644 non-null  float64\n",
      " 24  rate_negative_words             39644 non-null  float64\n",
      " 25  avg_positive_polarity           39644 non-null  float64\n",
      " 26  min_positive_polarity           39644 non-null  float64\n",
      " 27  max_positive_polarity           39644 non-null  float64\n",
      " 28  avg_negative_polarity           39644 non-null  float64\n",
      " 29  min_negative_polarity           39644 non-null  float64\n",
      " 30  max_negative_polarity           39644 non-null  float64\n",
      " 31  title_subjectivity              39644 non-null  float64\n",
      " 32  title_sentiment_polarity        39644 non-null  float64\n",
      " 33  abs_title_subjectivity          39644 non-null  float64\n",
      " 34  abs_title_sentiment_polarity    39644 non-null  float64\n",
      " 35  shares                          39644 non-null  int64  \n",
      " 36  day_of_week                     39644 non-null  object \n",
      " 37  news_category                   39644 non-null  object \n",
      " 38  year                            39644 non-null  int64  \n",
      " 39  month                           39644 non-null  int64  \n",
      " 40  log_shares                      39644 non-null  float64\n",
      " 41  log_n_tokens_content            39644 non-null  float64\n",
      " 42  log_num_hrefs                   39644 non-null  float64\n",
      " 43  log_num_self_hrefs              39644 non-null  float64\n",
      " 44  log_num_imgs                    39644 non-null  float64\n",
      " 45  log_num_videos                  39644 non-null  float64\n",
      " 46  log_kw_max_min                  39644 non-null  float64\n",
      " 47  log_kw_min_max                  39644 non-null  float64\n",
      " 48  log_kw_avg_avg                  39644 non-null  float64\n",
      " 49  log_self_reference_min_shares   39644 non-null  float64\n",
      " 50  log_self_reference_max_shares   39644 non-null  float64\n",
      " 51  log_self_reference_avg_sharess  39644 non-null  float64\n",
      "dtypes: float64(45), int64(3), object(4)\n",
      "memory usage: 15.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original (before any cleaning):\n",
    "url:        \n",
    "    Containes the url of the article with the date      \n",
    "    Object\n",
    "\n",
    "timedelta:               \n",
    "    Days between the article publication and the dataset acquisition (non-predictive)               \n",
    "    float64\n",
    "\n",
    "n_tokens_title:               \n",
    "    Number of words in the title               \n",
    "    float64\n",
    "\n",
    "n_tokens_content:               \n",
    "    Number of words in the content               \n",
    "    float64\n",
    "\n",
    "n_unique_tokens:               \n",
    "    Rate of unique words in the content               \n",
    "    float64\n",
    "\n",
    "n_non_stop_words:           \n",
    "    Rate of non-stop words in the content           \n",
    "    float64\n",
    "\n",
    "n_non_stop_unique_tokens:      \n",
    "    Rate of unique non-stop words in the content      \n",
    "    float64\n",
    "\n",
    "num_hrefs:                    \n",
    "    Number of links                 \n",
    "    float64\n",
    "\n",
    "num_self_hrefs:               \n",
    "    Number of links to other articles published by Mashable            \n",
    "    float64\n",
    "\n",
    "num_imgs:                      \n",
    "    Number of images        \n",
    "    float64\n",
    "\n",
    "num_videos:                    \n",
    "    Number of videos            \n",
    "    float64\n",
    "    \n",
    "average_token_length:               \n",
    "    Average length of the words in the content               \n",
    "    Float64\n",
    "\n",
    "num_keywords:               \n",
    "    Number of keywords in the metadata               \n",
    "    float64\n",
    "\n",
    "data_channel_is_lifestyle:     \n",
    "    Is data channel 'Lifestyle'?            \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    "\n",
    "data_channel_is_entertainment:          \n",
    "    Is data channel 'Entertainment'?            \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    "\n",
    "data_channel_is_bus:           \n",
    "    Is data channel 'Business'?         \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    "  \n",
    "data_channel_is_socmed:        \n",
    "    Is data channel 'Social Media'?             \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    "   \n",
    "data_channel_is_tech:          \n",
    "    Is data channel 'Tech'?             \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    " \n",
    "data_channel_is_world:         \n",
    "    Is data channel 'World'?        \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    " \n",
    "kw_min_min:               \n",
    "    Worst keyword (min. shares)               \n",
    "    float64\n",
    "\n",
    "kw_max_min:                    \n",
    "    Worst keyword (max. shares)         \n",
    "    float64\n",
    "\n",
    "kw_avg_min:                    \n",
    "    Worst keyword (avg. shares)               \n",
    "    float64\n",
    "\n",
    "kw_min_max:                    \n",
    "    Best keyword (min. shares)          \n",
    "    float64\n",
    "\n",
    "kw_max_max:                    \n",
    "    Best keyword (max. shares)               \n",
    "    float64\n",
    "\n",
    "kw_avg_max:                    \n",
    "    Best keyword (avg. shares)               \n",
    "    float64\n",
    "\n",
    "kw_min_avg:                    \n",
    "    Avg. keyword (min. shares)               \n",
    "    float64\n",
    "\n",
    "kw_max_avg:                    \n",
    "    Avg. keyword (max. shares)               \n",
    "    float64\n",
    "\n",
    "kw_avg_avg:                    \n",
    "    Avg. keyword (avg. shares)          \n",
    "    float64\n",
    "\n",
    "self_reference_min_shares:    \n",
    "    Min. shares of referenced articles in Mashable          \n",
    "    float64\n",
    "\n",
    "self_reference_max_shares:     \n",
    "    Max. shares of referenced articles in Mashable          \n",
    "    float64\n",
    "\n",
    "self_reference_avg_sharess:   \n",
    "    Avg. shares of referenced articles in Mashable          \n",
    "    float64\n",
    "\n",
    "weekday_is_monday:             \n",
    "    Was the article published on a Monday?          \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    "\n",
    "weekday_is_tuesday:            \n",
    "    Was the article published on a Tuesday?             \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    "\n",
    "weekday_is_wednesday:          \n",
    "    Was the article published on a Wednesday?               \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    "\n",
    "weekday_is_thursday:           \n",
    "    Was the article published on a Thursday?            \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    "\n",
    "weekday_is_friday:             \n",
    "    Was the article published on a Friday?          \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    "\n",
    "weekday_is_saturday:           \n",
    "    Was the article published on a Saturday?            \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    "\n",
    "weekday_is_sunday:              \n",
    "    Was the article published on a Sunday?          \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    "\n",
    "is_weekend:                    \n",
    "    Was the article published on the weekend?               \n",
    "    Binary (Yes = 1 / No = 0)       \n",
    "    float64\n",
    "\n",
    "LDA_00:                        \n",
    "    LDA topic modeling \n",
    "    Closeness to LDA topic 0               \n",
    "    float64\n",
    "\n",
    "LDA_01:                       \n",
    "    Closeness to LDA topic 1               \n",
    "    float64\n",
    "\n",
    "LDA_02:                        \n",
    "    Closeness to LDA topic 2               \n",
    "    float64\n",
    "\n",
    "LDA_03:                       \n",
    "    Closeness to LDA topic 3               \n",
    "    float64\n",
    "\n",
    "LDA_04:                        \n",
    "    Closeness to LDA topic 4               \n",
    "    float64\n",
    "\n",
    "global_subjectivity:           \n",
    "    Text subjectivity               \n",
    "    float64\n",
    "\n",
    "global_sentiment_polarity:     \n",
    "    Text sentiment polarity               \n",
    "    float64\n",
    "\n",
    "global_rate_positive_words:    \n",
    "    Rate of positive words in the content               \n",
    "    float64\n",
    "\n",
    "global_rate_negative_words:    \n",
    "    Rate of negative words in the content               \n",
    "    float64\n",
    "\n",
    "rate_positive_words:           \n",
    "    Rate of positive words among non-neutral tokens               \n",
    "    float64\n",
    "\n",
    "rate_negative_words:           \n",
    "    Rate of negative words among non-neutral tokens               \n",
    "    float64\n",
    "\n",
    "avg_positive_polarity:         \n",
    "    Avg. polarity of positive words               \n",
    "    float64\n",
    "\n",
    "min_positive_polarity:         \n",
    "    Min. polarity of positive words               \n",
    "    float64\n",
    "\n",
    "max_positive_polarity:         \n",
    "    Max. polarity of positive words               \n",
    "    float64\n",
    "\n",
    "avg_negative_polarity:         \n",
    "    Avg. polarity of negative  words               \n",
    "    float64\n",
    "\n",
    "min_negative_polarity:         \n",
    "    Min. polarity of negative  words               \n",
    "    float64\n",
    "\n",
    "max_negative_polarity:         \n",
    "    Max. polarity of negative  words               \n",
    "    float64\n",
    "\n",
    "title_subjectivity:            \n",
    "    Title subjectivity               \n",
    "    float64\n",
    "\n",
    "title_sentiment_polarity:      \n",
    "    Title polarity               \n",
    "    float64\n",
    "\n",
    "abs_title_subjectivity:        \n",
    "    Absolute subjectivity level               \n",
    "    float64\n",
    "\n",
    "abs_title_sentiment_polarity:  \n",
    "    Absolute polarity level               \n",
    "    float64\n",
    "\n",
    "shares:                        \n",
    "    Number of shares (target)               \n",
    "    Integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Newly Created (after preeviously cleaning & transformations):\n",
    "url_name:               \n",
    "    URL of the article (non-predictive)               \n",
    "    Float\n",
    "\n",
    "Date:               \n",
    "    The date the article was published               \n",
    "    DateTime\n",
    "\n",
    "Day_of_week:               \n",
    "    What day of the week the article is posted on               \n",
    "    Categorical\n",
    "\n",
    "news_category:               \n",
    "    What news category the article is               \n",
    "    Categorical\n",
    "\n",
    "Year:               \n",
    "    The year the article was published               \n",
    "    Integer\n",
    "\n",
    "Month:               \n",
    "    The month the aticle was published               \n",
    "    Integer\n",
    "\n",
    "log_shares:               \n",
    "    log of the \"shares\" variable               \n",
    "    Float\n",
    "\n",
    "log_n_tokens_content:               \n",
    "    log of the \"n_tokens_content\" variable               \n",
    "    Float\n",
    "\n",
    "log_num_hrefs:               \n",
    "    log of the \"num_hrefs\" variable               \n",
    "    Float\n",
    "\n",
    "log_num_self_hrefs:               \n",
    "    log of the \"num_self_hrefs\" variable               \n",
    "    Float\n",
    "\n",
    "log_num_imgs:               \n",
    "    log of the \"num_imgs\" variable               \n",
    "    Float\n",
    "\n",
    "log_num_videos:               \n",
    "    log of the \"num_videos\" variable               \n",
    "    Float\n",
    "\n",
    "log_kw_max_min:               \n",
    "    log of the \"kw_max_min\" variable               \n",
    "    Float\n",
    "\n",
    "log_kw_min_max:               \n",
    "    log of the \"kw_min_max\" variable               \n",
    "    Float\n",
    "\n",
    "log_kw_avg_avg:               \n",
    "    log of the \"kw_avg_avg\" variable               \n",
    "    Float\n",
    "\n",
    "log_self_reference_min_shares:               \n",
    "    log of the \"self_reference_min_shares\" variable               \n",
    "    Float\n",
    "\n",
    "log_self_reference_max_shares:               \n",
    "    log of the \"self_reference_max_shares\" variable               \n",
    "    Float\n",
    "\n",
    "log_self_reference_avg_shares:               \n",
    "    log of the \"self_reference_avg_shares\" variable               \n",
    "    Float\n",
    "\n",
    "day_of_weekX where X is the day of the week\n",
    "    a binary value meaning either Yes (1) it is day X or No (0) it is not day x\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your dataset has outliers, you may want to remove them before training your model, as outliers can skew the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>news_category</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>log_n_tokens_content</th>\n",
       "      <th>log_num_hrefs</th>\n",
       "      <th>log_num_self_hrefs</th>\n",
       "      <th>log_num_imgs</th>\n",
       "      <th>log_num_videos</th>\n",
       "      <th>log_kw_max_min</th>\n",
       "      <th>log_kw_min_max</th>\n",
       "      <th>log_kw_avg_avg</th>\n",
       "      <th>log_self_reference_min_shares</th>\n",
       "      <th>log_self_reference_max_shares</th>\n",
       "      <th>log_self_reference_avg_sharess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.378279</td>\n",
       "      <td>0.040005</td>\n",
       "      <td>0.041263</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>593</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>5.393628</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.208590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>4.546154</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.022446</td>\n",
       "      <td>0.022276</td>\n",
       "      <td>0.251465</td>\n",
       "      <td>0.681548</td>\n",
       "      <td>0.381987</td>\n",
       "      <td>0.152189</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.353939</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1300</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Tech</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>4.875197</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "      <td>7.170888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>4.759494</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.199626</td>\n",
       "      <td>0.028615</td>\n",
       "      <td>0.714611</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.542580</td>\n",
       "      <td>0.122370</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.357269</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.338889</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1100</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>6.163315</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>5.147748</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>0.117255</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.822410</td>\n",
       "      <td>0.425089</td>\n",
       "      <td>0.128515</td>\n",
       "      <td>0.039640</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.337965</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.225794</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Tech</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>6.320768</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "      <td>7.550135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.424132</td>\n",
       "      <td>4.631390</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.327017</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.597981</td>\n",
       "      <td>0.506520</td>\n",
       "      <td>0.279769</td>\n",
       "      <td>0.071749</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.417055</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.212354</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>2400</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Tech</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.017506</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.302619</td>\n",
       "      <td>9.680406</td>\n",
       "      <td>8.140199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_unique_tokens  average_token_length  \\\n",
       "0      731.0            12.0         0.663594              4.680365   \n",
       "1      731.0             8.0         0.821705              4.546154   \n",
       "2      731.0             9.0         0.608602              4.759494   \n",
       "3      731.0            10.0         0.535390              5.147748   \n",
       "4      731.0             9.0         0.424132              4.631390   \n",
       "\n",
       "   num_keywords  kw_min_min  kw_avg_min  kw_max_max  kw_avg_max  kw_min_avg  \\\n",
       "0           5.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1           9.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2           7.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3          10.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4           8.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   kw_max_avg  is_weekend    LDA_00    LDA_01    LDA_02    LDA_03    LDA_04  \\\n",
       "0         0.0         0.0  0.500331  0.378279  0.040005  0.041263  0.040123   \n",
       "1         0.0         0.0  0.022265  0.022446  0.022276  0.251465  0.681548   \n",
       "2         0.0         0.0  0.028575  0.199626  0.028615  0.714611  0.028572   \n",
       "3         0.0         0.0  0.020011  0.020317  0.117255  0.020007  0.822410   \n",
       "4         0.0         0.0  0.025001  0.327017  0.025001  0.025001  0.597981   \n",
       "\n",
       "   global_subjectivity  global_sentiment_polarity  global_rate_positive_words  \\\n",
       "0             0.521617                   0.092562                    0.045662   \n",
       "1             0.381987                   0.152189                    0.038462   \n",
       "2             0.542580                   0.122370                    0.063291   \n",
       "3             0.425089                   0.128515                    0.039640   \n",
       "4             0.506520                   0.279769                    0.071749   \n",
       "\n",
       "   global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "0                    0.013699             0.769231             0.230769   \n",
       "1                    0.007692             0.833333             0.166667   \n",
       "2                    0.025316             0.714286             0.285714   \n",
       "3                    0.012613             0.758621             0.241379   \n",
       "4                    0.013453             0.842105             0.157895   \n",
       "\n",
       "   avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "0               0.378636               0.100000                    0.7   \n",
       "1               0.353939               0.033333                    0.7   \n",
       "2               0.357269               0.050000                    0.6   \n",
       "3               0.337965               0.050000                    0.7   \n",
       "4               0.417055               0.100000                    1.0   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.350000                   -0.6                 -0.200   \n",
       "1              -0.400000                   -0.4                 -0.400   \n",
       "2              -0.338889                   -1.0                 -0.050   \n",
       "3              -0.225794                   -0.4                 -0.125   \n",
       "4              -0.212354                   -0.5                 -0.050   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0            0.500000                   -0.1875                0.000000   \n",
       "1            0.250000                    0.2000                0.250000   \n",
       "2            0.650000                   -0.5000                0.150000   \n",
       "3            0.500000                   -0.1000                0.000000   \n",
       "4            0.333333                    0.2500                0.166667   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares day_of_week  news_category  year  \\\n",
       "0                        0.1875     593      Monday  Entertainment  2013   \n",
       "1                        0.2000    1300      Monday           Tech  2013   \n",
       "2                        0.5000    1100      Monday  Uncategorized  2013   \n",
       "3                        0.1000    1600      Monday           Tech  2013   \n",
       "4                        0.2500    2400      Monday           Tech  2013   \n",
       "\n",
       "   month  log_n_tokens_content  log_num_hrefs  log_num_self_hrefs  \\\n",
       "0      1              5.393628       1.609438            1.098612   \n",
       "1      1              4.875197       2.079442            1.609438   \n",
       "2      1              6.163315       2.484907            0.000000   \n",
       "3      1              6.320768       2.079442            1.945910   \n",
       "4      1              7.017506       3.091042            3.091042   \n",
       "\n",
       "   log_num_imgs  log_num_videos  log_kw_max_min  log_kw_min_max  \\\n",
       "0      0.693147             0.0             0.0             0.0   \n",
       "1      0.000000             0.0             0.0             0.0   \n",
       "2      0.693147             0.0             0.0             0.0   \n",
       "3      0.693147             0.0             0.0             0.0   \n",
       "4      3.044522             0.0             0.0             0.0   \n",
       "\n",
       "   log_kw_avg_avg  log_self_reference_min_shares  \\\n",
       "0             0.0                       6.208590   \n",
       "1             0.0                       7.170888   \n",
       "2             0.0                       0.000000   \n",
       "3             0.0                       7.550135   \n",
       "4             0.0                       6.302619   \n",
       "\n",
       "   log_self_reference_max_shares  log_self_reference_avg_sharess  \n",
       "0                       6.208590                        6.208590  \n",
       "1                       7.170888                        7.170888  \n",
       "2                       0.000000                        0.000000  \n",
       "3                       7.550135                        7.550135  \n",
       "4                       9.680406                        8.140199  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "\n",
    "# Remove certain columns before dimensionality reduction can take place\n",
    "\n",
    "# drop certain columns\n",
    "df1 = df.drop('url_name', axis=1) # was a string and not helpful\n",
    "df1 = df1.drop('date', axis=1) # datetime change didn't work.\n",
    "df1 = df1.drop('log_shares', axis=1) # not as useful\n",
    "\n",
    "#Factor columns that need it for certain models\n",
    "# Factor the `news_category` column for other two tasks.\n",
    "# df1 = pd.get_dummies(df1, drop_first=False,columns=['news_category'])\n",
    "\n",
    "# Factor the `day_of_week` column for other two tasks.\n",
    "# df1 = pd.get_dummies(df1, columns=['day_of_week'], drop_first=False)\n",
    "\n",
    "# drop Na's\n",
    "df1.dropna()\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 \n",
    "\n",
    "# Create share_quantile_ranges_variable for target\n",
    "\n",
    "# Create bins using quantiles\n",
    "q1 = df1['shares'].quantile(0.25)\n",
    "q2 = df1['shares'].quantile(0.5)\n",
    "q3 = df1['shares'].quantile(0.75)\n",
    "\n",
    "# Define the bin labels\n",
    "labels = ['<Q1', 'Q1-Q2', 'Q2-Q3', '>Q3']\n",
    "\n",
    "# Cut the shares column into bins\n",
    "df1['share_quantile_ranges'] = pd.cut(df1['shares'], bins=[0, q1, q2, q3, 1000000], labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Initially a 80/20 test split was used for modeling our data but a Stratified Kfold was ultimately chosen as the more appropriate method as you will see in the next few cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timedelta', 'n_tokens_title', 'n_unique_tokens',\n",
      "       'average_token_length', 'num_keywords', 'kw_min_min', 'kw_avg_min',\n",
      "       'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg', 'is_weekend',\n",
      "       'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
      "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
      "       'global_rate_negative_words', 'rate_positive_words',\n",
      "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
      "       'max_positive_polarity', 'avg_negative_polarity',\n",
      "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
      "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
      "       'abs_title_sentiment_polarity', 'shares', 'year', 'month',\n",
      "       'log_n_tokens_content', 'log_num_hrefs', 'log_num_self_hrefs',\n",
      "       'log_num_imgs', 'log_num_videos', 'log_kw_max_min', 'log_kw_min_max',\n",
      "       'log_kw_avg_avg', 'log_self_reference_min_shares',\n",
      "       'log_self_reference_max_shares', 'log_self_reference_avg_sharess'],\n",
      "      dtype='object')\n",
      "0          <Q1\n",
      "1        Q1-Q2\n",
      "2        Q1-Q2\n",
      "3        Q2-Q3\n",
      "4        Q2-Q3\n",
      "         ...  \n",
      "39639    Q1-Q2\n",
      "39640    Q1-Q2\n",
      "39641      >Q3\n",
      "39642    Q2-Q3\n",
      "39643    Q1-Q2\n",
      "Name: share_quantile_ranges, Length: 39644, dtype: category\n",
      "Categories (4, object): ['<Q1' < 'Q1-Q2' < 'Q2-Q3' < '>Q3']\n"
     ]
    }
   ],
   "source": [
    "# 6 \n",
    "\n",
    "X = df1.drop(['share_quantile_ranges', 'day_of_week', 'news_category'], axis=1)\n",
    "y = df1['share_quantile_ranges']\n",
    "print(X.columns)\n",
    "print(y)\n",
    "\n",
    "# Training Test 80/20 Split\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 \n",
    "\n",
    "# Scale the features in the training and testing sets using standard scalar.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8\n",
    "\n",
    "# Scale the features using QuantileTransformer with n_quantiles=100 AFTER using StandardScalar().\n",
    "quantile_transformer = QuantileTransformer(n_quantiles=100)\n",
    "\n",
    "X_train_q = quantile_transformer.fit_transform(X_train)\n",
    "X_test_q = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling is done on the training and testing sets \"X_train\" and \"X_test\" in order put the data on a common scale. This is helpful in improving the model performance as they  arre sensitive to the scale of the data. Scaling will be done for each classification task and both types of scaling will be done on the data seperately so that the two methods can be compared later.\n",
    "\n",
    "\n",
    "#### Overall scaling is important for some model types. Random forest classification models are powerful and are completely invariant to the scaling of data. SVMs on the other hand are sensitive to the scaling of data; for kernal SVMs it is common to scale the data between 0 and 1 for all features. KNN is also sensitive to scaling as KNN chooses the k closest neighbor and then based off those neighbors assigns a class. KNN is a distance based algorithm that is sensitive to the magnitudes of the features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following variables within the Mashable datatset were deemed unnecessary during lab 1 and were removed during the course of this labs notebook.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Url:        \n",
    "    Dropped as it was better served being split into multiple variables.            \n",
    "    These varriables did end up not being useful or useable, however.  \n",
    "\n",
    "n_tokens_content:           \n",
    "    was removed after being log transformed.            \n",
    "    This helped with the very skewed data.\n",
    "\n",
    "n_non_stop_words:              \n",
    "    Deemed unhelpful\n",
    "\n",
    "n_non_stop_unique_tokens:           \n",
    "    Deemed unhelpful\n",
    "\n",
    "num_hrefs:          \n",
    "    was removed after being log transformed.            \n",
    "    This helped with the very skewed data.\n",
    "\n",
    "num_self_hrefs:         \n",
    "    was removed after being log transformed.            \n",
    "    This helped with the very skewed data.\n",
    "    \n",
    "num_imgs:           \n",
    "    was removed after being log transformed.            \n",
    "    This helped with the very skewed data.\n",
    "\n",
    "num_videos:         \n",
    "    was removed after being log transformed.            \n",
    "    This helped with the very skewed data.\n",
    "\n",
    "kw_max_min:         \n",
    "    was removed after being log transformed.            \n",
    "    This helped with the very skewed data.\n",
    "\n",
    "kw_min_max:         \n",
    "    was removed after being log transformed.            \n",
    "    This helped with the very skewed data.\n",
    "\n",
    "self_reference_min_shares:          \n",
    "    was removed after being log transformed.            \n",
    "    This helped with the very skewed data.\n",
    "\n",
    "self_reference_max_shares:          \n",
    "    was removed after being log transformed.            \n",
    "    This helped with the very skewed data.\n",
    "\n",
    "self_reference_avg_sharess:             \n",
    "    was removed after being log transformed.            \n",
    "    This helped with the very skewed data.\n",
    "\n",
    "weekday_is_X where X is the day of the week:        \n",
    "    Removed previously.         \n",
    "    This was to turn it into a categorical variable for the model being run at the time.        \n",
    "    This variable has been recreated for our current classification problems as shown above with the factoring of day_of_week.      \n",
    "\n",
    "data_channel_is_X where X is the type of data channel:      \n",
    "    Removed previously.     \n",
    "    This was to turn it into a categorical variable for the model being run at the time.        \n",
    "    This variable has been recreated for our current classification problems as shown above with the factoring of news_category.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "\n",
    "# The following variables were removed in lab1 when we first worked with the Mashable dataset\n",
    "\n",
    "# drop certain columns\n",
    "# Done above\n",
    "# df1 = df.drop('url_name', axis=1) # was a string\n",
    "# df1 = df1.drop('date', axis=1) # datetime change didn't work.\n",
    "# df1 = df1.drop('log_shares', axis=1) # not useful\n",
    "\n",
    "# drop Na's\n",
    "df1.dropna()\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url_name:           \n",
    "    Dropped due to it being a string variable that wasn't useful\n",
    "\n",
    "date:\n",
    "    Dropped due to it being a datetime variable that wasn't useful\n",
    "\n",
    "log_shares:           \n",
    "    The share_quantile_ranges was deemed to be more useful.\n",
    "\n",
    "A sanity check was completed to make sure no Na's were captured in the dataset. The dataset was clean with no Na's \n",
    "\n",
    "The following features will be excluded when selecting the target variable for our modeling: shares, day_of_week, and news_category. Variables that are highly correlated with the target variable will create modeling results that are overly optimistic and by strategically eliminating them we avoid overfitting by giving the model the correct answer to what its trying to predict.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "\n",
    "\n",
    "# Load the data\n",
    "X = df1.drop(['share_quantile_ranges', 'shares', 'day_of_week', 'news_category'], axis=1) \n",
    "y = df1['share_quantile_ranges']\n",
    "\n",
    "# Initialize the sequential feature selector\n",
    "sfs = SequentialFeatureSelector(estimator=LogisticRegression(), scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the selector to the data\n",
    "sfs.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = sfs.get_support(indices=True)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_feature_names = X.columns[selected_features]\n",
    "\n",
    "# Print the column names of the selected features\n",
    "print(selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using feature selection with a LogisticRegression estimator several variables were able to be removed. The following variables were deemed unimportant to the model:\n",
    "\n",
    "    'timedelta'\n",
    "    'n_tokens_title'\n",
    "    'average_token_length'   \n",
    "    'num_keywords'\n",
    "    'kw_min_min'\n",
    "    'kw_avg_min'\n",
    "    'kw_max_max'\n",
    "    'kw_avg_max' \n",
    "    'kw_min_avg'\n",
    "    'kw_max_avg'\n",
    "    'LDA_00'\n",
    "    'LDA_04'\n",
    "    'global_sentiment_polarity'\n",
    "    'rate_negative_words'\n",
    "    'title_subjectivity'\n",
    "    'shares'\n",
    "    'month'\n",
    "    'log_n_tokens_content'\n",
    "    'log_num_hrefs'  \n",
    "    'log_num_self_hrefs'\n",
    "    'log_num_imgs'\n",
    "    'log_num_videos'\n",
    "    'log_kw_max_min'\n",
    "    'log_self_reference_min_shares'\n",
    "\n",
    "##### Using feature selection with a LogisticRegression estimator the following variables were deemed most important to the model:\n",
    "    'n_unique_tokens'\n",
    "    'is_weekend'\n",
    "    'LDA_01'\n",
    "    'LDA_02'\n",
    "    'LDA_03'\n",
    "    'global_subjectivity'\n",
    "    'global_rate_positive_words'\n",
    "    'global_rate_negative_words'\n",
    "    'rate_positive_words'\n",
    "    'avg_positive_polarity\n",
    "    'min_positive_polarity'\n",
    "    'max_positive_polarity'\n",
    "    'avg_negative_polarity'\n",
    "    'min_negative_polarity'\n",
    "    'max_negative_polarity'\n",
    "    'title_sentiment_polarity'\n",
    "    'abs_title_subjectivity'\n",
    "    'abs_title_sentiment_polarity\n",
    "    'year'\n",
    "    'log_kw_min_max'\n",
    "    'log_kw_avg_avg'\n",
    "    'log_self_reference_max_shares'\n",
    "    'log_self_reference_avg_sharess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11\n",
    "\n",
    "\n",
    "# Load the data\n",
    "X = df1.drop(['share_quantile_ranges', 'shares', 'day_of_week', 'news_category'], axis=1) \n",
    "y = df1['share_quantile_ranges']\n",
    "\n",
    "# Initialize the sequential feature selector\n",
    "sfs = SequentialFeatureSelector(estimator=RandomForestClassifier(), scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the selector to the data\n",
    "sfs.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = sfs.get_support(indices=True)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_feature_names = X.columns[selected_features]\n",
    "\n",
    "# Print the column names of the selected features\n",
    "print(selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using feature selection with a RandomForest estimator several variables were able to be removed. The following variables were deemed unimportant to the model:\n",
    "\n",
    "    'timedelta'\n",
    "    'n_tokens_title'\n",
    "    'average_token_length'\n",
    "    'kw_min_min'\n",
    "    'kw_max_max'\n",
    "    'kw_avg_max'\n",
    "    'kw_max_avg'\n",
    "    'LDA_01'\n",
    "    'LDA_02'\n",
    "    'global_rate_negative_words'\n",
    "    'rate_positive_words'\n",
    "    'rate_negative_words'\n",
    "    'min_positive_polarity'\n",
    "    'avg_negative_polarity'\n",
    "    'min_negative_polarity'\n",
    "    'max_negative_polarity'\n",
    "    'title_sentiment_polarity'\n",
    "    'abs_title_subjectivity'\n",
    "    'shares'\n",
    "    'year'\n",
    "    'month'\n",
    "    'log_num_videos'\n",
    "    'log_kw_min_max'\n",
    "    'log_self_reference_max_shares'\n",
    "\n",
    "##### Using feature selection with a RandomForest estimator the following variables were deemed most important to the model:\n",
    "    'n_unique_tokens'\n",
    "    'num_keywords'\n",
    "    'kw_avg_min'\n",
    "    'kw_min_avg'\n",
    "    'is_weekend'\n",
    "    'LDA_00'\n",
    "    'LDA_03'\n",
    "    'LDA_04'\n",
    "    'global_subjectivity'\n",
    "    'global_sentiment_polarity'\n",
    "    'global_rate_positive_words'\n",
    "    'avg_positive_polarity'\n",
    "    'max_positive_polarity'\n",
    "    'title_subjectivity'\n",
    "    'abs_title_sentiment_polarity'\n",
    "    'log_n_tokens_content'\n",
    "    'log_num_hrefs'\n",
    "    'log_num_self_hrefs'\n",
    "    'log_num_imgs'\n",
    "    'log_kw_max_min'\n",
    "    'log_kw_avg_avg'\n",
    "    'log_self_reference_min_shares'\n",
    "    'log_self_reference_avg_sharess'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 \n",
    "\n",
    "# Load the data\n",
    "X = df1.drop(['share_quantile_ranges', 'shares', 'day_of_week', 'news_category'], axis=1) \n",
    "y = df1['share_quantile_ranges']\n",
    "\n",
    "# Initialize the sequential feature selector\n",
    "sfs = SequentialFeatureSelector(estimator=KNeighborsClassifier(), scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the selector to the data\n",
    "sfs.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = sfs.get_support(indices=True)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_feature_names = X.columns[selected_features]\n",
    "\n",
    "# Print the column names of the selected features\n",
    "print(selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using feature selection with a KNN estimator several variables were able to be removed. The following variables were deemed unimportant to the model:\n",
    "\n",
    "    'timedelta'\n",
    "    'n_tokens_title'\n",
    "    'average_token_length'\n",
    "    'num_keywords'\n",
    "    'kw_min_min'\n",
    "    'kw_avg_min'\n",
    "    'kw_max_max'\n",
    "    'kw_avg_max'\n",
    "    'kw_min_avg'\n",
    "    'kw_max_avg'\n",
    "    'max_positive_polarity'\n",
    "    'avg_negative_polarity'\n",
    "    'min_negative_polarity'\n",
    "    'title_subjectivity'\n",
    "    'title_sentiment_polarity'\n",
    "    'abs_title_subjectivity'\n",
    "    'shares'\n",
    "    'year'\n",
    "    'month'\n",
    "    'log_num_self_hrefs'\n",
    "    'log_num_imgs'\n",
    "    'log_kw_max_min'\n",
    "    'log_kw_min_max'\n",
    "    'log_self_reference_min_shares'\n",
    "\n",
    "##### Using feature selection with a KNN estimator the following variables were deemed most important to the model:\n",
    "    'n_unique_tokens'\n",
    "    'is_weekend'\n",
    "    'LDA_00'\n",
    "    'LDA_01'\n",
    "    'LDA_02'\n",
    "    'LDA_03'\n",
    "    'LDA_04'\n",
    "    'global_subjectivity'\n",
    "    'global_sentiment_polarity',\n",
    "    'global_rate_positive_words'\n",
    "    'global_rate_negative_words'\n",
    "    'rate_positive_words'\n",
    "    'rate_negative_words'\n",
    "    'avg_positive_polarity'\n",
    "    'min_positive_polarity'\n",
    "    'max_negative_polarity'\n",
    "    'abs_title_sentiment_polarity'\n",
    "    'log_n_tokens_content'\n",
    "    'log_num_hrefs'\n",
    "    'log_num_videos'\n",
    "    'log_kw_avg_avg'\n",
    "    'log_self_reference_max_shares'\n",
    "    'log_self_reference_avg_sharess'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 \n",
    "\n",
    "\n",
    "# Load the data\n",
    "X = df1.drop(['share_quantile_ranges', 'shares', 'day_of_week', 'news_category'], axis=1) \n",
    "y = df1['share_quantile_ranges']\n",
    "\n",
    "# Initialize the sequential feature selector\n",
    "sfs = SequentialFeatureSelector(estimator=SVC(C=1, kernel=\"linear\"), scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the selector to the data\n",
    "sfs.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = sfs.get_support(indices=True)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_feature_names = X.columns[selected_features]\n",
    "\n",
    "# Print the column names of the selected features\n",
    "print(selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using feature selection with a SVM estimator several variables were able to be removed. The following variables were deemed unimportant to the model:\n",
    "\n",
    "    'timedelta'\n",
    "    'n_tokens_title'\n",
    "    'n_unique_tokens'\n",
    "    'average_token_length'\n",
    "    'num_keywords'\n",
    "    'kw_min_min'\n",
    "    'kw_avg_min'\n",
    "    'kw_max_max'\n",
    "    'kw_avg_max'\n",
    "    'kw_min_avg'\n",
    "    'kw_max_avg'\n",
    "    'is_weekend'\n",
    "    'LDA_00'\n",
    "    'LDA_01'\n",
    "    'LDA_02'\n",
    "    'LDA_03'\n",
    "    'LDA_04'\n",
    "    'global_subjectivity'\n",
    "    'global_sentiment_polarity'\n",
    "    'global_rate_positive_words'\n",
    "    'global_rate_negative_words'\n",
    "    'rate_positive_words'\n",
    "    'rate_negative_words'\n",
    "    'avg_positive_polarity'\n",
    "    'min_positive_polarity'\n",
    "    'max_positive_polarity'\n",
    "    'avg_negative_polarity'\n",
    "    'min_negative_polarity'\n",
    "    'max_negative_polarity'\n",
    "    'title_subjectivity'\n",
    "    'title_sentiment_polarity'\n",
    "    'abs_title_subjectivity'\n",
    "    'abs_title_sentiment_polarity'\n",
    "    'shares'\n",
    "    'year'\n",
    "    'month'\n",
    "    'log_n_tokens_content'\n",
    "    'log_num_hrefs'\n",
    "    'log_num_self_hrefs'\n",
    "    'log_num_imgs'\n",
    "    'log_num_videos'\n",
    "    'log_kw_max_min'\n",
    "    'log_kw_min_max'\n",
    "    'log_kw_avg_avg'\n",
    "    'log_self_reference_min_shares'\n",
    "    'log_self_reference_max_shares'\n",
    "    'log_self_reference_avg_sharess'\n",
    "\n",
    "\n",
    "##### Using feature selection with a SVM estimator the following variables were deemed most important to the model:\n",
    "After 20 hours the feature selection had still not returned any results. Due to this, we will be using a mix of previous selected features to improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"DataPrep2\"></a>\n",
    "# Data Preperation Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the final dataset that is used for classification/regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### share_quantile_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1-Q2    10152\n",
      "Q2-Q3     9932\n",
      "<Q1       9930\n",
      ">Q3       9630\n",
      "Name: share_quantile_ranges, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 14 \n",
    "\n",
    "\n",
    "# # Create bins using quantiles\n",
    "# q1 = df1['shares'].quantile(0.25)\n",
    "# q2 = df1['shares'].quantile(0.5)\n",
    "# q3 = df1['shares'].quantile(0.75)\n",
    "\n",
    "# # Define the bin labels\n",
    "# labels = ['<Q1', 'Q1-Q2', 'Q2-Q3', '>Q3']\n",
    "\n",
    "# # Cut the shares column into bins\n",
    "# df1['share_quantile_ranges'] = pd.cut(df1['shares'], bins=[0, q1, q2, q3, 1000000], labels=labels)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Print the value counts of the share_ranges_quantile column\n",
    "print(df1['share_quantile_ranges'].value_counts())\n",
    "# Create bins using quantiles\n",
    "q1 = df['shares'].quantile(0.25)\n",
    "q2 = df['shares'].quantile(0.5)\n",
    "q3 = df['shares'].quantile(0.75)\n",
    "\n",
    "# Define the bin labels\n",
    "labels = ['<Q1', 'Q1-Q2', 'Q2-Q3', '>Q3']\n",
    "\n",
    "# Cut the shares column into bins\n",
    "df['share_quantile_ranges'] = pd.cut(df['shares'], bins=[0, q1, q2, q3, 1000000], labels=labels)\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.histplot(data=df, x=\"share_quantile_ranges\", discrete=True)\n",
    "plt.xticks(rotation=45)  # Adjust the rotation angle as needed\n",
    "plt.xlabel(\"share_quantile_ranges\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "share_quantile_ranges: This was created by splitting up the shares variable into bins by using its different quantile values. This allowed for a more even split among the groups. The distribution between quantiles is fairly evenwith Q1-Q2 and >Q3 having the greatest difference in count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### factoring day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 15 \n",
    "\n",
    "\n",
    "# Factor the `day_of_week` column.\n",
    "# df1 = pd.get_dummies(df1, columns=['day_of_week'])\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.histplot(data=df, x=\"day_of_week\", discrete=True)\n",
    "plt.xticks(rotation=45)  # Adjust the rotation angle as needed\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "factored day_of_week columns: day_of_week was factored back into 7 columns of 0's and 1's similar to how it was in the original dataset. The data is right skewed with the mode roughly Wednesday, Thursday. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### factoring news_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#16\n",
    "\n",
    "\n",
    "# # Factor the `news_category` column.\n",
    "# df1 = pd.get_dummies(df1, columns=['news_category'])\n",
    "# Histogram of Existing Categorical Variables before encoding \n",
    "\n",
    "# We will need to one hot encode \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.histplot(data=df, x=\"news_category\", discrete=True)\n",
    "plt.xticks(rotation=45)  # Adjust the rotation angle as needed\n",
    "plt.xlabel(\"News Category\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "factored news_category columns: day_of_week was factored back into 6 columns of 0's and 1's representative if it is that day or not similar to how it was in the original dataset. World News is the highest frequency news category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>log_n_tokens_content</th>\n",
       "      <th>log_num_hrefs</th>\n",
       "      <th>log_num_self_hrefs</th>\n",
       "      <th>log_num_imgs</th>\n",
       "      <th>log_num_videos</th>\n",
       "      <th>log_kw_max_min</th>\n",
       "      <th>log_kw_min_max</th>\n",
       "      <th>log_kw_avg_avg</th>\n",
       "      <th>log_self_reference_min_shares</th>\n",
       "      <th>log_self_reference_max_shares</th>\n",
       "      <th>log_self_reference_avg_sharess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>354.530471</td>\n",
       "      <td>10.398749</td>\n",
       "      <td>0.548216</td>\n",
       "      <td>4.548239</td>\n",
       "      <td>7.223767</td>\n",
       "      <td>26.106801</td>\n",
       "      <td>312.366967</td>\n",
       "      <td>752324.066694</td>\n",
       "      <td>259281.938083</td>\n",
       "      <td>1117.146610</td>\n",
       "      <td>5657.211151</td>\n",
       "      <td>0.130915</td>\n",
       "      <td>0.184599</td>\n",
       "      <td>0.141256</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.223770</td>\n",
       "      <td>0.234029</td>\n",
       "      <td>0.443370</td>\n",
       "      <td>0.119309</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.682150</td>\n",
       "      <td>0.287934</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>-0.259524</td>\n",
       "      <td>-0.521944</td>\n",
       "      <td>-0.107500</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.071425</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>3395.380184</td>\n",
       "      <td>2013.540939</td>\n",
       "      <td>6.615856</td>\n",
       "      <td>5.889971</td>\n",
       "      <td>2.156564</td>\n",
       "      <td>1.208878</td>\n",
       "      <td>1.116427</td>\n",
       "      <td>0.400420</td>\n",
       "      <td>6.393888</td>\n",
       "      <td>5.045209</td>\n",
       "      <td>7.976327</td>\n",
       "      <td>6.195185</td>\n",
       "      <td>6.917477</td>\n",
       "      <td>6.667697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>214.163767</td>\n",
       "      <td>2.114037</td>\n",
       "      <td>3.520708</td>\n",
       "      <td>0.844406</td>\n",
       "      <td>1.909130</td>\n",
       "      <td>69.633215</td>\n",
       "      <td>620.783887</td>\n",
       "      <td>214502.129573</td>\n",
       "      <td>135102.247285</td>\n",
       "      <td>1137.456951</td>\n",
       "      <td>6098.871957</td>\n",
       "      <td>0.337312</td>\n",
       "      <td>0.262975</td>\n",
       "      <td>0.219707</td>\n",
       "      <td>0.282145</td>\n",
       "      <td>0.295191</td>\n",
       "      <td>0.289183</td>\n",
       "      <td>0.116685</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.190206</td>\n",
       "      <td>0.156156</td>\n",
       "      <td>0.104542</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>11626.950749</td>\n",
       "      <td>0.498327</td>\n",
       "      <td>3.390683</td>\n",
       "      <td>1.255442</td>\n",
       "      <td>0.809445</td>\n",
       "      <td>0.692698</td>\n",
       "      <td>0.973755</td>\n",
       "      <td>0.680486</td>\n",
       "      <td>1.311168</td>\n",
       "      <td>4.521016</td>\n",
       "      <td>0.489467</td>\n",
       "      <td>3.076913</td>\n",
       "      <td>3.432430</td>\n",
       "      <td>3.280186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.393750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>164.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.470870</td>\n",
       "      <td>4.478404</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>141.750000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>172846.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3562.101631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>0.025012</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>0.057757</td>\n",
       "      <td>0.028384</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.306244</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.328383</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.509388</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.100319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.776304</td>\n",
       "      <td>6.461468</td>\n",
       "      <td>7.003974</td>\n",
       "      <td>6.889782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>339.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.539226</td>\n",
       "      <td>4.664082</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>235.500000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>244572.222223</td>\n",
       "      <td>1023.635611</td>\n",
       "      <td>4355.688836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>0.453457</td>\n",
       "      <td>0.119117</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.358755</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.253333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.016157</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.493754</td>\n",
       "      <td>7.244942</td>\n",
       "      <td>7.962442</td>\n",
       "      <td>7.090910</td>\n",
       "      <td>7.937732</td>\n",
       "      <td>7.696667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>542.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>4.854839</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>330980.000000</td>\n",
       "      <td>2056.781032</td>\n",
       "      <td>6019.953968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240958</td>\n",
       "      <td>0.150831</td>\n",
       "      <td>0.334218</td>\n",
       "      <td>0.375763</td>\n",
       "      <td>0.399986</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.177832</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.411428</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186905</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2800.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.575076</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6.908755</td>\n",
       "      <td>8.974745</td>\n",
       "      <td>8.189031</td>\n",
       "      <td>7.863651</td>\n",
       "      <td>8.987322</td>\n",
       "      <td>8.556606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>8.041534</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>42827.857143</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>3613.039819</td>\n",
       "      <td>298400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926994</td>\n",
       "      <td>0.925947</td>\n",
       "      <td>0.919999</td>\n",
       "      <td>0.926534</td>\n",
       "      <td>0.927191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727841</td>\n",
       "      <td>0.155488</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.044876</td>\n",
       "      <td>5.720312</td>\n",
       "      <td>4.762174</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>4.521789</td>\n",
       "      <td>12.606193</td>\n",
       "      <td>13.645079</td>\n",
       "      <td>10.682093</td>\n",
       "      <td>13.645079</td>\n",
       "      <td>13.645079</td>\n",
       "      <td>13.645079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          timedelta  n_tokens_title  n_unique_tokens  average_token_length  \\\n",
       "count  39644.000000    39644.000000     39644.000000          39644.000000   \n",
       "mean     354.530471       10.398749         0.548216              4.548239   \n",
       "std      214.163767        2.114037         3.520708              0.844406   \n",
       "min        8.000000        2.000000         0.000000              0.000000   \n",
       "25%      164.000000        9.000000         0.470870              4.478404   \n",
       "50%      339.000000       10.000000         0.539226              4.664082   \n",
       "75%      542.000000       12.000000         0.608696              4.854839   \n",
       "max      731.000000       23.000000       701.000000              8.041534   \n",
       "\n",
       "       num_keywords    kw_min_min    kw_avg_min     kw_max_max     kw_avg_max  \\\n",
       "count  39644.000000  39644.000000  39644.000000   39644.000000   39644.000000   \n",
       "mean       7.223767     26.106801    312.366967  752324.066694  259281.938083   \n",
       "std        1.909130     69.633215    620.783887  214502.129573  135102.247285   \n",
       "min        1.000000     -1.000000     -1.000000       0.000000       0.000000   \n",
       "25%        6.000000     -1.000000    141.750000  843300.000000  172846.875000   \n",
       "50%        7.000000     -1.000000    235.500000  843300.000000  244572.222223   \n",
       "75%        9.000000      4.000000    357.000000  843300.000000  330980.000000   \n",
       "max       10.000000    377.000000  42827.857143  843300.000000  843300.000000   \n",
       "\n",
       "         kw_min_avg     kw_max_avg    is_weekend        LDA_00        LDA_01  \\\n",
       "count  39644.000000   39644.000000  39644.000000  39644.000000  39644.000000   \n",
       "mean    1117.146610    5657.211151      0.130915      0.184599      0.141256   \n",
       "std     1137.456951    6098.871957      0.337312      0.262975      0.219707   \n",
       "min       -1.000000       0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000    3562.101631      0.000000      0.025051      0.025012   \n",
       "50%     1023.635611    4355.688836      0.000000      0.033387      0.033345   \n",
       "75%     2056.781032    6019.953968      0.000000      0.240958      0.150831   \n",
       "max     3613.039819  298400.000000      1.000000      0.926994      0.925947   \n",
       "\n",
       "             LDA_02        LDA_03        LDA_04  global_subjectivity  \\\n",
       "count  39644.000000  39644.000000  39644.000000         39644.000000   \n",
       "mean       0.216321      0.223770      0.234029             0.443370   \n",
       "std        0.282145      0.295191      0.289183             0.116685   \n",
       "min        0.000000      0.000000      0.000000             0.000000   \n",
       "25%        0.028571      0.028571      0.028574             0.396167   \n",
       "50%        0.040004      0.040001      0.040727             0.453457   \n",
       "75%        0.334218      0.375763      0.399986             0.508333   \n",
       "max        0.919999      0.926534      0.927191             1.000000   \n",
       "\n",
       "       global_sentiment_polarity  global_rate_positive_words  \\\n",
       "count               39644.000000                39644.000000   \n",
       "mean                    0.119309                    0.039625   \n",
       "std                     0.096931                    0.017429   \n",
       "min                    -0.393750                    0.000000   \n",
       "25%                     0.057757                    0.028384   \n",
       "50%                     0.119117                    0.039023   \n",
       "75%                     0.177832                    0.050279   \n",
       "max                     0.727841                    0.155488   \n",
       "\n",
       "       global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "count                39644.000000         39644.000000         39644.000000   \n",
       "mean                     0.016612             0.682150             0.287934   \n",
       "std                      0.010828             0.190206             0.156156   \n",
       "min                      0.000000             0.000000             0.000000   \n",
       "25%                      0.009615             0.600000             0.185185   \n",
       "50%                      0.015337             0.710526             0.280000   \n",
       "75%                      0.021739             0.800000             0.384615   \n",
       "max                      0.184932             1.000000             1.000000   \n",
       "\n",
       "       avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "count           39644.000000           39644.000000           39644.000000   \n",
       "mean                0.353825               0.095446               0.756728   \n",
       "std                 0.104542               0.071315               0.247786   \n",
       "min                 0.000000               0.000000               0.000000   \n",
       "25%                 0.306244               0.050000               0.600000   \n",
       "50%                 0.358755               0.100000               0.800000   \n",
       "75%                 0.411428               0.100000               1.000000   \n",
       "max                 1.000000               1.000000               1.000000   \n",
       "\n",
       "       avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "count           39644.000000           39644.000000           39644.000000   \n",
       "mean               -0.259524              -0.521944              -0.107500   \n",
       "std                 0.127726               0.290290               0.095373   \n",
       "min                -1.000000              -1.000000              -1.000000   \n",
       "25%                -0.328383              -0.700000              -0.125000   \n",
       "50%                -0.253333              -0.500000              -0.100000   \n",
       "75%                -0.186905              -0.300000              -0.050000   \n",
       "max                 0.000000               0.000000               0.000000   \n",
       "\n",
       "       title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "count        39644.000000              39644.000000            39644.000000   \n",
       "mean             0.282353                  0.071425                0.341843   \n",
       "std              0.324247                  0.265450                0.188791   \n",
       "min              0.000000                 -1.000000                0.000000   \n",
       "25%              0.000000                  0.000000                0.166667   \n",
       "50%              0.150000                  0.000000                0.500000   \n",
       "75%              0.500000                  0.150000                0.500000   \n",
       "max              1.000000                  1.000000                0.500000   \n",
       "\n",
       "       abs_title_sentiment_polarity         shares          year  \\\n",
       "count                  39644.000000   39644.000000  39644.000000   \n",
       "mean                       0.156064    3395.380184   2013.540939   \n",
       "std                        0.226294   11626.950749      0.498327   \n",
       "min                        0.000000       1.000000   2013.000000   \n",
       "25%                        0.000000     946.000000   2013.000000   \n",
       "50%                        0.000000    1400.000000   2014.000000   \n",
       "75%                        0.250000    2800.000000   2014.000000   \n",
       "max                        1.000000  843300.000000   2014.000000   \n",
       "\n",
       "              month  log_n_tokens_content  log_num_hrefs  log_num_self_hrefs  \\\n",
       "count  39644.000000          39644.000000   39644.000000        39644.000000   \n",
       "mean       6.615856              5.889971       2.156564            1.208878   \n",
       "std        3.390683              1.255442       0.809445            0.692698   \n",
       "min        1.000000              0.000000       0.000000            0.000000   \n",
       "25%        4.000000              5.509388       1.609438            0.693147   \n",
       "50%        7.000000              6.016157       2.197225            1.386294   \n",
       "75%       10.000000              6.575076       2.708050            1.609438   \n",
       "max       12.000000              9.044876       5.720312            4.762174   \n",
       "\n",
       "       log_num_imgs  log_num_videos  log_kw_max_min  log_kw_min_max  \\\n",
       "count  39644.000000    39644.000000    39644.000000    39644.000000   \n",
       "mean       1.116427        0.400420        6.393888        5.045209   \n",
       "std        0.973755        0.680486        1.311168        4.521016   \n",
       "min        0.000000        0.000000        0.000000        0.000000   \n",
       "25%        0.693147        0.000000        6.100319        0.000000   \n",
       "50%        0.693147        0.000000        6.493754        7.244942   \n",
       "75%        1.609438        0.693147        6.908755        8.974745   \n",
       "max        4.859812        4.521789       12.606193       13.645079   \n",
       "\n",
       "       log_kw_avg_avg  log_self_reference_min_shares  \\\n",
       "count    39644.000000                   39644.000000   \n",
       "mean         7.976327                       6.195185   \n",
       "std          0.489467                       3.076913   \n",
       "min          0.000000                       0.000000   \n",
       "25%          7.776304                       6.461468   \n",
       "50%          7.962442                       7.090910   \n",
       "75%          8.189031                       7.863651   \n",
       "max         10.682093                      13.645079   \n",
       "\n",
       "       log_self_reference_max_shares  log_self_reference_avg_sharess  \n",
       "count                   39644.000000                    39644.000000  \n",
       "mean                        6.917477                        6.667697  \n",
       "std                         3.432430                        3.280186  \n",
       "min                         0.000000                        0.000000  \n",
       "25%                         7.003974                        6.889782  \n",
       "50%                         7.937732                        7.696667  \n",
       "75%                         8.987322                        8.556606  \n",
       "max                        13.645079                       13.645079  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 17 \n",
    "\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"ModelEval1\"></a>\n",
    "# Modeling and Evaluation 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score was chosen as our most important evaluation metric for analyzing the results of the modeling.\n",
    "\n",
    "F1 Score balances both precision and recall on the positive class which is ideal for this type of classification problem that predicts popularity based off shares, day of week, or news category as it is easy to interpret and communicate to our stakeholder Mashable. \n",
    "\n",
    "Accuracy is also tracked as it does provide correctly classified observations and it is important to note but it is not the most significant metric in our final analysis of the models.\n",
    "\n",
    "Overall F1 is the most appropriate metric for our modeling in order to avoid overfitting issues due to any imbalances in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"ModelEval2\"></a>\n",
    "# Modeling and Evaluation 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing your data into training and testing splits:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Our modeling uses 10-fold stratified cross validation for training and testing split to have more reliable estimates of the models' generalized performance. \n",
    "    \n",
    "### It ensures that the training and testing splits are representative of the overall dataset and avoids overfitting the model to the training data. It reduces the risk of variance. This is because the model is trained and evaluated on 10 different folds of the data, rather than just a single split. Overall cross validation is the most appropriate approach to splitting the dataset into a training set for model building, validation set for model and parameter selection, and test set for model evaluation. \n",
    "\n",
    "### Cross validation can also be useful in other ways such as comparing different machine learning models or estimate confidence intervals for a model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# Create a StratifiedKFold object with n_splits=10\n",
    "# kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state = random_state)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state = random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: share_quantile_ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19 Matt's Version \n",
    "\n",
    "# Remove target, related variables, and factor other targets due to them being categorical\n",
    "# import numpy as np\n",
    "# X0 = pd.get_dummies(df1, columns=['day_of_week'])\n",
    "# X0 = pd.get_dummies(X0, columns=['news_category'])\n",
    "# X1 = X0.drop(['share_quantile_ranges', 'shares'], axis=1) \n",
    "# y1 = X0['share_quantile_ranges']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 MATT's Version - i could not get it to work \n",
    "\n",
    "# Create a StratifiedKFold object with n_splits=10\n",
    "# X_train1, X_test1, y_train1, y_test1 = [], [], [], []\n",
    "# for train_index, test_index in kfold.split(X1, y1):\n",
    "#     X_train1.append(X1[train_index])\n",
    "#     X_test1.append(X1[test_index])\n",
    "#     y_train1.append(y1[train_index])\n",
    "#     y_test1.append(y1[test_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21 Tim's Version \n",
    "\n",
    "# Remove target, related variables, and factor other targets due to them being categorical\n",
    "import numpy as np\n",
    "X0 = pd.get_dummies(df1, columns=['day_of_week'])\n",
    "X0 = pd.get_dummies(X0, columns=['news_category'])\n",
    "X1 = X0.drop(['share_quantile_ranges', 'shares'], axis=1) \n",
    "y1 = X0.loc[:,'share_quantile_ranges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    9    19    23 ... 39630 39636 39639]\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   26    27    29 ... 39570 39592 39621]\n",
      "Fold 2:\n",
      "  Train: index=[    1     2     3 ... 39641 39642 39643]\n",
      "  Test:  index=[    0     5    16 ... 39593 39600 39615]\n",
      "Fold 3:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    4    10    11 ... 39574 39614 39638]\n",
      "Fold 4:\n",
      "  Train: index=[    0     3     4 ... 39641 39642 39643]\n",
      "  Test:  index=[    1     2     6 ... 39589 39596 39611]\n",
      "Fold 5:\n",
      "  Train: index=[    0     1     2 ... 39639 39640 39642]\n",
      "  Test:  index=[   33    42    49 ... 39637 39641 39643]\n",
      "Fold 6:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    3    15    31 ... 39584 39608 39635]\n",
      "Fold 7:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    7    20    57 ... 39633 39634 39640]\n",
      "Fold 8:\n",
      "  Train: index=[    0     1     2 ... 39640 39641 39643]\n",
      "  Test:  index=[   17    18    21 ... 39628 39631 39642]\n",
      "Fold 9:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   24    62    64 ... 39620 39622 39629]\n"
     ]
    }
   ],
   "source": [
    "# 22 TIMs Version \n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = [], [], [], []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X1, y1)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    X_train1.append(np.array(X1.iloc[train_index].to_numpy()))\n",
    "    X_test1.append(np.array(X1.iloc[test_index].to_numpy()))\n",
    "    y_train1.append(np.array(y1.iloc[train_index].to_numpy()))\n",
    "    y_test1.append(np.array(y1.iloc[test_index].to_numpy()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Test Split Shapes \n",
      "----------------------------------------\n",
      "Fold 0 : X_train1 set shape: (35679, 60)\n",
      "Fold 0 : X_test1 set shape: (3965, 60)\n",
      "Fold 0 : y_train1 labels shape: (35679,)\n",
      "Fold 0 : y_test1 labels shape: (3965,)\n"
     ]
    }
   ],
   "source": [
    "# 23  TIMs Version \n",
    "\n",
    "# Understanding the shape of the fold \n",
    "\n",
    "for i in range(1):  # This will get the shapes for the first two folds\n",
    "\n",
    "    train_shape = X_train1[i].shape\n",
    "    test_shape = X_test1[i].shape\n",
    "    train_labels_shape = y_train1[i].shape\n",
    "    test_labels_shape = y_test1[i].shape\n",
    "\n",
    "    \n",
    "    print(f\"           Test Split Shapes \" )\n",
    "    print(f\"----------------------------------------\")\n",
    "    print(f\"Fold {i} : X_train1 set shape: {train_shape}\")\n",
    "    print(f\"Fold {i} : X_test1 set shape: {test_shape}\")\n",
    "    print(f\"Fold {i} : y_train1 labels shape: {train_labels_shape}\")\n",
    "    print(f\"Fold {i} : y_test1 labels shape: {test_labels_shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: day_of_week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 Matt's Version \n",
    "\n",
    "# Remove target, related variables, and factor other targets due to them being categorical\n",
    "# X0 = pd.get_dummies(df1, columns=['news_category'])\n",
    "# X2 = X0.drop(['share_quantile_ranges', 'day_of_week'], axis=1) # Removing target categorical variable and other categorical variables\n",
    "# y2 = X0['day_of_week']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25 Matt's Version -- couldn't get to work \n",
    "\n",
    "# Split the data into training and testing folds\n",
    "# X_train2, X_test2, y_train2, y_test2 = [], [], [], []\n",
    "# for train_index, test_index in kfold.split(X2, y2):\n",
    "#     X_train2.append(X2[train_index])\n",
    "#     X_test2.append(X2[test_index])\n",
    "#     y_train2.append(y2[train_index])\n",
    "#     y_test2.append(y2[test_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26 Tim's Version \n",
    "\n",
    "# Remove target, related variables, and factor other targets due to them being categorical\n",
    "X0 = pd.get_dummies(df1, columns=['news_category'])\n",
    "X2 = X0.drop(['share_quantile_ranges', 'day_of_week'], axis=1) # Removing target categorical variable and other categorical variables\n",
    "y2 = X0.loc[:,'day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    7    16    37 ... 39623 39632 39636]\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     3 ... 39640 39642 39643]\n",
      "  Test:  index=[    2    12    18 ... 39630 39631 39641]\n",
      "Fold 2:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   19    22    62 ... 39565 39586 39619]\n",
      "Fold 3:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   61    64    72 ... 39624 39634 39640]\n",
      "Fold 4:\n",
      "  Train: index=[    0     2     4 ... 39641 39642 39643]\n",
      "  Test:  index=[    1     3     8 ... 39626 39627 39633]\n",
      "Fold 5:\n",
      "  Train: index=[    0     1     2 ... 39640 39641 39642]\n",
      "  Test:  index=[   21    44    47 ... 39600 39628 39643]\n",
      "Fold 6:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   14    28    34 ... 39625 39635 39637]\n",
      "Fold 7:\n",
      "  Train: index=[    1     2     3 ... 39641 39642 39643]\n",
      "  Test:  index=[    0    10    11 ... 39605 39618 39639]\n",
      "Fold 8:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    5     9    23 ... 39609 39621 39629]\n",
      "Fold 9:\n",
      "  Train: index=[    0     1     2 ... 39640 39641 39643]\n",
      "  Test:  index=[    4     6    13 ... 39617 39638 39642]\n"
     ]
    }
   ],
   "source": [
    "# 27 TIMs Version \n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = [], [], [], []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X2, y2)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    X_train2.append(np.array(X2.iloc[train_index].to_numpy()))\n",
    "    X_test2.append(np.array(X2.iloc[test_index].to_numpy()))\n",
    "    y_train2.append(np.array(y2.iloc[train_index].to_numpy()))\n",
    "    y_test2.append(np.array(y2.iloc[test_index].to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Task 3: news_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28 Matt's Version \n",
    "\n",
    "# Splitting the Data for news_category task and other targets due to them being categorical\n",
    "# X0 = pd.get_dummies(df1, columns=['day_of_week'])\n",
    "# X3 = X0.drop(['share_quantile_ranges', 'news_category'], axis=1) # Removing target categorical variable and other categorical variables\n",
    "# # y3 = X0['news_category']\n",
    "# # print(X2.columns)\n",
    "# # print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29Matt's Version -- couldn't get to work \n",
    "\n",
    "# Split the data into training and testing folds\n",
    "# X_train3, X_test3, y_train3, y_test3 = [], [], [], []\n",
    "# for train_index, test_index in kfold.split(X3, y3):\n",
    "#     X_train3.append(X3[train_index])\n",
    "#     X_test3.append(X3[test_index])\n",
    "#     y_train3.append(y3[train_index])\n",
    "#     y_test3.append(y3[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  30 Tim's Version \n",
    "\n",
    "# Splitting the Data for news_category task and other targets due to them being categorical\n",
    "X0 = pd.get_dummies(df1, columns=['day_of_week'])\n",
    "X3 = X0.drop(['share_quantile_ranges', 'news_category'], axis=1) # Removing target categorical variable and other categorical variables\n",
    "y3 = X0.loc[:,'news_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    7    21    33 ... 39620 39626 39627]\n",
      "Fold 1:\n",
      "  Train: index=[    0     2     3 ... 39640 39641 39642]\n",
      "  Test:  index=[    1    11    32 ... 39600 39628 39643]\n",
      "Fold 2:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    9    13    14 ... 39630 39634 39635]\n",
      "Fold 3:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    4    17    22 ... 39625 39631 39639]\n",
      "Fold 4:\n",
      "  Train: index=[    1     2     3 ... 39641 39642 39643]\n",
      "  Test:  index=[    0     6    12 ... 39603 39605 39607]\n",
      "Fold 5:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   24    25    45 ... 39622 39624 39637]\n",
      "Fold 6:\n",
      "  Train: index=[    0     1     3 ... 39640 39641 39643]\n",
      "  Test:  index=[    2    15    18 ... 39632 39633 39642]\n",
      "Fold 7:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    3    10    20 ... 39629 39636 39638]\n",
      "Fold 8:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    5    36    38 ... 39580 39584 39606]\n",
      "Fold 9:\n",
      "  Train: index=[    0     1     2 ... 39639 39642 39643]\n",
      "  Test:  index=[    8    19    23 ... 39618 39640 39641]\n"
     ]
    }
   ],
   "source": [
    "# 31 TIMs Version \n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = [], [], [], []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X3, y3)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    X_train3.append(np.array(X3.iloc[train_index].to_numpy()))\n",
    "    X_test3.append(np.array(X3.iloc[test_index].to_numpy()))\n",
    "    y_train3.append(np.array(y3.iloc[train_index].to_numpy()))\n",
    "    y_test3.append(np.array(y3.iloc[test_index].to_numpy()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"ModelEval3\"></a>\n",
    "# Modeling and Evaluation 3 (20 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32\n",
    "\n",
    "# Scale the features in the training and testing sets using StandardScalar.\n",
    "scaler = StandardScaler()\n",
    "import numpy as np  # Assuming you are using NumPy for your data\n",
    "# Use previous train/test split\n",
    "# for share_quantile_range_task\n",
    "X_train1 = scaler.fit_transform(X_train1)\n",
    "X_test1 = scaler.transform(X_test1)\n",
    "\n",
    "# for day_of_week task\n",
    "X_train2 = scaler.fit_transform(X_train2)\n",
    "X_test2 = scaler.transform(X_test2)\n",
    "\n",
    "# for news_category task\n",
    "X_train3 = scaler.fit_transform(X_train3)\n",
    "X_test3 = scaler.transform(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33 \n",
    "\n",
    "# Scale the features in the training and testing sets using QuantileTransformer after using StandardScalar.\n",
    "quantile_transformer = QuantileTransformer(n_quantiles=100)\n",
    "\n",
    "# # Use previous train/test split\n",
    "\n",
    "# # for share_quantile_range_task\n",
    "X_train_q1 = quantile_transformer.fit_transform(X_train1)\n",
    "X_test_q1 = quantile_transformer.fit_transform(X_test1)\n",
    "\n",
    "# for day_of_week task\n",
    "X_train_q2 = quantile_transformer.fit_transform(X_train2)\n",
    "X_test_q2 = quantile_transformer.fit_transform(X_test2)\n",
    "\n",
    "# for news_category task\n",
    "X_train_q3 = quantile_transformer.fit_transform(X_train3)\n",
    "X_test_q3 = quantile_transformer.fit_transform(X_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "## Create three different classification/regression models\n",
    "<a id=\"RFmodel\"></a>\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1: share_quantile_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34 Matts Version \n",
    "\n",
    "# Create the random forest model\n",
    "# rf = RandomForestClassifier(n_estimators=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 Matts Version \n",
    "\n",
    "# Train the share_quantile_ranges model\n",
    "# rf.fit(X_train_q1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 36 Matts Version \n",
    "\n",
    "# Make predictions on the test set for share_quantile_ranges task\n",
    "# rf_y_pred_q1 = rf.predict(X_test_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    9    19    23 ... 39630 39636 39639]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   26    27    29 ... 39570 39592 39621]\n",
      "Fold 0:\n",
      "  Train: index=[    1     2     3 ... 39641 39642 39643]\n",
      "  Test:  index=[    0     5    16 ... 39593 39600 39615]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    4    10    11 ... 39574 39614 39638]\n",
      "Fold 0:\n",
      "  Train: index=[    0     3     4 ... 39641 39642 39643]\n",
      "  Test:  index=[    1     2     6 ... 39589 39596 39611]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39639 39640 39642]\n",
      "  Test:  index=[   33    42    49 ... 39637 39641 39643]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    3    15    31 ... 39584 39608 39635]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    7    20    57 ... 39633 39634 39640]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39640 39641 39643]\n",
      "  Test:  index=[   17    18    21 ... 39628 39631 39642]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   24    62    64 ... 39620 39622 39629]\n"
     ]
    }
   ],
   "source": [
    "# 37 Tim's Version \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "\n",
    "#########\n",
    "# Adjust here for computational time the number of folds \n",
    "######################################################################################\n",
    "# Create a StratifiedKFold object adjust the number of fold as necessary \n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state = random_state)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state = random_state)\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "# Remove target, related variables, and factor other targets due to them being categorical\n",
    "import numpy as np\n",
    "X0 = pd.get_dummies(df1, columns=['day_of_week'])\n",
    "X0 = pd.get_dummies(X0, columns=['news_category'])\n",
    "X1 = X0.drop(['share_quantile_ranges', 'shares'], axis=1) \n",
    "y1 = X0.loc[:,'share_quantile_ranges']\n",
    "\n",
    "# Instantiate transformers\n",
    "quantile_transformer = QuantileTransformer(n_quantiles=100, output_distribution='normal')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "X_train_list, X_test_list, y_train_list, y_test_list = [], [], [], []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X1, y1)):\n",
    "    print(f\"Fold {0}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "    X_train1 = np.array(X1.iloc[train_index].to_numpy())\n",
    "    X_test1 = np.array(X1.iloc[test_index].to_numpy())\n",
    "    y_train1 = np.array(y1.iloc[train_index].to_numpy())\n",
    "    y_test1 = np.array(y1.iloc[test_index].to_numpy())\n",
    "\n",
    "    # Scale and Quantile Transform for this fold\n",
    "    X_train_fold = scaler.fit_transform(X_train1)\n",
    "    X_test_fold = scaler.transform(X_test1)\n",
    "    X_train_q1 = quantile_transformer.fit_transform(X_train_fold)\n",
    "    X_test_q1 = quantile_transformer.transform(X_test_fold)\n",
    "\n",
    "    # Instantiate and fit the model (e.g., RandomForestClassifier)\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "    rf.fit(X_train_q1, y_train1)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    rf_y_pred_q1 = rf.predict(X_test_q1)\n",
    "\n",
    "    # Calculate accuracy and F1 score for this fold\n",
    "    accuracy = accuracy_score(y_test1, rf_y_pred_q1)\n",
    "    f1 = f1_score(y_test1, rf_y_pred_q1, average='macro')\n",
    "    precision = precision_score(y_test1, rf_y_pred_q1, average=None)\n",
    "    recall = recall_score(y_test1, rf_y_pred_q1, average= None)\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    \n",
    "    X_train_list.append(X_train1)\n",
    "    X_test_list.append(X_test1)\n",
    "    y_train_list.append(y_train1)\n",
    "    y_test_list.append(y_test1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle Results Save 1:\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Create a dictionary to store all the data\n",
    "data_to_save = {\n",
    "    'X_train_list': X_train_list,\n",
    "    'X_test_list': X_test_list,\n",
    "    'y_train_list': y_train_list,\n",
    "    'y_test_list': y_test_list,\n",
    "    'accuracy_scores': accuracy_scores,\n",
    "    'f1_scores': f1_scores,\n",
    "    'precision_scores': precision_scores,\n",
    "    'recall_scores': recall_scores\n",
    "}\n",
    "\n",
    "# Save the data to a file\n",
    "with open('data_and_scores.pkl', 'wb') as file:\n",
    "    pickle.dump(data_to_save, file)\n",
    "    \n",
    "# Pickle Results Load 1: \n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the lists and scores from the file\n",
    "with open('data_and_scores.pkl', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "X_train_list = loaded_data['X_train_list']\n",
    "X_test_list = loaded_data['X_test_list']\n",
    "y_train_list = loaded_data['y_train_list']\n",
    "y_test_list = loaded_data['y_test_list']\n",
    "accuracy_scores = loaded_data['accuracy_scores']\n",
    "f1_scores = loaded_data['f1_scores']\n",
    "precision_scores = loaded_data['precision_scores']\n",
    "recall_scores = loaded_data['recall_scores']\n",
    "\n",
    "# print(recall_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest on Task 1: share_quantile_ranges \n",
      "[0.38319879 0.37394854 0.38474149 0.37574802]\n",
      "---------------------------------------------\n",
      "Random Forest accuracy: 0.38319878910191724\n",
      "Random Forest precision: 0.3739485375801075\n",
      "Random Forest recall: 0.3847414885336963\n",
      "Random Forest F1 score: 0.3757480186161482\n"
     ]
    }
   ],
   "source": [
    "# 38 Tim's Version\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the model evaluation metrics\n",
    "\n",
    "rf_accuracy_q1 = accuracy_score(y_test1, rf_y_pred_q1)\n",
    "rf_precision_q1 = precision_score(y_test1, rf_y_pred_q1, average='macro')\n",
    "rf_recall_q1 = recall_score(y_test1, rf_y_pred_q1, average='macro')\n",
    "rf_f1_score_q1 = f1_score(y_test1, rf_y_pred_q1, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics\n",
    "rf_model_scores_q1 = np.array([rf_accuracy_q1, rf_precision_q1, rf_recall_q1, rf_f1_score_q1])\n",
    "\n",
    "# Print the model evaluation metrics\n",
    "print('Random Forest on Task 1: share_quantile_ranges ')\n",
    "print(rf_model_scores_q1)\n",
    "print('---------------------------------------------')\n",
    "print('Random Forest accuracy:', rf_accuracy_q1)\n",
    "print('Random Forest precision:', rf_precision_q1)\n",
    "print('Random Forest recall:', rf_recall_q1)\n",
    "print('Random Forest F1 score:', rf_f1_score_q1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Move to VIZ AREA and ADD VIZ TO OTHER MODELS \n",
    "# \n",
    "# \n",
    "# IFFY but it works -- you can add \n",
    "# \n",
    "# Calculate average precision and recall across all folds for each class\n",
    "average_precision = np.mean(precision_scores, axis=0)\n",
    "average_recall = np.mean(recall_scores, axis=0)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(average_precision)\n",
    "\n",
    "# Plot the precision and recall for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(num_classes), average_precision, marker='o', label='Precision', linestyle='--')\n",
    "plt.plot(range(num_classes), average_recall, marker='o', label='Recall', linestyle='--')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Class Index')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Average Precision and Recall for Each Class')\n",
    "plt.xticks(range(num_classes))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAGECAYAAAA1Cln7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABKjElEQVR4nO3dd1wUd/4G8GfpICIILCh2aSpgj4hYEAVFEGuCJRo9S5IzJt7FxCSm2HLJJRfTfvFMLpfElpio2A9BEStiiy0qvdeV3tny/f3hsRdiQ2TZZXner5d/zM7MzmeGkYf57Ox8JUIIASIiItI7BtougIiIiDSDIU9ERKSnGPJERER6iiFPRESkpxjyREREeoohT0REpKcY8qTzsrKy4Obmhrlz594zb9WqVXBzc0NRUZEWKrvrpZdewrBhw1BdXa21Gppi7dq1+OKLL+55fc+ePRg8eDBCQ0MxZcoUhIaGIiwsDL/++muzbXvx4sVISkp64Pzr169j+fLlzba9rKws9OnTB6Ghoep/48ePx7PPPovMzMxm2069uLg4BAcHA7h7jn777bf3XS4/Px+rVq1CSEgIJk+ejJkzZ+Lo0aPNXg+1XUbaLoCoMUxNTZGamors7Gw4OTkBAKqqqnD58mWt1pWfn48LFy5gwIAB2Lt3L2bNmqXVeprLkCFDsHnzZvV0dHQ0XnrpJcTExMDI6Ml/bXzzzTcPne/p6YnPP//8ibfze2ZmZti3b596WgiB9evXY+PGjfjkk0+adVuNUVRUhLCwMLz88sv429/+BolEgtu3b2PBggUwNzfHiBEjWrwm0j8MeWoVDA0NMXHiRBw4cADPP/88ACAyMhL+/v7497//DQBQqVR4//33cfXqVVRWVqp/iQ8ePBiVlZVYv349Ll++DENDQ4wbNw4rVqzAG2+8gZKSEmRmZmLMmDF4/vnnsWbNGty+fRsSiQQjR47EX/7ylwcG288//4zhw4cjMDAQn332GcLCwiCRSPDXv/4V/fr1w8KFCwEAO3bswPnz5/Hpp58iOjoamzZtglwuh5mZGV5//XUMHDgQX3zxBa5cuYKCggK4ublh1apVeOedd1BYWAiZTAYnJyd8+umnsLW1xbVr1/Dee+9BLpejW7duyMnJwapVqzBs2LAHvn9FRQXeeust3L59G1KpFIaGhhg8eHCjjv/w4cMhk8lQVlaGv//97w2O2csvv4yPP/4YFy5cgFKpRN++fbF69WpYWloiNTUV77zzDoqKimBgYIAXXngBQUFBGDt2LD777DP06tULb7zxBtLT02FgYIB+/fph7dq1uHDhAtatW4eDBw+ivLz8gT8TT09PLFmyBGfOnEFBQQEWLVqE2bNnN2qfamtrUVBQADs7OwBAXV3dY+/H8ePHsXnzZtTV1aGoqAhTpkzBK6+80qjt79ixA4MGDcKUKVPUr7m7u+Pzzz+HlZUVAMDNzQ2xsbHo2LFjg+nExERs2LABFhYWqKyshIuLCzw8PB7rfKM2QhDpuMzMTDFgwABx/fp1MWHCBPXr8+fPF/Hx8cLV1VUUFhaKy5cvi5deekkolUohhBCbN28WS5cuFUII8f7774sVK1YIhUIhamtrxZw5c8S5c+fE66+/LubPn69+z9dee02sW7dOqFQqUVtbKxYuXCg2b95837rkcrnw9fUV0dHRora2VgwdOlTExMQIIYSIjY0VwcHB6mVnzJghzpw5I1JTU0VwcLAoKioSQgiRkJAgRowYISorK8Xnn38uAgMDhVwuF0II8f3336u3rVKpxKJFi8S3334r5HK5GDVqVINtubm5iXPnzj30/Tds2CBee+01oVKpRGFhoRg1apT4/PPP79mv3bt3iyVLlqinVSqV+O6779T788dj9sUXX4gPPvhAqFQqIYQQ//jHP8S7774rhBBiypQpYtu2bUIIIXJycoS/v78oLy8Xfn5+4tq1ayI8PFwsXLhQCCGEQqEQb731lkhLSxPnzp0TkyZNeuTPxNXVVWzdulUIIcT169eFh4eHqKmpuWefMjMzhbu7u5g8ebIIDg4Ww4cPFxMmTBCffPKJqKioaNJ+lJWViblz54rU1FQhhBB5eXmiT58+orCwsEH9r7/+uvjXv/51T01Lly5Vv+eD1J/bf5w+d+6ccHd3F1lZWUKIpp1v1DbwSp5aDQ8PDxgaGuLGjRuwtbVFZWUlXF1d1fMHDhyIDh064KeffkJmZibi4uLQrl07AMDZs2fxxhtvwNDQEIaGhti2bRsAIDw8vMHV7MmTJ/Hjjz9CIpHAxMQEYWFh+OGHH7BkyZJ76jl27BhUKhVGjhwJIyMjBAUFYcuWLRg9ejSGDRuG2tpaXL9+Hebm5igqKsLw4cOxY8cOFBQU4LnnnlO/j0QiQUZGBgBgwIAB6q7B/PnzcfHiRXz33XdIS0tDYmIi+vfvj4SEBADA6NGjAQDe3t5wcXEBAPUV7f3ePzY2Fm+++SYkEgk6duyI8ePHP/BYX7x4EaGhoZBIJKirq0OvXr0atM9/f8xiYmJQXl6Os2fPAgDkcjlsbW1RUlKC27dvY+bMmQCATp063fN58+DBg7Fx40Y8++yz8PHxwfz589G9e3fk5eU1+mfi7+8PAOjXrx/q6upQVVUFU1PTe/bp9+36U6dOYeXKlfDz81OfI03Zj3/+85+IiYnBwYMHkZycDCFEo+/NkEgkEE/wVPFOnTqpP7pqyvnm7u7e5G1T68GQp1Zl8uTJ2L9/Pzp27IjQ0NAG82JiYrBhwwYsWLAA/v7+6NWrF/bv3w8AMDIygkQiUS+bm5sLMzMzAICFhYX6dZVK1WA5lUoFhUKBY8eOqUNOKpXim2++wY4dO1BTU4OAgAAAd9u9MpkMiYmJcHFxwYwZM7Bv3z4YGxtjxowZkEgkUKlUGD58OD799NMGtUilUkRFRTWo5aOPPsK1a9cwffp0DBs2DAqFAkIIGBoa3hMOhoaG6nof9P4AGqxXv879/PEz+T/64zF788031X90VFZWora2Vv3Hyu+PZ0pKCjp37qye7tq1K6KiohAXF4dz585hwYIFWLt2rTp469//fj+TevWBXr+MEAJvvfUWbty4AQAICwvDyJEjG9Q/cuRILFiwAC+//DIOHToES0vLx94PR0dHTJ06FePGjcOQIUMwffp0HD16tNHBPWDAAFy5cuWeG0p/+uknVFdXY8GCBQ1er6urazD9+5+BRCJ57PON2gbeXU+tSmhoKCIiInD48GH13cv1zpw5Az8/P8yePRseHh44evQolEolgLufKYeHh0OlUqGurg7Lly/HhQsX7nl/X19fbNu2DUII1NXV4eeff4aPjw/8/f2xb98+7Nu3D9988w1SU1Nx4cIF7NmzB9HR0YiOjsbp06cxdOhQbNmyBQAwdepUREdH48iRI5g2bZq6jjNnziA5ORkAcOLECUyePBk1NTX31HL69GnMnz8fU6ZMga2tLc6ePQulUonevXvDxMQEJ0+eBABcu3YNCQkJkEgkD33/kSNHYteuXVCpVCgtLcWxY8ea5Wfi6+uL7du3o66uDiqVCm+//TY++eQTWFpaol+/fti7dy+Au+Eya9YslJeXq9fdsWMH3njjDfj6+mLlypXw9fXFzZs3G/UzeZgNGzaof14Puhly4cKFaNeunfqPt8fdj4SEBFRUVOCVV17B2LFjERcXp163MZ555hmcP38e+/fvV/9hcOPGDXz++efqDlXHjh1x/fp1AMDBgwcf+n5Per6RfuKVPLUqDg4O6N27N9q3bw9ra+sG88LCwvDXv/4VISEhUCgUGDFiBCIjI6FSqbBs2TJs2LABoaGhUCqVCAoKQkBAAKKjoxu8x+rVq7F+/XqEhIRALpdj5MiR6hv9fu/HH3/EuHHj0L179wav//nPf8bSpUuxYsUK2Nvbo2/fvlAoFHBwcAAAODs7Y+3atfjLX/4CIQSMjIywadOmBleuv3+vv//97/jss89gbGyMQYMGISMjA0ZGRvjiiy/w7rvv4pNPPkGPHj1gZ2cHMzOzh77/Sy+9hHfffRcTJ05Ex44dG3zU8SRefPFFfPjhh5g6dSqUSiX69OmDVatWAQD+8Y9/YM2aNdi6dSskEgk2bNgAe3t79bpTpkzB+fPnERQUBHNzc3Tq1AnPPvssbt++/dg/k8dlbGyMt99+G4sWLcKMGTMeez+8vLwwZswYTJw4ESYmJnB1dYWzszPS09NhYmLyyO1bW1tj69at+Oijj7B582YYGBjA3NwcGzZsUN9Zv3r1aqxduxZWVlbw8fFpcOz+6EnPN9JPEvEkHwoRkVZ8+OGH+NOf/gQ7Ozvk5uYiNDQUR48eVd+VTUQE8EqeqFVycnLCc889ByMjI/VXBRnwRPRHvJInIiLSU7zxjoiISE8x5ImIiPQUQ56IiEhPMeSJiIj0lF7eXV9cXAmVivcTEhGR/jMwkMDG5v7PPtDLkFepBEOeiIjaPLbriYiI9BRDnoiISE8x5ImIiPQUQ56IiEhPMeSJiIj0FEOeiIhITzHkiYiI9BRDnoiISE8x5ImIiPQUQ56IiEhPMeSJiIhaSFJ2KQ7FpiEpu7RFtqeXz64nIiLSNUnZpfj7jstQKAWMjQywctZAODt10Og2eSVPRETUAq4nF0KhvDt4mlKpQnxGsca3yZAnIiJqAen55QAAiQQwNDSAWzcbjW+T7XoiIiINu55SiGvJhfDxcEQnWwu4dbPReKseYMgTERFpVFWNAt//5zY627XD/AnuMDZquSa6Rrd04MABBAUFISAgANu3b3/gcjExMRg7duw9r9+8eRMeHh6aLJGIiEijfj6eiJKKWiwM6tOiAQ9o8Eo+Pz8fGzduxJ49e2BiYoKwsDAMGzYMzs7ODZa7c+cOPvzww3vWr66uxrp16yCXyzVVIhERkUbdSCnEyau5CPLujl6drVp8+xr7k+Ls2bPw9vaGtbU1LCwsEBgYiIiIiHuWW716NZYtW3bP6x988AHmz5+vqfKIiIg0qqpGge/+cxudbC0Q6ttDKzVoLOQLCgpgb2+vnpZKpcjPz2+wzJYtW9C3b1/079+/wevHjh1DTU0NJkyYoKnyiIiINOrn40l32/ST+sDYyFArNWisXa9SqSCRSNTTQogG0wkJCYiMjMT333+PvLw89esymQybNm3C999/r6nSiIiINOpGaiFOXs3BxGHd0Luz5u+ifxCNhbyjoyMuXryonpbJZJBKperpiIgIyGQyTJ8+HXK5HAUFBZg9ezamTp2KkpISzJkzR71saGgotm/fDktLS02VS0RE1CyqaxX44b9t+ikje2q1FokQQmjijfPz8zFr1izs2rUL5ubmCAsLw7p16+Dl5XXPsllZWZg3bx6io6Pvmefm5ob4+PjH2nZhYQVUKo3sFhER0UNtibiNE1dz8ObcwejdAt+FNzCQwNb2/hfBGvtM3sHBAStWrMC8efMwZcoUBAcHw8vLC4sXL8b169c1tVkiIiKt+S2tCDFXchA4tFuLBPyjaOxKXpt4JU9ERC2tulaBd749DyMjA6xZMBQmxi1zs51WruSJiIjakl9iklFUVoM/BfVpsYB/FIY8ERHRE7qZVoSYX7MR8FRXOHfRfpu+HkOeiIjoCVTXKvDd4dtw6GiBqSN7abucBhjyRERET2DXibtt+oVB7jrTpq/HkCciImqiW+nFOH45G+OHdoVLF2ttl3MPhjwREVET1NQp8N3hW5DamGPqKN1q09djyBMRETXB7pgUFJbWYGFQH5jqWJu+HkOeiIjoMcVnFOPY5Sz4D+kC167W2i7ngRjyREREj6G2Tol/H74FqbU5po/qre1yHoohT0RE9Bh2nUiGrKQGC4LcYWqim236egx5IiKiRorPKMaxS1kYN7gL3LrZaLucR2LIExERNUJtnRLfHb4Ne2szTB+t2236egx5IiKiRth9MhkFJdV376bX8TZ9PYY8ERHRIyRkluDYxSz4D2odbfp6DHkiIqKHqJXfvZvetoMZpo/RzYfePAhDnoiI6CHCT6agoLgaC4L6wMzESNvlPBaGPBER0QMkZpUg6kIm/AY5oU/31tOmr8eQJyIiuo86uRL/PnS3TT9zTOu4m/6PGPJERET3sedkCvKLq7Fgonura9PXY8gTERH9QVJW6d02/UAn9OnRUdvlNBlDnoiI6Hfq5Ep8e/gWOlqZYUYrbdPXY8gTERH9zt5TqcgvqsKCIHeYm7bONn09hjwREdF/JWWX4siFDIwZ0Bl9W3Gbvh5DnoiICP+7m75je1PM9HPWdjnNgiFPREQEYN/pVOQVVeG5iX1afZu+HkOeiIjavOScUkScz8Co/p3Rr2frb9PXY8gTEVGbJlfcbdPbtDfFM2P1o01fjyFPRERt2t7TqcgtrMJzE1r/3fR/xJAnIqI2KyWnDBFxGRjp1QkevWy1XU6zY8gTEVGbJFfcHULW2tIUz4x10XY5GsGQJyKiNmn/mTTk3KnEcxPdYWGmX236egx5IiJqc1Jzy3D4XDp8vTrBUw/b9PUY8kRE1KbIFSr8+9DdNn2Ynt1N/0cMeSIialMOnE1F9p1KzJ/gBgszY22Xo1EMeSIiajPS8spwODYDIzwd4dXbTtvlaBxDnoiI2gS5QoVvD92CVTtjhPnr5930f6TRkD9w4ACCgoIQEBCA7du3P3C5mJgYjB07Vj196dIlzJgxA6GhoZg/fz6ys7M1WSYREbUBB86mIVtWifkT3NFOz9v09TQW8vn5+di4cSN27NiBvXv3YufOnUhKSrpnuTt37uDDDz9s8NrKlSuxfv167Nu3DyEhIVi/fr2myiQiojYgPa8ch2PT4ePhiP7O+t+mr6exkD979iy8vb1hbW0NCwsLBAYGIiIi4p7lVq9ejWXLlqmn6+rq8PLLL8Pd3R0A4ObmhtzcXE2VSUREek6hVOHbQzfRvp0xZo1rG236ehoL+YKCAtjb26unpVIp8vPzGyyzZcsW9O3bF/3791e/ZmJigtDQUACASqXCl19+iXHjxmmqTCIi0nMHz6YhS1aJ+YFtp01fT2Mhr1KpIJFI1NNCiAbTCQkJiIyMxIsvvnjf9evq6vDqq69CoVBg6dKlmiqTiIj0WHpeOQ7FpmN4P0cMcGk7bfp6Ggt5R0dHyGQy9bRMJoNUKlVPR0REQCaTYfr06ViyZAkKCgowe/ZsAEBlZSUWLVoEhUKBTZs2wdi4bf3lRURET06hVOHfh2/B0rzttenraSzkfXx8EBsbi6KiIlRXVyMyMhKjRo1Sz1++fDmOHDmCffv24euvv4ZUKsWOHTsA3L3xrnv37vj0009hYmKiqRKJiEiPHYpNR2ZBBeZNcIOledu8WNTYE/kdHBywYsUKzJs3D3K5HDNmzICXlxcWL16M5cuXw9PT877r3bx5E8eOHYOzszOmTp0K4O7n+d98842mSiUiIj2TkV+Og2fT4N3PAQNd7B+9gp6SCCGEtotoboWFFVCp9G63iIioERRKFdb/cBEllXVYv2iY3l/FGxhIYGtref95LVwLERGRRh2OTUdGQQXmBbbdNn09hjwREemNjPxyHDibhmF9HTDIte226esx5ImISC/U303fzswIc8a7arscncCQJyIivfCfc+nIyK/As4Hubb5NX48hT0RErV5WQQX2n0nDU32kGOzGNn09hjwREbVqd59NfwsWbNPfgyFPREStWkRcBtLzy/FsgBvaW/ABar/HkCciolYrS1aBfadTMdRdiiHu0kev0MYw5ImIqFVSqu626c1NjTAngG36+2HIExFRqxQRl4H0vHI8G+gGK7bp74shT0RErU72f9v0Q9zsMZRt+gdiyBMRUauiVN196I2ZiRHmBrhpuxydxpAnIqJW5cj5TKTmlmNugCus2rFN/zAMeSIiajWy71Ri76kUDGabvlEY8kRE1CooVSr8+9D/2vQSiUTbJek8hjwREbUKkRcykZpbhjnjXdGBbfpGYcgTEZHOy7lTifCTqRjkao+n+rBN31gMeSIi0mkqlcC/D9+CqbEBng1wZZv+MTDkiYhIp0VeyERKzn/b9Jam2i6nVWHIExGRzsotrMSekykY6GKHYX0dtF1Oq8OQJyIindSgTR/Iu+mbgiFPREQ6KepiJpKzyzB7vCus2aZvEoY8ERHpnLyiKuw5mYIBznbwZpu+yRjyRESkU+rb9MaGBpg3gW36J8GQJyIinXL0UhaSskoxe7wL2/RPiCFPREQ6I7+oCntOJKN/b1sM7+eo7XJaPSNtF0BERAQAiZkl2HzgN0gkEsyb4M42fTNgyBMRkdb9llqEjT9fhUoIGBpIUFhWA5v2bNU/KbbriYhIa4QQOH8rH/8Xfh0qIdSvxWcUa7ky/cAreSIi0orcwkpsj0rAzbRiONiYQ6GsgUolYGhoALduNtouTy8w5ImIqEXV1ilxMDYNEXEZMDE2xJzxrvAb6ISU3DLEZxTDrZsNnJ06aLtMvSAR4r/9ET1SWFgBlUrvdouIqFUTQuBywh38dCwBhWW1GOHhiBl+zhwb/gkZGEhga2t533m8kiciIo3LL67CjqhEXE8pRBf7dlg1px9cu1pruyy9x5AnIiKNqZMrcfhcOg6fy4CRoQRh/i7wH+wEQwPe990SGPJERKQRV5LuYEdUAu6U1sC7rwNm+jnza3EtjCFPRETNSlZSjR+PJuJK0h10srXAylkD0ac775bXBo32Sw4cOICgoCAEBARg+/btD1wuJiYGY8eOVU/n5ORgzpw5mDBhAl544QVUVlZqskwiImoGcoUS+8+kYvW/4nArvRgz/XpjzcKnGPBapLGQz8/Px8aNG7Fjxw7s3bsXO3fuRFJS0j3L3blzBx9++GGD19asWYPZs2cjIiICHh4e+OqrrzRVJhERNYMbKYV4+9vz2HsqFf2d7bBh8TBMHNYdRob87F2bNHb0z549C29vb1hbW8PCwgKBgYGIiIi4Z7nVq1dj2bJl6mm5XI4LFy4gMDAQADBt2rT7rkdERNpXWFqD/9tzHZ/8fBUSiQR/eaY/XpzigY5WZtoujaDBz+QLCgpgb2+vnpZKpbh27VqDZbZs2YK+ffuif//+6teKi4thaWkJI6O7pdnb2yM/P19TZRIRURMolCocOZ+BA2fTAAFMG9ULgU91g7ERr9x1icZCXqVSNRhBSAjRYDohIQGRkZH4/vvvkZeX98DlAHAkIiIiHXIzrQjbIhOQV1SFgS52mDXOBXYdzLVdFt2HxkLe0dERFy9eVE/LZDJIpVL1dEREBGQyGaZPnw65XI6CggLMnj0bP/zwA8rLy6FUKmFoaHjPekREpB3F5bXYGZ2I87cKYG9thldmesGrt522y6KH0FhfxcfHB7GxsSgqKkJ1dTUiIyMxatQo9fzly5fjyJEj2LdvH77++mtIpVLs2LEDxsbGGDJkCA4fPgwA2Lt3b4P1iIioZSmUKkTEZeDNb87hcsIdhPr2xLo/DWPAtwIau5J3cHDAihUrMG/ePMjlcsyYMQNeXl5YvHgxli9fDk9Pzweu++6772LVqlXYtGkTOnXqhE8++URTZRIR0UPEZxRjW2QCsu9Uwqu3LWaPc4HUxkLbZVEjcYAaIiK6R2lFLX4+noTY3/Jha2WG2eNcMMDFjvdI6SAOUENERI2iVKkQfTkbe0+lQK5QIdinOyYN7wFTY0Ntl0ZNwJAnIiIAQFJWKbZGxiOzoAL9ethgToAbHDuyNd+aMeSJiNq4sso67IpJxunrubBpb4oXp3hgsJs9W/N6gCFPRNRGqVQCJ65kY/eJFNTKlZg4rBtCRvSAmQmjQV/wJ0lE1Aal5JRha2Q80vPK4d7NGnMD3NDZrp22y6JmxpAnImpDKqrl2H0iGSev5MDK0gRLJvfFsD4ObM3rKYY8EVEboBICp6/lYldMMqpqFBg/tCtCfXvC3JQxoM/40yUi0nPpeeXYGhmPlJwyuHbpgLkBbugivf/3qkm/MOSJiPRUZY0c4SdTcPzXbLQ3N8ai4D4Y3s+Rrfk2hCFPRKRnhBA4eyMPPx9PQkW1HGMHdsHUUT1hYWas7dKohTHkiYj0SGZBBbZFxiMxqxS9O1vhL08PQHfH9toui7SEIU9EpAeqaxXYeyoVxy5lwcLMCAsmumOEVycYsDXfpjHkiYhaMSEE4m7mY2d0Esoq6zB6oBOmjeoFS3O25okhT0TUamXfqcT2yHjczihBD8f2WD7DCz07WWm7LNIhDHkiolampk6B/WfSEHUhE2YmhpgX6IZR/TvDwICteWqIIU9E1EoIIXAxXoafjiWiuLwWI706YfqY3rCyMNF2aaSjGPJERK1AbmEldkQl4Le0YnSTWuKFKR5wduqg7bJIxzHkiYh0WG2dEgdj0xARlwETY0PMGe8Kv4FObM1TozDkiYh0kBACvybewY9HE1BYVgsfD0fM9HNGh3ZszVPjMeSJiHRMQXEVtkcl4npKIZzs22HVnH5w7Wqt7bKoFWLIExHpiDq5EofPpePwuQwYGUoQNtYZYwd3gZGhgbZLo1aKIU9EpAOuJN3BjqgE3CmtwbC+Dnjazxk27U21XRa1cgx5IiItkpVU48ejibiSdAedbC2wMmwA+vToqO2ySE80OuTPnz+P0tJSCCHUrwUEBGikKCIifSdXqBARl46DsemQSICZY3pj/NCubM1Ts2pUyK9evRonT55E9+7d1a9JJBKGPBFRE9xIKcS2qAQUFFdjiJs9wvxd0NHKTNtlkR5qVMjHxsbi8OHDsLS01HQ9RER6q6isBj8eS8SleBkcbMzxl6f7w6OXrbbLIj3WqJDv1KkTA56IqIkUShUiL2Ri/5lUQABTR/XChKe6wdiIrXnSrEaF/KBBg7BixQr4+fnBzOx/LSW264mIHu5WWhG2RSUgt7AKA13sMMvfBXbW5toui9qIRoX8r7/+CgD45Zdf1K/xM3kiogcrLq/FzuhEnL9VALsOZnh5hhf6O9tpuyxqYyTi97fLP4JCoYAQAsbGxpqs6YkVFlZApWr0bhERNRuFUoVjl7Kw93QqlEqBIO9uCPLuDhNjQ22XRnrKwEACW9v7f6TeqCv5wsJCvP766zh37hyUSiWGDh2Kjz76CA4ODs1aKBFRaxafUYxtUQnIllXCq7ctZo9zgdTGQttlURvWqCv5l19+GS4uLpg3bx6USiW2bt2KW7duYdOmTS1R42PjlTwRtaTSyjr8HJ2E2N/yYGtlhtnjXDDAxQ4SCUeKI8174iv5tLQ0fPbZZ+rp5cuXY9KkSc1THRFRK6VUqXD8cjbCT6WgTq7CpOHdEezTA6ZszZOOaFTIKxQK1NbWwtT07nOUq6ur+RcqEbVpSdml2HYkHhkFFejXwwZzAtzg2JGtedItjQr5oKAgPPfcc5g2bRokEgl2796NwMBATddGRKRzyqrqsCsmGaev5cKmvSlenOKBwW72vPAhndTou+t3796NU6dOQaVSYeTIkZgxY4bOntT8TJ6ImptKJXDiag72nEhGTZ0SAUO7ImRED5iZcJwv0q6HfSb/0JCvqKiApaUlSkpK7jvf2tr6oRs+cOAANm3aBIVCgfnz52POnDkN5kdFReHzzz+HSqWCp6cn1q5dCxMTE2RlZeH1119HRUUFrKys8MEHH8DJyenhe/k7DHkiak6puWXYeiQeaXnlcO9mjTkBbnCya6ftsogAPEHIT506FeHh4XB3d29w1S6EgEQiwa1btx640fz8fMyaNQt79uyBiYkJwsLC8Mknn8DZ2RkAUFVVhcDAQISHh8POzg4rVqyAt7c3nnnmGaxcuRIDBw7E7NmzsXXrVly9ehUff/xxo3eYIU9EzaGiWo49J5Jx4koOrCxN8MxYZwzr46CzXUxqm5p8d314eDgA4Pbt24+90bNnz8Lb21t9tR8YGIiIiAgsW7YMAGBhYYHo6GgYGxujuroahYWFsLKyAgCoVCpUVFQAuHuT3+8fpUtEpGkqIXD6Wi52xSSjqkaB8UO7ItS3J8xN2Zqn1qVRZ+ydO3dw9epV+Pv74+OPP8b169fxxhtvwN3d/YHrFBQUwN7eXj0tlUpx7dq1BssYGxvjxIkTeO211yCVSuHr6wvg7vfyw8LCsHXrVsjlcuzcubMp+0ZE9NjS88qxLTIeyTllcOnSAXMD3NBVygG6qHVq1BBIq1atQmZmJmJjY3Hy5EmEhoZi/fr1D11HpVLdt8X/R6NHj0ZcXBz8/Pzw3nvvAQBef/11rF27FqdOncKaNWuwbNkyPMbTd4mIHltVjRzbIxOw9ocLkJVU40+T+mDVnEEMeGrVGhXyJSUleO6553Dy5EkEBwdj2rRpqK6ufug6jo6OkMlk6mmZTAapVNrgPU+fPq2eDgkJQXx8PIqKipCSkoJx48YBuNvml8lkKC4ufqwdIyJqDCEEzlzPxZtfn0P0r1kYO7AL3l/ijRGenfjZO7V6jQp5uVwOuVyOU6dOwcfHB9XV1aiqqnroOj4+PoiNjUVRURGqq6sRGRmJUaNGqecLIbBy5Urk5OQAACIiIjBo0CDY2NjA1NQUFy9eBABcunQJ7dq1Q8eOHZu6j0RE95VVUIEPtl/Gt4duwd7aHO/MH4o5Aa6wMNPtQbiIGqtRn8n7+/tj+PDh6NOnDzw8PBAcHIzg4OCHruPg4IAVK1Zg3rx5kMvlmDFjBry8vLB48WIsX74cnp6eWLduHZYuXQqJRAJnZ2esWbMGEokEX375JdatW4eamhq0a9cOX3zxRbPsLBERAFTXKrD3VCqOXcqChZkRnpvoDl+vTjDglTvpmUY/DCcvLw8ODne/OnL79u2H3nSnbfwKHRHdjxACcTfzsTM6CWWVdRg9oDOmje4NS3NeuVPr1eTvye/btw+hoaH47rvv7jt/wYIFzVNhM2PIE9EfZd+pxPbIeNzOKEEPx/Z4NtANPTtZabssoifW5O/Jp6enAwASEhKavyoiohZQU6fA/jNpiLqQCTMTQzwb6IbR/TvDwICtedJ/jW7XX7hwAUOHDkVJSQkuXryovvtdF/FKnoiEELgYL8NPxxJRXF4LX69OmDGmN6wsTLRdGlGzeuLx5Ddu3IjLly9j69atqKmpwddff42EhAS8+OKLzVooEVFzyCuqwvbIePyWVoyuUku8EOoB5y4dtF0WUYtr1JV8cHAwwsPDYWx89+aUuro6TJs2DQcPHtR4gU3BK3mitqlWrsSh2DRExGXA2MgAU0f2gt8gJxgaNOrbwkSt0hNfycvlcnXAA3cfR8uHRBCRrhBC4EriHew4mojCshoM7+eIp/16o4OlqbZLI9KqRoX8oEGD8Ne//lU9hvzevXvRv39/TddGRPRIBcVV2HE0EdeSC+Fk1w6vzx4It2422i6LSCc0ql1fVVWFzz77DLGxsTAyMsLw4cOxbNkymJubt0SNj43teiL9VydX4vC5dBw+lwFDQwmm+PaE/+AuMDJka57aliZ/T/6PSktL0aGD7t+8wpAn0m/Xku9ge1QCZCU1eKqPFM+MdYFNe7bmqW16WMg36k/elJQUBAUFITg4GPn5+Zg4cSKSk5ObtUgioke5U1KNL3Zfw6e/XIORoQFeDRuA50M9GPBED9CokF+/fj3eeust2NrawsHBAXPnzsU777yj6dqIiAAAcoUKB86mYfW/4vBbWhFmjOmNNQufQt8eHLiK6GEaPdTsiBEj1NNz5sxBRUWFxooiIqp3I7UQ73wbh/CTKfDsbYv3F3sjyLs7P3snaoRG3V0PALW1teqvzclkMqhUKo0VRURUVFaDn44l4mK8DA425vjL0/3h0ctW22URtSqNCvlZs2bhT3/6EwoLC/GPf/wDhw4dwqJFizRdGxG1QQqlClEXMrH/TBpUQmDqyJ6YMKw7jI145U70uB7r2fUxMTFQqVTw9fVt0L7XNby7nqh1upVejG2R8cgtrMIAZzvMHucCO2vd/Kouka544q/QzZ8/Hz/88EOzF6YpDHmi1qW4vBY/H09C3M182HUww+zxrhjgbKftsohahSd+rG15eTmqqqpgYWHRrIURUdumUKoQfSkLe0+nQqEUmDyiB4K8u8PE2FDbpRHphUaFvLm5Ofz8/ODm5tYg6P/5z39qrDAi0m8JmSXYFhmPLFklPHvZYvZ4FzjY8EKCqDk9MuQTEhLg7+8PX19fODo6tkRNRKTHSivr8MvxJJy9kQdbK1Msm+aJgS52HPSKSAMeGvK7d+/Ghx9+iO7duyMjIwMff/wxRo4c2VK1EZEeUapUiPk1B3tOpqBOrsSk4d0RPLwHTE3YmifSlIeG/NatW3HgwAE4ODjg119/xcaNGxnyRPTYkrJLse1IPDIKKtC3hw3mjHdFJ9t22i6LSO89sl3v4OAAABg4cCCKi4s1XhAR6Y+yqjrsiknG6Wu5sGlvihemeGCImz1b80Qt5KEh/8f/iIaGbKsR0aOpVAInr+Zg94lk1NQpMWFYN0we0QNmJo1+yCYRNYPH+h/Hv76J6FFSc8uw9Ug80vLK4d7NGnPGu8LJ/v7f4SUizXrow3D69u0LMzMz9XRNTQ3MzMwghIBEIsHly5dbpMjHxYfhELW8imo59pxIxokrObBqZ4JnxjpjWF8HXhwQaViTH4YTFRWlkYKISH+ohMDpa7nYFZOMqhoFxg3piikje8LclK15Im176P9CJyenlqqDiFqhjPxybI2MR3J2GVy6dMDcADd0lbI1T6Qr+Kc2ET22qho5wk+lIvpyFizNjfGnSX3g4+HI1jyRjmHIE1GjCSEQ+1sefj6ejPKqOvgNdMK0Ub1gYWas7dKI6D4Y8kTUKFkFFdgWGY+ErFL06myFFTP7o7tje22XRUQPwZAnooeqrlVg3+lUHL2YBQszIzw30R2+Xp1gwNY8kc5jyBPRfQkhcP5WAX6KTkRZRR1GDeiM6aN7w9KcrXmi1oIhT0T3yLlTie1RCbiVXozuju3x0jQv9Opspe2yiOgxMeSJSK2mToEDZ9IQeSETpsaGeDbAFaMHOMHAgK15otaIIU9EEELgUrwMPx5LRHF5LXw9O2GGX29YWZhouzQiegIaDfkDBw5g06ZNUCgUmD9/PubMmdNgflRUFD7//HOoVCp4enpi7dq1MDExQUFBAVavXo2CggKYmZnh448/RpcuXTRZKlGblV9UhW1RCfgttQhdpZZ4PrQfXLpYa7ssImoGBpp64/z8fGzcuBE7duzA3r17sXPnTiQlJannV1VVYe3atfjuu+9w6NAh1NbWIjw8HADw2muvwc/PD3v37kVoaCg+/vhjTZVJ1GbVypXYczIZb38bh5ScUswa54J3nhvCgCfSIxq7kj979iy8vb1hbW0NAAgMDERERASWLVsGALCwsEB0dDSMjY1RXV2NwsJCWFlZoaioCLdv38Z3330HAJg+fTqGDx+uqTKJ2hwhBK4k3sGOo4koLKvB8H4OeNrPGR0sTbVdGhE1M42FfEFBAezt7dXTUqkU165da7CMsbExTpw4gddeew1SqRS+vr5ISUlB586d8cEHH+DixYuwt7fH22+/rakyidqUgpJq7IhKwLXkQjjZtcPrswfCrZuNtssiIg3RWLtepVI1eI51/fC0fzR69GjExcXBz88P7733HhQKBW7evAlvb2/s3r0b/v7+WLVqlabKJGoT5Aol9p1Oxepv4hCfWYKn/Zzx7oKhDHgiPaexkHd0dIRMJlNPy2QySKVS9XRJSQlOnz6tng4JCUF8fDzs7e3Rrl07+Pn5AQCCg4Pv6QAQUeNdS76D1f+Kw77TqRjkaof3F3tjwrBuMDLU2H9/ItIRGvtf7uPjg9jYWBQVFaG6uhqRkZEYNWqUer4QAitXrkROTg4AICIiAoMGDUK3bt3g6OiIEydOAACOHz+Ofv36aapMIr11p7QaX+y+hk9/uQYjQwO8GjYAz4d6wKY9P3snaiskQgihqTc/cOAANm/eDLlcjhkzZmDx4sVYvHgxli9fDk9PTxw9ehSfffYZJBIJnJ2dsWbNGrRv3x4pKSl49913UVxcDEtLS3zwwQfo0aNHo7dbWFgBlUpju0Wk0+QKFY6cz8DBs2mABJg8oicChnbllTuRnjIwkMDW1vK+8zQa8trCkKe26rfUImyLSkB+URUGu9kjbKwLbDuYabssItKgh4U8n3hHpAeKymrwU3QSLt4ugNTGHCue7g/PXrbaLouItIwhT9SKKZQqRF3MxP7TaVAJgakje2LCsG4wNjLUdmlEpAMY8kSt1K30YmyLjEduYRUGONth1jgX2Fuba7ssItIhDHmiVqakohY7o5MQdzMfdh3MsHyGFwY422m7LCLSQQx5olZCqVLh2KVs7D2VAoVSYPKIHgjy7g4TY7bmiej+GPJErUBCZgm2RcYjS1YJj14dMWe8KxxsLLRdFhHpOIY8kQ4rrazDruNJOHMjD7ZWpvjzVE8McrW77yOiiYj+iCFPpINUKoHjv2Zjz8kU1MmVmDS8O4KH94CpCVvzRNR4DHkiHZOcXYqtkfHIyK9A3x42mDPeFZ1s22m7LCJqhRjyRDqivKoOu08k4+TVXFhbmuD50H4Y6i5la56ImowhT6RlKiFw8moOdscko6ZOiQlPdUPIiB4wN+V/TyJ6MvwtQqRFqbll2BYZj9Tccrh1tcbcAFc42d//GdRERI+LIU+kBRXVcuw5mYITv2ajfTsTLA7pC+++DmzNE1GzYsgTtSCVEDhzPRe/HE9GZY0c/kO6YIpvL1iY8b8iETU//mYhaiEZ+eXYFpmApOxSODt1wNwAV3RzaK/tsohIjzHkiTSsqkaB8FMpiL6cBUtzYywM6gMfT0cYsDVPRBrGkCfSECEEYn/Lw8/Hk1FeWYcxg5wwbVQvtDMz1nZpRNRGMOSJNCBLVoFtkQlIyCxBz05WeGWmF3o4Wmm7LCJqYxjyRM2oulaBfadTcfRiFsxNDTF/ghtG9u/M1jwRaQVDnqgZCCFw/lYBdkYnorSiDiP7d8aMMb1hac7WPBFpD0Oe6Anl3KnE9qgE3EovRneH9vjzNE/07txB22URETHkiZqqtk6J/WdTEXk+E6bGhng2wBWjBzjBwICteSLSDQx5osckhMCleBl+ik5EUVktRng6YuYYZ1i1M9F2aUREDTDkiR5DflEVtkcl4EZqEbrYW2Lp3H5w6WKt7bKIiO6LIU/UCLVyJQ7FpiMiLh3GRgaYNc4FYwc5wdDAQNulERE9EEOe6BF+TZThx6OJuFNag+H9HDDTzxnWlqbaLouI6JEY8kQPUFBSjR+jEnA1uRBOdu3w+uyBcOtmo+2yiIgajSFP9AdyhRL/OZeBQ+fSYWAgwdN+zhg3pAuMDNmaJ6LWhSFP9DvXkguxIyoBBSXVeKqPFM+MdYFNe7bmiah1YsgTASgsrcGPxxJxOUEGx44W+GvYAPTr0VHbZRERPRGGPLVpCqUKR85n4MCZNEACTB/dC4FPdWNrnoj0AkOe2qzf0oqwPTIBeUVVGOxqjzB/F9h2MNN2WUREzYYhT21OUVkNdkYn4cLtAkitzbHi6f7w7GWr7bKIiJodQ57aDIVShaMXs7DvdCpUQmDKyJ6YOKwbjI0MtV0aEZFGMOSpTbidXoxtUQnIuVOJAc52mDXOBfbW5toui4hIoxjypNdKKmrx8/EknPstH3YdzLB8uhcGuNhpuywiohah0VuIDxw4gKCgIAQEBGD79u33zI+KikJISAgmTZqEVatWoa6ursH8mzdvwsPDQ5Mlkp5SqlSIupCJt745h4u3CxDi0wPrFw1jwBNRm6KxK/n8/Hxs3LgRe/bsgYmJCcLCwjBs2DA4OzsDAKqqqrB27VqEh4fDzs4OK1asQHh4OJ555hkAQHV1NdatWwe5XK6pEklPJWaVYOuRBGTJKuDRsyPmjHeFQ0cLbZdFRNTiNHYlf/bsWXh7e8Pa2hoWFhYIDAxERESEer6FhQWio6NhZ2eH6upqFBYWwsrKSj3/gw8+wPz58zVVHumhsso6fHvwJv627TKqauX481QPrHi6PwOeiNosjV3JFxQUwN7eXj0tlUpx7dq1BssYGxvjxIkTeO211yCVSuHr6wsAOHbsGGpqajBhwgRNlUd6RKUSiLmSjT0nUlArVyLIuztCfHrA1IR3zRNR26axkFepVJBIJOppIUSD6XqjR49GXFwcPvnkE7z33ntYtWoVNm3ahO+//15TpZEeSc4pxbYjCUjPL0ef7jaYG+CKTrbttF0WEZFO0Fi73tHRETKZTD0tk8kglUrV0yUlJTh9+rR6OiQkBPHx8YiJiUFJSQnmzJmD0NBQAEBoaCgqKio0VSq1QuVVdfj+P7ewYcsllFbW4vnQfng1bAADnojodzR2Je/j44MvvvgCRUVFMDc3R2RkJNatW6eeL4TAypUrsXv3bnTu3BkREREYNGgQZs6ciZkzZ6qXc3Nzw759+zRVJrUyKiFw8moOdscko7pWicCnumLyiJ4wN+W3QYmI/khjvxkdHBywYsUKzJs3D3K5HDNmzICXlxcWL16M5cuXw9PTE+vWrcPSpUshkUjg7OyMNWvWaKoc0gNpeWXYeiQBqbllcO1qjbkBruhib6ntsoiIdJZECCG0XURzKyysgEqld7vVZlXWyLHnRApifs1G+3YmeMbPGd79HO57jwcRUVtjYCCBre39L3jY4ySdpRICZ67n4pfjyaiskcN/cBdMGdkLFmY8bYmIGoO/LUknZeSXY1tkApKyS+Hs1AFzA1zRzaG9tssiImpVGPKkU6pqFNh7KgXHLmfB0twYC4P6wMfTEQZszRMRPTaGPOkEIQTO/ZaPnceTUF5ZhzEDnTBtdC+0MzPWdmlERK0WQ560LltWgW2RCYjPLEHPTlZ4ZaYXejhaPXpFIiJ6KIY8aU11rQL7z6Ti6MUsmJkYYv4EN4zs35mteSKiZsKQpxYnhMCF2wX46VgiSirqMKp/Z0wf3QvtLUy0XRoRkV5hyFOLyi2sxPaoBNxMK0Z3h/b48zRP9O7cQdtlERHpJYY8tYjaOiUOnE3DkfMZMDU2xNwAV4wZ4AQDA7bmiYg0hSFPGiWEwOUEGX48loiislqM8HTEzDHOsGrH1jwRkaYx5Elj8ouqsP1oAm6kFKGLvSWWzOkH167W2i6LiKjNYMhTs6uTK3EoNh3/iUuHkaEBZvm7YOxgJxgaaGxkYyIiug+GPDWrK4l3sONoAu6U1sC7nwOe9nOGtaWptssiImqTGPLULGQl1fjxaCKuJN1BZ7t2eG3WQLh3t9F2WUREbRpDXkckZZciPqMYbt1s4OzUer5SJlco8Z+4DByKTYeBRIKn/ZwxbkgXGBmyNU9EpG0MeR2QlF2Kv++4DIVSwNjIACtnDWwVQX89pRDboxJQUFyNoe5SPDPWGR2tzLRdFhER/RdDXgfcSC2EQikAAEqlCvEZxTod8oWlNfjpWCIuJcjg0NECfw0bgH49Omq7LCIi+gOGvA7IL6wGAEgkgKGhAdy66eZn2QqlCkfOZ+DA2TRAANNH90LA0G4wNmJrnohIFzHktSyzoAIXbhdggLMdejtZ6exn8jfTirAtMgF5RVUY5GqPMH9n2HUw13ZZRET0EAx5LVIJga1H4mFhZoSFk/rA0lz3xk4vLq/FT8cSceF2AaTW5nhlZn949bbVdllERNQIDHktOn0tF0nZpfiTDga8QqnC0YtZ2HcmFSqVwBTfnpjo3Q3GRobaLo2IiBqJIa8lZVV1+OV4Ety6WsPHw1Hb5TQQn1GMbZEJyL5TCa/etpg93hVSa7bmiYhaG4a8lvxyPAk1dUrMDXSDRKIbI7GVVtRi5/EknPstH7ZWZnhpuicGuthruywiImoihrwWxGcU48z1PEwa3h1Odu20XQ6UKhWiL2Vj7+kUyBUqBPv0wKTh3WFqzNY8EVFrxpBvYQqlCluOxMOugxmCfXpouxwkZpVg65EEZMkq4NGzI+aMd4VDRwttl0VERM2AId/CjpzPQG5hFV6e4aXVK+Wyyjr8EpOEM9fzYNPeFC9O8cBgN3ud+eiAiIieHEO+BclKqnHgTBoGu9qjv7OdVmpQqQRirmRjz4kU1MqVmOjdDZN9esLUhK15IiJ9w5BvIUIIbI9KgEQiwaxxLlqpISWnDFsj45GeV44+3W0wZ7wrOuvAPQFERKQZDPkWcjnhDq4lF2plEJeKajl2xSTj1NUcdLA0wfOh/TDUXcrWPBGRnmPIt4DqWgV2HE1AV6klxg3p0mLbVQmB09dysSsmGVU1CgQ81RWTR/SEuSl/7EREbQF/27eAfadTUVxeixemeMDQoGUGc0nPK8fWyHik5JTBtas15ga4oou9ZYtsm4iIdANDXsMy8stx9GIWRg/o3CIDz1TWyLHnZApiLmejfTsTLA7uC+9+DmzNExG1QQx5DaofgKaduRGmj+6t8W2dvZ6HX2KSUFEth//gLpgysicszHTrmfhERNRyGPIadPJqDpJzyjQ+AE1mQQW2RsYjKasUvZ2s8NdnBqCbQ3uNbY+IiFoHhryGlFXWYXdMskYHoKmqUWDv6RREX8qGhZkRFgS5Y4RnJxiwNU9ERGDIa8zP/x2A5lkNDEAjhMC5m/n4OToJZZV1GDPQCVNH9dK54WqJiEi7NBryBw4cwKZNm6BQKDB//nzMmTOnwfyoqCh8/vnnUKlU8PT0xNq1a2FiYoJLly7hb3/7G+RyOaytrfH+++/DyclJk6U2q9vpxTh74+4ANM39sJlsWQW2RSYgPrMEPTu1x/IZXujZyapZt0FERPpBIoQQmnjj/Px8zJo1C3v27IGJiQnCwsLwySefwNnZGQBQVVWFwMBAhIeHw87ODitWrIC3tzeeeeYZjB07Fl999RXc3d2xa9cuHDt2DJs2bWr0tgsLK6BSaWS3HkmhVOHdf5+HXKHCukXDmu359NW1Chw4k4aoi5kwMzHE9DG9Map/Z7bmiYjaOAMDCWxt7/8VaY19afvs2bPw9vaGtbU1LCwsEBgYiIiICPV8CwsLREdHw87ODtXV1SgsLISVlRXq6urw8ssvw93dHQDg5uaG3NxcTZXZ7CLi7g5AMzfAtVkCXgiB87fysfpfcYg4n4ERno54f4k3xgxwYsATEdFDaaxdX1BQAHt7e/W0VCrFtWvXGixjbGyMEydO4LXXXoNUKoWvry9MTEwQGhoKAFCpVPjyyy8xbtw4TZXZrApKqnHgbBoGu9nDq/eTD0CTW1iJ7VEJuJlWjG4Olnhxigd6t8B37YmISD9o7EpepVI1uOFMCHHfG9BGjx6NuLg4+Pn54b333lO/XldXh1dffRUKhQJLly7VVJnNRgiB7ZEJMDCQYJb/kw1AU1unxO4TyXjn2/NIzS3HnPGueGf+UAY8ERE9Fo2FvKOjI2QymXpaJpNBKpWqp0tKSnD69Gn1dEhICOLj4wEAlZWVWLRoERQKBTZt2gRjY92/a/xSvAzXUwox1bdnkwegEULgUrwMq/91Dodi0+Hd1wF/W+IN/8FdYGDA1jwRET0ejYW8j48PYmNjUVRUhOrqakRGRmLUqFHq+UIIrFy5Ejk5OQCAiIgIDBo0CACwcuVKdO/eHZ9++ilMTEw0VWKzqa5V4MdjiegqtYR/EwegyS+uwqe/XMP/hV+HuakRVs0ZhD8F94VVO93ffyIi0k0au7seuPsVus2bN0Mul2PGjBlYvHgxFi9ejOXLl8PT0xNHjx7FZ599BolEAmdnZ6xZswaZmZmYOnUqnJ2dYWR095YBqVSKb775ptHbbem76386loioC5l489nBj91Sr5MrcfhcOg6fy4CRoQRTRvaC/2CnFhvIhoiIWreH3V2v0ZDXlpYM+Yz8cqz5/gJG9++MeRPcH2vdK0l3sCMqAXdKa+Dd1wEz/Zxh095UQ5USEZE+eljI84l3T0AlBLYciYeluTGmj2n8ADSykmr8eDQRV5LuoJOtBVbOGog+3W00WCkREbVFDPkncPJKDlJyyrAouA/aNWK0N7lCif/EZeBQbDoMJBLM9OuN8UO6wsiQrXkiImp+DPkmKq2sw66YZLh3s8bwfo8egOZGSiG2RSWgoLgaQ9ylCBvr3OS78ImIiBqDId9EP0cnoVb+6AFoispq8OPRRFxKkMGhowX+8kx/ePS0bcFKiYiorWLIN8Gt9GLE/paHYJ/u6GR7/wFoFEoVIi9kYv+ZVEAA00b1QuBT3WBsxNY8ERG1DIb8Y5IrVNh6JB721mYIHt7jvsvcSivCtqgE5BZWYaCLHWaNc4FdB/OWLZSIiNo8hvxjijifgbyiKrwysz9M/jAATXF5LXZGJ+L8rQJIrc3xykyvZnmGPRERUVMw5B9DQXEVDp5NwxA3e3j1/t/n6gqlCscuZWHv6VQolQKhvj0R5N0NxkbNM8wsERFRUzDkG0kIgW1R/x2AZpyr+vX4jGJsi0pAtqwSXr1tMXu8K6TWbM0TEZH2MeQb6VK8DDdSihDm7wKb9qYorajFz8eTEPtbPmytzPDSdE8McLZ76J32RERELYkh3wjVtQrsOJqAblJL+A10wtGLmQg/lQK5QoVgnx6YNLw7TI3ZmiciIt3CkG+E8FMpKK2ow4Rh3bFhy0VkFFSgX8+OmDPeFY4dLbRdHhER0X1xgJqHSMouxbnf8hB9ORuGBhIoVQI27U0xy98Fg93s2ZonIiKt4wA1TZCUXYqPfvwVcoUKwN0b7yZ6d0OITw+YmfCwERGR7mNaPUB8RjEUSpV62n9wF8wc46zFioiIiB4Pn7H6AG7dbGBkaACJBDA2MsDQPg7aLomIiOix8DP5h0jKLkV8RjHcutnA2alDM1RGRETUvB72mTxDnoiIqBV7WMizXU9ERKSnGPJERER6iiFPRESkpxjyREREeoohT0REpKcY8kRERHqKIU9ERKSnGPJERER6iiFPRESkpxjyREREekovR6EzMOA470RE1DY8LPP08tn1RERExHY9ERGR3mLIExER6SmGPBERkZ5iyBMREekphjwREZGeYsgTERHpKYY8ERGRnmLIExER6SmGPBERkZ5qdSF/4MABBAUFISAgANu3b79n/tGjRxEaGorJkyfjxRdfRGlpKQAgPDwcvr6+CA0NRWhoKDZu3NjSpeuMRx3DqKgohISEYNKkSVi1ahXq6uoAADk5OZgzZw4mTJiAF154AZWVlS1duk5p6nHkufg/jzqG9WJiYjB27Fj1NM/Fhpp6HHkuNvSo4/jll1/Cz89Pfbzql9Hp81G0Inl5ecLPz08UFxeLyspKERISIhITE9Xzy8vLxYgRI0ReXp4QQohPP/1UrFu3TgghxNq1a8WBAwe0UrcuedQxrKysFL6+vkImkwkhhHjllVfETz/9JIQQYsmSJeLgwYNCCCG+/PJL8fe//73ld0BHPMlx5Ll416OOYT2ZTCYmTJgg/Pz81K/xXPyfJzmOPBf/pzHHcenSpeLy5cv3rKvL52OrupI/e/YsvL29YW1tDQsLCwQGBiIiIkI9Xy6X491334WDgwMAwM3NDbm5uQCA69evIzw8HCEhIXj11VfVV/htzaOOoYWFBaKjo2FnZ4fq6moUFhbCysoKcrkcFy5cQGBgIABg2rRpDdZra5p6HAGei/UedQzrrV69GsuWLVNP81xsqKnHEeC5+HuNOY43btzA5s2bERISgrVr16K2tlbnz8dWFfIFBQWwt7dXT0ulUuTn56unbWxsMH78eABATU0Nvv76a4wbNw4AYG9vjxdffBH79+9Hp06dsHbt2pYtXkc86hgCgLGxMU6cOIExY8aguLgYvr6+KC4uhqWlJYyM7g5caG9vf896bUlTjyPAc7FeY47hli1b0LdvX/Tv31/9Gs/Fhpp6HAGei7/3qONYWVmJPn36YOXKlQgPD0dZWRm++uornT8fW1XIq1QqSCT/G1JPCNFgul55eTmWLFkCd3d3TJ06FQDwf//3fxg8eDAkEgkWLVqEU6dOtVjduqSxx3D06NGIi4uDn58f3nvvvfsud7/12oqmHkeA52K9Rx3DhIQEREZG4sUXX2ywHs/Fhpp6HAGei7/3qOPYrl07fPPNN+jduzeMjIywcOFCnDhxQufPx1YV8o6OjpDJZOppmUwGqVTaYJmCggLMnj0bbm5u2LBhA4C7of/999+rlxFCwNDQsEVq1jWPOoYlJSU4ffq0ejokJATx8fHo2LEjysvLoVQq77teW9PU48hz8X8edQwjIiIgk8kwffp0LFmyRP1/m+diQ009jjwXG3rUcczJycGuXbvU00IIGBkZ6fz52KpC3sfHB7GxsSgqKkJ1dTUiIyMxatQo9XylUonnn38eEydOxFtvvaX+a8rCwgL/+te/cPXqVQDAtm3b1G39tuZRx1AIgZUrVyInJwfA3V8QgwYNgrGxMYYMGYLDhw8DAPbu3dtgvbamqceR5+L/POoYLl++HEeOHMG+ffvw9ddfQyqVYseOHTwX/6Cpx5HnYkOPOo5mZmb46KOPkJmZCSEEtm/fjvHjx+v++djy9/o9mf3794tJkyaJgIAA8fXXXwshhFi0aJG4du2aiIyMFG5ubmLy5Mnqf2+++aYQQogLFy6IKVOmiAkTJojnn39elJWVaXM3tOphx1AIIaKiokRwcLAICQkRK1asUB+rrKwsMXfuXDFx4kSxcOFCUVJSorV90AVNPY48F//nUcewXmZmZoO7wnkuNtTU48hzsaFHHceIiAj1/FWrVona2lohhG6fjxIhhND2HxpERETU/FpVu56IiIgajyFPRESkpxjyREREeoohT0REpKcY8kRERHrKSNsFEJHucHNzg6urKwwMDCCRSFBdXQ1LS0u899578PT0bNZtZWVlISQkBL/++iu++OILFBcX45133mnWbRC1dQx5Imrghx9+QMeOHdXT3377LdavX4+dO3dqsSoiagqGPBE9kEKhQG5uLjp06KB+bdOmTYiMjIRKpYKTk5N65EeZTIZ3330XKSkpMDAwQFhYGObNm4crV67go48+Ql1dHWQyGXx8fPD+++9rca+I2g6GPBE1MH/+fAB3R3szNTWFn58f/va3vwG4+8jOhIQE/PLLLzAyMsLOnTuxevVqfPPNN1izZg169OiBr776CuXl5Zg1axZGjx6NLVu2YPny5Rg2bBgqKyvh7++PGzduwNraWot7SdQ2MOSJqIH6dv1vv/2GJUuWYNiwYbC1tQUAHD9+HNevX8f06dMB3B25q7q6GsDd8bhXrlwJAGjfvj0OHjwIAPjggw9w8uRJ/POf/0RKSgpqa2tRVVXFkCdqAQx5Irqvfv364Y033sCqVavQp08fdOnSBSqVCosWLcLs2bMBAHV1dSgtLQUAGBkZNRhiMzMzEzY2Nli4cCHc3NwwcuRITJw4EVevXgWfpk3UMvgVOiJ6oODgYHh5eanb9b6+vti1axcqKioAAJ999hlee+01AMDw4cOxe/duAHeHd54/fz7S0tJw/fp1vPrqqwgICEBeXh4yMjKgUqm0s0NEbQyv5Inood5++21MnjwZp06dwsyZM5Gfn4+nn34aEokEnTp1wgcffAAAeOedd/Dee+8hJCQEQggsXboUHh4eWLJkCaZOnQoLCws4ODhg0KBBSE9PR9euXbW8Z0T6j6PQERER6Sm264mIiPQUQ56IiEhPMeSJiIj0FEOeiIhITzHkiYiI9BRDnoiISE8x5ImIiPQUQ56IiEhP/T+6LCm0rVvtSwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# very iffy \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Continue with the code to plot the macro-averaged precision-recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Macro-Averaged Precision-Recall Curve')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 36 Matt's Version \n",
    "\n",
    "\n",
    "# # Evaluate the model on the test set IT STOPS working here on score\n",
    "# score = rf.score(X_test1, y_test1)\n",
    "# print(f\"  Test score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_q1 shape: (35680, 60)\n",
      "X_test_q1 shape: (237840,)\n",
      "y_train1 shape: (35680,)\n",
      "y_test1 shape: (3964,)\n",
      "y_pred shape: (7928,)\n"
     ]
    }
   ],
   "source": [
    "# 37 \n",
    "\n",
    "# Sanity Check the shape of the data \n",
    "\n",
    "# import numpy as np  # Assuming you are using NumPy for your data\n",
    "# import numpy as np\n",
    "\n",
    "# # Convert lists to NumPy arrays\n",
    "# X_train_q1 = np.array(X_train_q1)\n",
    "# X_test_q1 = np.array(X_test_q1)\n",
    "# y_train1 = np.array(y_train1)\n",
    "# y_test1 = np.array(y_test1)\n",
    "\n",
    "\n",
    "# # Now you can use the shape attribute\n",
    "# print(\"X_train_q1 shape:\", X_train_q1.shape)\n",
    "# print(\"X_test_q1 shape:\", X_test_q1.shape)\n",
    "# print(\"y_train1 shape:\", y_train1.shape)\n",
    "# print(\"y_test1 shape:\", y_test1.shape)\n",
    "# print(\"y_pred shape:\", y_pred.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 38 Matt's Version\n",
    "\n",
    "# Make predictions on the test set for share_quantile_ranges task\n",
    "# rf_y_pred_q1 = rf.predict(X_test_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 39 Matt's Version \n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the share_quantile_ranges task.\n",
    "# rf_accuracy_q1 = accuracy_score(y_test1, rf_y_pred_q1)\n",
    "# rf_precision_q1 = precision_score(y_test1, rf_y_pred_q1, average='macro')\n",
    "# rf_recall_q1 = recall_score(y_test1, rf_y_pred_q1, average='macro')\n",
    "# rf_f1_score_q1 = f1_score(y_test1, rf_y_pred_q1, average='macro')\n",
    "\n",
    "# # Create an array to store the model evaluation metrics\n",
    "# rf_model_scores_q1 = np.array([rf_accuracy_q1, rf_precision_q1, rf_recall_q1, rf_f1_score_q1])\n",
    "\n",
    "# # Print the model evaluation metrics\n",
    "# print('Random Forest on share_quantile_ranges Task')\n",
    "# print(rf_model_scores_q1)\n",
    "# print('---------------------------------------------------------')\n",
    "# print('Random Forest accuracy:', rf_accuracy_q1)\n",
    "# print('Random Forest precision:', rf_precision_q1)\n",
    "# print('Random Forest recall:', rf_recall_q1)\n",
    "# print('Random Forest F1 score:', rf_f1_score_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust parameters as appropriate to increase generalization performance using our chosen metric F1 Score (indicated by scoring=\"f1_macro\" in the cell below).\n",
    "\n",
    "### The approach for adjusting parameters was two step process. First we chose two key hyper-parameters and performed a Random Grid Search. Using the best parameters of the Random Grid Search we were able to scope the hyper-parameters and tune the mode on a regular Grid Search to determine the best values. Because of the computational time we use a parallel backend use the n_jobs parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40 Tim's Version \n",
    "\n",
    "# Step 1 get the randomized grid search to scope the most important hyper parameter values \n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "###################################################################\n",
    "# Define the parameter grid to search over\n",
    "\n",
    "# RUN for final scores \n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "\n",
    "# Run for testing purposes only \n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "##################################################################\n",
    "\n",
    "\n",
    "#reduced to run faster - chose f1-score average as scorer \n",
    "# random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=5, scoring='f1_macro')\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "\n",
    "random_search.fit(X_train1, y_train1)\n",
    "# Get the results of the random search\n",
    "results = random_search.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 41 Tim's Version\n",
    "\n",
    "# Heat Map RF 1 \n",
    "# Comparing a parameters RANDOM GRID SEARCH HEAT MAP\n",
    "\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have already run RandomizedSearchCV and have 'results' available\n",
    "\n",
    "# Extract the scores and corresponding hyperparameters\n",
    "scores = results['mean_test_score']\n",
    "n_estimators_values = [params['n_estimators'] for params in results['params']]\n",
    "min_samples_split_values = [params['min_samples_split'] for params in results['params']]\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'n_estimators': n_estimators_values, 'min_samples_split': min_samples_split_values, 'Score': scores})\n",
    "\n",
    "# Pivot the DataFrame to create a 2D grid\n",
    "heatmap_data = df.pivot_table(index='n_estimators', columns='min_samples_split', values='Score', aggfunc='mean')\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='viridis')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('n_estimators')\n",
    "plt.title('Performance Heatmap')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat Map of mean cross-validation score as a function of n_estimators and min_samples_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model score for the RF model on the test set: 0.28\n",
      "Best CV F1  score for the RF model: 0.26\n",
      "Best parameters: {'n_estimators': 10, 'min_samples_split': 5}\n",
      "Best Estimator: \n",
      "RandomForestClassifier(min_samples_split=5, n_estimators=10)\n"
     ]
    }
   ],
   "source": [
    "# 43 Tim's Version  VIZ -- Duplicate To the right section \n",
    "\n",
    "# Calculate the score on the test set using the best estimator\n",
    "best_model_rf = random_search.best_estimator_\n",
    "best_model_test_set_score = best_model_rf.score(X_test_q1, y_test1)\n",
    "print(\"Best model score for the RF model on the test set: {:.2f}\".format(best_model_test_set_score))\n",
    "\n",
    "# The mean accuracy or best CV accuracy over the different splits for this parameter setting\n",
    "best_CV_score_rf = random_search.best_score_\n",
    "print(\"Best CV F1  score for the RF model: {:.2f}\".format(best_CV_score_rf))\n",
    "\n",
    "# Accessing the best parameters that were found\n",
    "best_params_rf_model = random_search.best_params_\n",
    "print(\"Best parameters: {}\".format(best_params_rf_model))\n",
    "\n",
    "# Accessing the model with the best parameters trained on the whole training set\n",
    "print(\"Best Estimator: \\n{}\".format(best_model_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the Grid Search we take the best hyper-parameter values generated by the random grid search and double their values to do a search within that range to further tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model score for the RF model on the test set (Grid Search): 0.27\n",
      "Best parameters: {'min_samples_split': 5, 'n_estimators': 90}\n"
     ]
    }
   ],
   "source": [
    "# 44 Tim's Version \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# ignore warnings \n",
    "import warnings\n",
    "# To ignore all warnings (not recommended for debugging):\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# To ignore a specific type of warning, e.g., DeprecationWarning:\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "#based off the best params you woud then run a grid search based off the best params_\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Extract the best parameters from the random search\n",
    "best_random_params = random_search.best_params_\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# YOU MUST CHANGE THE VALUE BASED OFF THE BEST PARAMETER FOR THAT HYPERPARAMETER \n",
    "param_grid_grid_search = {\n",
    "    'n_estimators': [90, 100, 140],\n",
    "    'min_samples_split': [3, 5, 25]\n",
    "}\n",
    "#######################################################################################\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid_grid_search, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train1, y_train1)\n",
    "\n",
    "# Get the results of the grid search\n",
    "grid_search_results = grid_search.cv_results_\n",
    "\n",
    "# Evaluate the model's performance using the test set\n",
    "best_model_rf_grid_search = grid_search.best_estimator_\n",
    "best_model_test_set_score_grid_search = best_model_rf_grid_search.score(X_test_q1, y_test1)\n",
    "print(\"Best model score for the RF model on the test set (Grid Search): {:.2f}\".format(best_model_test_set_score_grid_search))\n",
    "\n",
    "# Accessing the best parameters that were found\n",
    "best_params_rf_model = grid_search.best_params_\n",
    "print(\"Best parameters: {}\".format(best_params_rf_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45 Matt's Version \n",
    "# \n",
    "# Make predictions on the test set for share_quantile_ranges task\n",
    "# rf_y_pred_q1 = rf.predict(X_test_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2: day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 46 Matt's Version \n",
    "# \n",
    "# Train the day_of_week task\n",
    "rf.fit(X_train_q2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 47 Matt's Version \n",
    "# \n",
    "# \n",
    "# Make predictions on the test set for day_of_week task\n",
    "rf_y_pred_q2 = rf.predict(X_test_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 48 Matt's Version \n",
    "# \n",
    "# \n",
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for day_of_week task.\n",
    "# rf_accuracy_q2 = accuracy_score(y_test2, rf_y_pred_q2)\n",
    "# rf_precision_q2 = precision_score(y_test2, rf_y_pred_q2, average='macro')\n",
    "# rf_recall_q2 = recall_score(y_test2, rf_y_pred_q2, average='macro')\n",
    "# rf_f1_score_q2 = f1_score(y_test2, rf_y_pred_q2, average='macro')\n",
    "\n",
    "# # Create an array to store the model evaluation metrics\n",
    "# rf_model_scores_q2 = np.array([rf_accuracy_q2, rf_precision_q2, rf_recall_q2, rf_f1_score_q2])\n",
    "\n",
    "# # Print the model evaluation metrics\n",
    "# print('Random Forest on day_of_week Task')\n",
    "# print(rf_model_scores_q2)\n",
    "# print('---------------------------------------------------------')\n",
    "# print('Random Forest accuracy:', rf_accuracy_q2)\n",
    "# print('Random Forest precision:', rf_precision_q2)\n",
    "# print('Random Forest recall:', rf_recall_q2)\n",
    "# print('Random Forest F1 score:', rf_f1_score_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    7    16    37 ... 39623 39632 39636]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     3 ... 39640 39642 39643]\n",
      "  Test:  index=[    2    12    18 ... 39630 39631 39641]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   19    22    62 ... 39565 39586 39619]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   61    64    72 ... 39624 39634 39640]\n",
      "Fold 0:\n",
      "  Train: index=[    0     2     4 ... 39641 39642 39643]\n",
      "  Test:  index=[    1     3     8 ... 39626 39627 39633]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39640 39641 39642]\n",
      "  Test:  index=[   21    44    47 ... 39600 39628 39643]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   14    28    34 ... 39625 39635 39637]\n",
      "Fold 0:\n",
      "  Train: index=[    1     2     3 ... 39641 39642 39643]\n",
      "  Test:  index=[    0    10    11 ... 39605 39618 39639]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    5     9    23 ... 39609 39621 39629]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39640 39641 39643]\n",
      "  Test:  index=[    4     6    13 ... 39617 39638 39642]\n"
     ]
    }
   ],
   "source": [
    "# 49 Tim's Version \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# Create a StratifiedKFold object with n_splits=10\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state = random_state)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state = random_state)\n",
    "\n",
    "# Remove target, related variables, and factor other targets due to them being categorical\n",
    "X0 = pd.get_dummies(df1, columns=['news_category'])\n",
    "X2 = X0.drop(['share_quantile_ranges', 'day_of_week'], axis=1) # Removing target categorical variable and other categorical variables\n",
    "y2 = X0.loc[:,'day_of_week']\n",
    "\n",
    "# Instantiate transformers\n",
    "quantile_transformer = QuantileTransformer(n_quantiles=100, output_distribution='normal')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "f1_scores2 = []\n",
    "accuracy_scores2 = []\n",
    "precision_scores2 = []\n",
    "recall_scores2 = []\n",
    "\n",
    "# precision_scores, recall_scores = [], []  # Initialize lists to store precision and recall\n",
    "\n",
    "X_train_list2, X_test_list2, y_train_list2, y_test_list2 = [], [], [], []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X2, y2)):\n",
    "    print(f\"Fold {0}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "    X_train2 = np.array(X2.iloc[train_index].to_numpy())\n",
    "    X_test2 = np.array(X2.iloc[test_index].to_numpy())\n",
    "    y_train2 = np.array(y2.iloc[train_index].to_numpy())\n",
    "    y_test2 = np.array(y2.iloc[test_index].to_numpy())\n",
    "\n",
    "    # Scale and Quantile Transform for this fold\n",
    "    # X_train_fold = quantile_transformer.fit_transform(X_train_fold)\n",
    "    # X_test_fold = quantile_transformer.transform(X_test_fold)\n",
    "    X_train_fold2 = scaler.fit_transform(X_train2)\n",
    "    X_test_fold2 = scaler.transform(X_test2)\n",
    "    X_train_q2 = quantile_transformer.fit_transform(X_train_fold2)\n",
    "    X_test_q2 = quantile_transformer.transform(X_test_fold2)\n",
    "\n",
    "    # Instantiate and fit the model (e.g., RandomForestClassifier)\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "    # rf = RandomForestClassifier(n_estimators=100)\n",
    "    rf.fit(X_train_q2, y_train2)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    rf_y_pred_q2 = rf.predict(X_test_q2)\n",
    "\n",
    "\n",
    "    # Calculate accuracy and F1 score for this fold\n",
    "    accuracy = accuracy_score(y_test2, rf_y_pred_q2)\n",
    "    # f1 = f1_score(y_test1, rf_y_pred_q1)\n",
    "    f1 = f1_score(y_test2, rf_y_pred_q2, average='macro')\n",
    "    precision = precision_score(y_test2, rf_y_pred_q2, average=None)\n",
    "    recall = recall_score(y_test2, rf_y_pred_q2, average= None)\n",
    "\n",
    "    accuracy_scores2.append(accuracy)\n",
    "    f1_scores2.append(f1)\n",
    "    precision_scores2.append(precision)\n",
    "    recall_scores2.append(recall)\n",
    "    \n",
    "    X_train_list2.append(X_train2)\n",
    "    X_test_list2.append(X_test2)\n",
    "    y_train_list2.append(y_train2)\n",
    "    y_test_list2.append(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle Results 2 \n",
    "\n",
    "import pickle\n",
    "\n",
    "# Create a dictionary to store all the data\n",
    "data_to_save = {\n",
    "    'X_train_list2': X_train_list2,\n",
    "    'X_test_list2': X_test_list2,\n",
    "    'y_train_list2': y_train_list2,\n",
    "    'y_test_list2': y_test_list2,\n",
    "    'accuracy_scores2': accuracy_scores2,\n",
    "    'f1_scores2': f1_scores2,\n",
    "    'precision_scores2': precision_scores2,\n",
    "    'recall_scores2': recall_scores2\n",
    "}\n",
    "\n",
    "# Save the data to a file\n",
    "with open('data_and_scores_rf2.pkl', 'wb') as file:\n",
    "    pickle.dump(data_to_save, file)\n",
    "\n",
    "\n",
    "\n",
    "# # Pickle Results Load 1: \n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the lists and scores from the file\n",
    "with open('data_and_scores_rf2.pkl', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "X_train_list2 = loaded_data['X_train_list2']\n",
    "X_test_list2 = loaded_data['X_test_list2']\n",
    "y_train_list2 = loaded_data['y_train_list2']\n",
    "y_test_list2 = loaded_data['y_test_list2']\n",
    "accuracy_scores2 = loaded_data['accuracy_scores2']\n",
    "f1_scores2 = loaded_data['f1_scores2']\n",
    "precision_scores2 = loaded_data['precision_scores2']\n",
    "recall_scores2 = loaded_data['recall_scores2']\n",
    "\n",
    "# print(recall_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest on Task 2: day_of_week\n",
      "[0.28657921 0.33733766 0.33267144 0.33157025]\n",
      "---------------------------------------------\n",
      "Random Forest accuracy: 0.2865792129162462\n",
      "Random Forest precision: 0.33733765938904015\n",
      "Random Forest recall: 0.3326714387186743\n",
      "Random Forest F1 score: 0.3315702463018108\n"
     ]
    }
   ],
   "source": [
    "# 50 Tim's Version \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "rf_accuracy_q2 = accuracy_score(y_test2, rf_y_pred_q2)\n",
    "rf_precision_q2 = precision_score(y_test2, rf_y_pred_q2, average='macro')\n",
    "rf_recall_q2 = recall_score(y_test2, rf_y_pred_q2, average='macro')\n",
    "rf_f1_score_q2 = f1_score(y_test2, rf_y_pred_q2, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics\n",
    "rf_model_scores_q2 = np.array([rf_accuracy_q2, rf_precision_q2, rf_recall_q2, rf_f1_score_q2])\n",
    "\n",
    "# Print the model evaluation metrics\n",
    "print('Random Forest on Task 2: day_of_week')\n",
    "print(rf_model_scores_q2)\n",
    "print('---------------------------------------------')\n",
    "print('Random Forest accuracy:', rf_accuracy_q2)\n",
    "print('Random Forest precision:', rf_precision_q2)\n",
    "print('Random Forest recall:', rf_recall_q2)\n",
    "print('Random Forest F1 score:', rf_f1_score_q2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust parameters as appropriate to increase generalization performance using your chosen metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 51 Tim's Version \n",
    " \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Identify the most important hyperparameters\n",
    "# Define the parameter grid to search \n",
    "###################################################################\n",
    "# Define the parameter grid to search over\n",
    "\n",
    "# RUN for final scores \n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "\n",
    "# Run for testing purposes only \n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "##################################################################\n",
    "#reduced to run faster - chose f1-score average as scorer \n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "\n",
    "random_search.fit(X_train2, y_train2)\n",
    "# Get the results of the random search\n",
    "results2 = random_search.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 52 Tim's Version \n",
    "\n",
    "# Tim's Version Heat Map RF  2 day of week \n",
    "\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the scores and corresponding hyperparameters\n",
    "scores = results2['mean_test_score']\n",
    "n_estimators_values = [params['n_estimators'] for params in results2['params']]\n",
    "min_samples_split_values = [params['min_samples_split'] for params in results2['params']]\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'n_estimators': n_estimators_values, 'min_samples_split': min_samples_split_values, 'Score': scores})\n",
    "\n",
    "# Pivot the DataFrame to create a 2D grid\n",
    "heatmap_data = df.pivot_table(index='n_estimators', columns='min_samples_split', values='Score', aggfunc='mean')\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='viridis')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('n_estimators')\n",
    "plt.title('Performance Heatmap: day_of_week')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust parameters as appropriate to increase generalization performance using your chosen metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model score for the RF model on the test set: 0.17\n",
      "Best CV F1  score for the RF model: 0.29\n",
      "Best parameters: {'n_estimators': 20, 'min_samples_split': 2}\n",
      "Best Estimator: \n",
      "RandomForestClassifier(n_estimators=20)\n"
     ]
    }
   ],
   "source": [
    "# 53 Tim's Version \n",
    "\n",
    "# Calculate the score on the test set using the best estimator\n",
    "best_model_rf = random_search.best_estimator_\n",
    "best_model_test_set_score = best_model_rf.score(X_test_q2, y_test2)\n",
    "print(\"Best model score for the RF model on the test set: {:.2f}\".format(best_model_test_set_score))\n",
    "\n",
    "# The mean accuracy or best CV accuracy over the different splits for this parameter setting\n",
    "best_CV_score_rf = random_search.best_score_\n",
    "print(\"Best CV F1  score for the RF model: {:.2f}\".format(best_CV_score_rf))\n",
    "\n",
    "# Accessing the best parameters that were found\n",
    "best_params_rf_model = random_search.best_params_\n",
    "print(\"Best parameters: {}\".format(best_params_rf_model))\n",
    "\n",
    "# Accessing the model with the best parameters trained on the whole training set\n",
    "print(\"Best Estimator: \\n{}\".format(best_model_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model score for the RF model on the test set (Grid Search): 0.17\n",
      "Best parameters: {'min_samples_split': 2, 'n_estimators': 90}\n"
     ]
    }
   ],
   "source": [
    "# 54 Tim's Version \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ignore warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# To ignore a specific type of warning, e.g., DeprecationWarning:\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "#based off the best params you woud then run a grid search based off the best params_\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Extract the best parameters from the random search\n",
    "best_random_params = random_search.best_params_\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# YOU MUST CHANGE THE VALUE BASED OFF THE BEST PARAMETER FOR THAT HYPERPARAMETER \n",
    "param_grid_grid_search = {\n",
    "    'n_estimators': [90, 100, 140],\n",
    "    'min_samples_split': [2, 5, 25]\n",
    "}\n",
    "#######################################################################################\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid_grid_search, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train2, y_train2)\n",
    "\n",
    "# Get the results of the grid search\n",
    "grid_search_results = grid_search.cv_results_\n",
    "\n",
    "# Evaluate the model's performance using the test set\n",
    "best_model_rf_grid_search = grid_search.best_estimator_\n",
    "best_model_test_set_score_grid_search = best_model_rf_grid_search.score(X_test_q2, y_test2)\n",
    "\n",
    "print(\"Best model score for the RF model on the test set (Grid Search): {:.2f}\".format(best_model_test_set_score_grid_search))\n",
    "\n",
    "# Accessing the best parameters that were found\n",
    "best_params_rf_model = grid_search.best_params_\n",
    "print(\"Best parameters: {}\".format(best_params_rf_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"KNNmodel\"></a>\n",
    "#### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1: share_quantile_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    9    19    23 ... 39630 39636 39639]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   26    27    29 ... 39570 39592 39621]\n",
      "Fold 0:\n",
      "  Train: index=[    1     2     3 ... 39641 39642 39643]\n",
      "  Test:  index=[    0     5    16 ... 39593 39600 39615]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    4    10    11 ... 39574 39614 39638]\n",
      "Fold 0:\n",
      "  Train: index=[    0     3     4 ... 39641 39642 39643]\n",
      "  Test:  index=[    1     2     6 ... 39589 39596 39611]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39639 39640 39642]\n",
      "  Test:  index=[   33    42    49 ... 39637 39641 39643]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    3    15    31 ... 39584 39608 39635]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    7    20    57 ... 39633 39634 39640]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39640 39641 39643]\n",
      "  Test:  index=[   17    18    21 ... 39628 39631 39642]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   24    62    64 ... 39620 39622 39629]\n"
     ]
    }
   ],
   "source": [
    "# 55 Tim's Version \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# Create a StratifiedKFold object with n_splits=10\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state = random_state)\n",
    "\n",
    "# Remove target, related variables, and factor other targets due to them being categorical\n",
    "import numpy as np\n",
    "X0 = pd.get_dummies(df1, columns=['day_of_week'])\n",
    "X0 = pd.get_dummies(X0, columns=['news_category'])\n",
    "X1 = X0.drop(['share_quantile_ranges', 'shares'], axis=1) \n",
    "y1 = X0.loc[:,'share_quantile_ranges']\n",
    "\n",
    "\n",
    "# Instantiate transformers\n",
    "quantile_transformer = QuantileTransformer(n_quantiles=100, output_distribution='normal')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "f1_scores_knn_q1 = []\n",
    "accuracy_scores_knn_q1 = []\n",
    "precision_scores_knn_q1 = []\n",
    "recall_scores_knn_q1 = []\n",
    "\n",
    "# precision_scores, recall_scores = [], []  # Initialize lists to store precision and recall\n",
    "\n",
    "X_train_list, X_test_list, y_train_list, y_test_list = [], [], [], []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X1, y1)):\n",
    "    print(f\"Fold {0}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "    X_train1 = np.array(X1.iloc[train_index].to_numpy())\n",
    "    X_test1 = np.array(X1.iloc[test_index].to_numpy())\n",
    "    y_train1 = np.array(y1.iloc[train_index].to_numpy())\n",
    "    y_test1 = np.array(y1.iloc[test_index].to_numpy())\n",
    "\n",
    "    # Scale and Quantile Transform for this fold\n",
    "    # X_train_fold = quantile_transformer.fit_transform(X_train_fold)\n",
    "    # X_test_fold = quantile_transformer.transform(X_test_fold)\n",
    "    X_train_fold = scaler.fit_transform(X_train1)\n",
    "    X_test_fold = scaler.transform(X_test1)\n",
    "    X_train_q1 = quantile_transformer.fit_transform(X_train_fold)\n",
    "    X_test_q1 = quantile_transformer.transform(X_test_fold)\n",
    "\n",
    "    # Instantiate KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train_q1, y_train1)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    knn_y_pred_q1 = knn.predict(X_test_q1)\n",
    "    \n",
    "    # Calculate accuracy and F1 score for this fold\n",
    "    knn_accuracy_q1 = accuracy_score(y_test1, knn_y_pred_q1)\n",
    "    # f1 = f1_score(y_test1, rf_y_pred_q1)\n",
    "    knn_f1_score_q1 = f1_score(y_test1, knn_y_pred_q1, average='macro')\n",
    "    knn_precision_q1 = precision_score(y_test1, knn_y_pred_q1, average=None)\n",
    "    knn_recall_q1 = recall_score(y_test1, knn_y_pred_q1, average= None)\n",
    "\n",
    "    accuracy_scores.append(knn_accuracy_q1)\n",
    "    f1_scores.append(knn_f1_score_q1)\n",
    "    precision_scores.append(knn_precision_q1)\n",
    "    recall_scores.append(knn_recall_q1)\n",
    "    \n",
    "    X_train_list.append(X_train1)\n",
    "    X_test_list.append(X_test1)\n",
    "    y_train_list.append(y_train1)\n",
    "    y_test_list.append(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN on share_quantile_ranges Task\n",
      "[0.32870838 0.32359307 0.32918026 0.32117773]\n",
      "---------------------------------------------------------\n",
      "KNN accuracy: 0.32870837537840564\n",
      "KNN precision: 0.323593071659247\n",
      "KNN recall: 0.32918025660927225\n",
      "KNN F1 score: 0.3211777324319068\n"
     ]
    }
   ],
   "source": [
    "# 56 Tim's Version \n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the share_quantile_ranges task.\n",
    "knn_accuracy_q1 = accuracy_score(y_test1, knn_y_pred_q1)\n",
    "knn_precision_q1 = precision_score(y_test1, knn_y_pred_q1, average='macro')\n",
    "knn_recall_q1 = recall_score(y_test1, knn_y_pred_q1, average='macro')\n",
    "knn_f1_score_q1 = f1_score(y_test1, knn_y_pred_q1, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics for the share_quantile_ranges task.\n",
    "knn_model_scores_q1 = np.array([knn_accuracy_q1, knn_precision_q1, knn_recall_q1, knn_f1_score_q1])\n",
    "print('KNN on share_quantile_ranges Task')\n",
    "print(knn_model_scores_q1)\n",
    "print('---------------------------------------------------------')\n",
    "print('KNN accuracy:', knn_accuracy_q1)\n",
    "print('KNN precision:', knn_precision_q1)\n",
    "print('KNN recall:', knn_recall_q1)\n",
    "print('KNN F1 score:', knn_f1_score_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust parameters as appropriate to increase generalization performance using your chosen metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 57 Tim's Version \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "######################################################\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],  # Number of neighbors to consider\n",
    "    'weights': ['uniform', 'distance'],  # Weighting of neighbors (uniform or distance-based)\n",
    "    'p': [1, 2],  # Power parameter for the Minkowski distance metric (1 for Manhattan, 2 for Euclidean)\n",
    "}\n",
    "######################################################\n",
    "\n",
    "# Perform the randomized search\n",
    "random_search = RandomizedSearchCV(estimator=knn, param_distributions=knn_param_grid, n_iter=100, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "random_search_knn.fit(X_train1, y_train1)\n",
    "# Get the results of the random search\n",
    "results_knn1 = random_search_knn.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model score for the KNN model on the test set: 0.25\n",
      "Best CV F1 score for the KNN model: 0.27\n",
      "Best parameters: {'weights': 'distance', 'p': 2, 'n_neighbors': 11}\n",
      "Best Estimator: \n",
      "KNeighborsClassifier(n_neighbors=11, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# 58 Tim's Version \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the scores and corresponding hyperparameters\n",
    "scores = results_knn1['mean_test_score']\n",
    "n_neighbors = [params['n_neighbors'] for params in results_knn1['params']]\n",
    "p = [params['p'] for params in results_knn1['params']]\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'n_neighbors': n_neighbors, 'p': p, 'Score': scores})\n",
    "\n",
    "# Pivot the DataFrame to create a 2D grid\n",
    "heatmap_data = df.pivot_table(index='n_neighbors', columns='p', values='Score', aggfunc='mean')\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='viridis')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('n_neighbors')\n",
    "plt.title('Performance Heatmap')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the score on the test set using the best estimator\n",
    "best_model_knn1 = random_search_knn.best_estimator_\n",
    "best_model_test_set_score_knn = best_model_knn1.score(X_test_q1, y_test1)\n",
    "print(\"Best model score for the KNN model on the test set: {:.2f}\".format(best_model_test_set_score_knn))\n",
    "\n",
    "# The mean accuracy or best CV accuracy over the different splits for this parameter setting\n",
    "best_CV_score_knn1 = random_search_knn.best_score_\n",
    "print(\"Best CV score for the KNN model: {:.2f}\".format(best_F1_score_knn1))\n",
    "\n",
    "\n",
    "\n",
    "# Accessing the best parameters that were found\n",
    "best_params_knn1_model = random_search_knn.best_params_\n",
    "print(\"Best parameters: {}\".format(best_params_knn1_model))\n",
    "\n",
    "# Accessing the model with the best parameters trained on the whole training set\n",
    "print(\"Best Estimator: \\n{}\".format(best_model_knn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_response.py\", line 194, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 254, in predict\n",
      "    probabilities = self.predict_proba(X)\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\", line 332, in predict_proba\n",
      "    probabilities = ArgKminClassMode.compute(\n",
      "  File \"/Users/tmc/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 591, in compute\n",
      "    unique_labels=np.array(unique_labels, dtype=np.intp),\n",
      "ValueError: invalid literal for int() with base 10: '<Q1'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model score for the KNN model on the test set (Grid Search): 0.25\n",
      "Best parameters: {'n_neighbors': 15, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# 59 Tim's Version \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# ignore warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# To ignore a specific type of warning, e.g., DeprecationWarning:\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Extract the best parameters from the random search\n",
    "best_params_knn1_model = random_search_knn.best_params_\n",
    "\n",
    "####################################################################\n",
    "# Define a new parameter grid for the grid search\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [11, 13, 15, 17],  # Number of neighbors to consider\n",
    "    'weights': ['uniform', 'distance'],  # Weighting of neighbors (uniform or distance-based)\n",
    "    'p': [1, 2],  # Power parameter for the Minkowski distance metric (1 for Manhattan, 2 for Euclidean)\n",
    "}\n",
    "####################################################################\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search_knn1 = GridSearchCV(estimator=knn, param_grid=knn_param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search_knn1.fit(X_train1, y_train1)\n",
    "\n",
    "# Get the results of the grid search\n",
    "grid_search_results_knn1 = grid_search_knn1.cv_results_\n",
    "\n",
    "# Evaluate the model's performance using the test set\n",
    "best_model_knn1_grid_search = grid_search_knn1.best_estimator_\n",
    "best_model_test_set_score_grid_search_knn1 = best_model_knn1_grid_search.score(X_test_q1, y_test1)\n",
    "print(\"Best model score for the KNN model on the test set (Grid Search): {:.2f}\".format(best_model_test_set_score_grid_search_knn1))\n",
    "\n",
    "# Accessing the best parameters that were found\n",
    "best_params_knn1_model = grid_search_knn1.best_params_\n",
    "print(\"Best parameters: {}\".format(best_params_knn1_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60 Matt's Version \n",
    "\n",
    "\n",
    "# Create the KNN model\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 61 Matt's Version \n",
    "# \n",
    "# Train the model for the share_quantile_ranges task.\n",
    "# knn.fit(X_train_q1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 62 Matt's Version \n",
    "\n",
    "\n",
    "# Make predictions on the test set for the share_quantile_ranges task.\n",
    "# knn_y_pred_q1 = knn.predict(X_test_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 63 Matt's Version \n",
    "\n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the share_quantile_ranges task.\n",
    "# knn_accuracy_q1 = accuracy_score(y_test1, knn_y_pred_q1)\n",
    "# knn_precision_q1 = precision_score(y_test1, knn_y_pred_q1, average='macro')\n",
    "# knn_recall_q1 = recall_score(y_test1, knn_y_pred_q1, average='macro')\n",
    "# knn_f1_score_q1 = f1_score(y_test1, knn_y_pred_q1, average='macro')\n",
    "\n",
    "# # Create an array to store the model evaluation metrics for the share_quantile_ranges task.\n",
    "# knn_model_scores_q1 = np.array([knn_accuracy_q1, knn_precision_q1, knn_recall_q1, knn_f1_score_q1])\n",
    "# print('KNN on share_quantile_ranges Task')\n",
    "# print(knn_model_scores_q1)\n",
    "# print('---------------------------------------------------------')\n",
    "# print('KNN accuracy:', knn_accuracy_q1)\n",
    "# print('KNN precision:', knn_precision_q1)\n",
    "# print('KNN recall:', knn_recall_q1)\n",
    "# print('KNN F1 score:', knn_f1_score_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2: day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    7    16    37 ... 39623 39632 39636]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     3 ... 39640 39642 39643]\n",
      "  Test:  index=[    2    12    18 ... 39630 39631 39641]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   19    22    62 ... 39565 39586 39619]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   61    64    72 ... 39624 39634 39640]\n",
      "Fold 0:\n",
      "  Train: index=[    0     2     4 ... 39641 39642 39643]\n",
      "  Test:  index=[    1     3     8 ... 39626 39627 39633]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39640 39641 39642]\n",
      "  Test:  index=[   21    44    47 ... 39600 39628 39643]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[   14    28    34 ... 39625 39635 39637]\n",
      "Fold 0:\n",
      "  Train: index=[    1     2     3 ... 39641 39642 39643]\n",
      "  Test:  index=[    0    10    11 ... 39605 39618 39639]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    5     9    23 ... 39609 39621 39629]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39640 39641 39643]\n",
      "  Test:  index=[    4     6    13 ... 39617 39638 39642]\n"
     ]
    }
   ],
   "source": [
    "# 64 Tim's Version \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# Create a StratifiedKFold object with n_splits=10\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state = random_state)\n",
    "\n",
    "# Remove target, related variables, and factor other targets due to them being categorical\n",
    "X0 = pd.get_dummies(df1, columns=['news_category'])\n",
    "X2 = X0.drop(['share_quantile_ranges', 'day_of_week'], axis=1) # Removing target categorical variable and other categorical variables\n",
    "y2 = X0.loc[:,'day_of_week']\n",
    "\n",
    "# Instantiate transformers\n",
    "quantile_transformer = QuantileTransformer(n_quantiles=100, output_distribution='normal')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "f1_scores2 = []\n",
    "accuracy_scores2 = []\n",
    "precision_scores2 = []\n",
    "recall_scores2 = []\n",
    "\n",
    "# precision_scores, recall_scores = [], []  # Initialize lists to store precision and recall\n",
    "\n",
    "X_train_list2, X_test_list2, y_train_list2, y_test_list2 = [], [], [], []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X2, y2)):\n",
    "    print(f\"Fold {0}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "    X_train2 = np.array(X2.iloc[train_index].to_numpy())\n",
    "    X_test2 = np.array(X2.iloc[test_index].to_numpy())\n",
    "    y_train2 = np.array(y2.iloc[train_index].to_numpy())\n",
    "    y_test2 = np.array(y2.iloc[test_index].to_numpy())\n",
    "\n",
    "    # Scale and Quantile Transform for this fold\n",
    "    # X_train_fold = quantile_transformer.fit_transform(X_train_fold)\n",
    "    # X_test_fold = quantile_transformer.transform(X_test_fold)\n",
    "    X_train_fold2 = scaler.fit_transform(X_train2)\n",
    "    X_test_fold2 = scaler.transform(X_test2)\n",
    "    X_train_q2 = quantile_transformer.fit_transform(X_train_fold2)\n",
    "    X_test_q2 = quantile_transformer.transform(X_test_fold2)\n",
    "\n",
    "\n",
    "    # Instantiate KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train_q2, y_train2)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    knn_y_pred_q2 = knn.predict(X_test_q2)\n",
    "    \n",
    "    # Calculate accuracy and F1 score for this fold\n",
    "    knn_accuracy_q2 = accuracy_score(y_test2, knn_y_pred_q2)\n",
    "    knn_f1_score_q2 = f1_score(y_test2, knn_y_pred_q2, average='macro')\n",
    "    knn_precision_q2 = precision_score(y_test2, knn_y_pred_q2, average=None)\n",
    "    knn_recall_q2 = recall_score(y_test2, knn_y_pred_q2, average= None)\n",
    "\n",
    "    accuracy_scores2.append(knn_accuracy_q2)\n",
    "    f1_scores2.append(knn_f1_score_q2)\n",
    "    precision_scores2.append(knn_precision_q2)\n",
    "    recall_scores2.append(knn_recall_q2)\n",
    "    \n",
    "    X_train_list2.append(X_train2)\n",
    "    X_test_list2.append(X_test2)\n",
    "    y_train_list2.append(y_train2)\n",
    "    y_test_list2.append(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN on share_quantile_ranges Task\n",
      "[0.25302725 0.30743114 0.30751924 0.30563799]\n",
      "---------------------------------------------------------\n",
      "KNN accuracy: 0.25302724520686176\n",
      "KNN precision: 0.30743113622130064\n",
      "KNN recall: 0.30751923863040675\n",
      "KNN F1 score: 0.3056379904637822\n"
     ]
    }
   ],
   "source": [
    "# 65 Tim's Version \n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the share_quantile_ranges task.\n",
    "knn_accuracy_q2 = accuracy_score(y_test2, knn_y_pred_q2)\n",
    "knn_precision_q2 = precision_score(y_test2, knn_y_pred_q2, average='macro')\n",
    "knn_recall_q2 = recall_score(y_test2, knn_y_pred_q2, average='macro')\n",
    "knn_f1_score_q2 = f1_score(y_test2, knn_y_pred_q2, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics for the share_quantile_ranges task.\n",
    "knn_model_scores_q2 = np.array([knn_accuracy_q2, knn_precision_q2, knn_recall_q2, knn_f1_score_q2])\n",
    "print('KNN on share_quantile_ranges Task')\n",
    "print(knn_model_scores_q2)\n",
    "print('---------------------------------------------------------')\n",
    "print('KNN accuracy:', knn_accuracy_q2)\n",
    "print('KNN precision:', knn_precision_q2)\n",
    "print('KNN recall:', knn_recall_q2)\n",
    "print('KNN F1 score:', knn_f1_score_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust parameters as appropriate to increase generalization performance using your chosen metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 66 Tim's Version \n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "######################################################\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],  # Number of neighbors to consider\n",
    "    'weights': ['uniform', 'distance'],  # Weighting of neighbors (uniform or distance-based)\n",
    "    'p': [1, 2],  # Power parameter for the Minkowski distance metric (1 for Manhattan, 2 for Euclidean)\n",
    "}\n",
    "######################################################\n",
    "\n",
    "# Perform the randomized search\n",
    "random_search = RandomizedSearchCV(estimator=knn, param_distributions=knn_param_grid, n_iter=100, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "random_search_knn2.fit(X_train2, y_train2)\n",
    "# Get the results of the random search\n",
    "results_knn2 = random_search_knn2.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 67 Tim's Version -- duplicate viz into the appropriate section \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have already run RandomizedSearchCV and have 'results' available\n",
    "\n",
    "# Extract the scores and corresponding hyperparameters\n",
    "scores = results_knn2['mean_test_score']\n",
    "n_neighbors = [params['n_neighbors'] for params in results_knn2['params']]\n",
    "p = [params['p'] for params in results_knn2['params']]\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'n_neighbors': n_neighbors, 'p': p, 'Score': scores})\n",
    "\n",
    "# Pivot the DataFrame to create a 2D grid\n",
    "heatmap_data = df.pivot_table(index='n_neighbors', columns='p', values='Score', aggfunc='mean')\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='viridis')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('n_neighbors')\n",
    "plt.title('Performance Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model score for the KNN model on the test set: 0.17\n",
      "Best CV F1 score for the KNN model: 0.15\n",
      "Best parameters: {'weights': 'distance', 'p': 1, 'n_neighbors': 5}\n",
      "Best Estimator: \n",
      "KNeighborsClassifier(p=1, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# 68 Tim's Version \n",
    "\n",
    "# Calculate the score on the test set using the best estimator\n",
    "best_model_knn2 = random_search_knn2.best_estimator_\n",
    "best_model_test_set_score_knn2 = best_model_knn2.score(X_test_q2, y_test2)\n",
    "print(\"Best model score for the KNN model on the test set: {:.2f}\".format(best_model_test_set_score_knn2))\n",
    "\n",
    "# The mean accuracy or best CV accuracy over the different splits for this parameter setting\n",
    "best_CV_score_knn2 = random_search_knn2.best_score_\n",
    "print(\"Best CV F1 score for the KNN model: {:.2f}\".format(best_CV_score_knn2))\n",
    "\n",
    "\n",
    "\n",
    "# Accessing the best parameters that were found\n",
    "best_params_knn2_model = random_search_knn2.best_params_\n",
    "print(\"Best parameters: {}\".format(best_params_knn2_model))\n",
    "\n",
    "# Accessing the model with the best parameters trained on the whole training set\n",
    "print(\"Best Estimator: \\n{}\".format(best_model_knn2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust parameters as appropriate to increase generalization performance using your chosen metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model score for the RF model on the test set (Grid Search): 0.17\n",
      "Best parameters: {'n_neighbors': 11, 'p': 2}\n"
     ]
    }
   ],
   "source": [
    "# 69 Tim's Version \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ignore warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# To ignore a specific type of warning, e.g., DeprecationWarning:\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "#based off the best params you woud then run a grid search based off the best params_\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Extract the best parameters from the random search\n",
    "best_params_knn2_model = random_search_knn2.best_params_\n",
    "\n",
    "####################################################################\n",
    "# Define a new parameter grid for the grid search\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [5, 11, 13, 15],  # Number of neighbors to consider\n",
    "    'weights': ['uniform', 'distance'],  # Weighting of neighbors (uniform or distance-based)\n",
    "    'p': [1, 2],  # Power parameter for the Minkowski distance metric (1 for Manhattan, 2 for Euclidean)\n",
    "}\n",
    "####################################################################\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search_knn1 = GridSearchCV(estimator=knn, param_grid=knn_param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search_knn2.fit(X_train2, y_train2)\n",
    "\n",
    "# Get the results of the grid search\n",
    "grid_search_results_knn2 = grid_search_knn2.cv_results_\n",
    "\n",
    "# Evaluate the model's performance using the test set\n",
    "best_model_knn2_grid_search = grid_search_knn2.best_estimator_\n",
    "best_model_test_set_score_grid_search_knn2 = best_model_knn2_grid_search.score(X_test_q2, y_test2)\n",
    "print(\"Best model score for the RF model on the test set (Grid Search): {:.2f}\".format(best_model_test_set_score_grid_search_knn2))\n",
    "\n",
    "# Accessing the best parameters that were found\n",
    "best_params_knn2_model = grid_search_knn2.best_params_\n",
    "print(\"Best parameters: {}\".format(best_params_knn2_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70 Matt's Version \n",
    "\n",
    "# Train the model for the day_of_week task.\n",
    "# knn.fit(X_train_q2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 71 Matt's Version \n",
    "\n",
    "# Make predictions on the test set for the day_of_week task.\n",
    "# knn_y_pred_q2 = knn.predict(X_test_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 72 Matt's Version \n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the day_of_week task.\n",
    "# knn_accuracy_q2 = accuracy_score(y_test2, knn_y_pred_q2)\n",
    "# knn_precision_q2 = precision_score(y_test2, knn_y_pred_q2, average='macro')\n",
    "# knn_recall_q2 = recall_score(y_test2, knn_y_pred_q2, average='macro')\n",
    "# knn_f1_score_q2 = f1_score(y_test2, knn_y_pred_q2, average='macro')\n",
    "\n",
    "# # Create an array to store the model evaluation metrics the day_of_week task.\n",
    "# knn_model_scores_q2 = np.array([knn_accuracy_q2, knn_precision_q2, knn_recall_q2, knn_f1_score_q2])\n",
    "# print('KNN on day_of_week Task')\n",
    "# print(knn_model_scores_q2)\n",
    "# print('---------------------------------------------------------')\n",
    "# print('KNN accuracy:', knn_accuracy_q2)\n",
    "# print('KNN precision:', knn_precision_q2)\n",
    "# print('KNN recall:', knn_recall_q2)\n",
    "# print('KNN F1 score:', knn_f1_score_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"SVMmodel\"></a>\n",
    "#### SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1: share_quantile_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    9    19    23 ... 39630 39636 39639]\n",
      "Fold 0:\n",
      "  Train: index=[    1     2     3 ... 39641 39642 39643]\n",
      "  Test:  index=[    0     4     5 ... 39614 39615 39638]\n",
      "Fold 0:\n",
      "  Train: index=[    0     3     4 ... 39639 39640 39642]\n",
      "  Test:  index=[    1     2     6 ... 39637 39641 39643]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39641 39642 39643]\n",
      "  Test:  index=[    3     7    15 ... 39634 39635 39640]\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 39640 39641 39643]\n",
      "  Test:  index=[   17    18    21 ... 39629 39631 39642]\n"
     ]
    }
   ],
   "source": [
    "# 73  Tim's Version \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# Create a StratifiedKFold object with n_splits=10\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state = random_state)\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state = random_state)\n",
    "\n",
    "# Remove target, related variables, and factor other targets due to them being categorical\n",
    "import numpy as np\n",
    "X0 = pd.get_dummies(df1, columns=['day_of_week'])\n",
    "X0 = pd.get_dummies(X0, columns=['news_category'])\n",
    "X1 = X0.drop(['share_quantile_ranges', 'shares'], axis=1) \n",
    "y1 = X0.loc[:,'share_quantile_ranges']\n",
    "\n",
    "\n",
    "# Instantiate transformers\n",
    "quantile_transformer = QuantileTransformer(n_quantiles=100, output_distribution='normal')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "f1_scores_svm_q1 = []\n",
    "accuracy_scores_svm_q1 = []\n",
    "precision_scores_svm_q1 = []\n",
    "recall_scores_svm_q1 = []\n",
    "\n",
    "# precision_scores, recall_scores = [], []  # Initialize lists to store precision and recall\n",
    "\n",
    "X_train_list_svm1, X_test_list_svm1, y_train_list_svm1, y_test_list_svm1 = [], [], [], []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X1, y1)):\n",
    "    print(f\"Fold {0}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "    X_train1 = np.array(X1.iloc[train_index].to_numpy())\n",
    "    X_test1 = np.array(X1.iloc[test_index].to_numpy())\n",
    "    y_train1 = np.array(y1.iloc[train_index].to_numpy())\n",
    "    y_test1 = np.array(y1.iloc[test_index].to_numpy())\n",
    "\n",
    "    # Scale and Quantile Transform for this fold\n",
    "    # X_train_fold = quantile_transformer.fit_transform(X_train_fold)\n",
    "    # X_test_fold = quantile_transformer.transform(X_test_fold)\n",
    "    X_train_fold = scaler.fit_transform(X_train1)\n",
    "    X_test_fold = scaler.transform(X_test1)\n",
    "    X_train_q1 = quantile_transformer.fit_transform(X_train_fold)\n",
    "    X_test_q1 = quantile_transformer.transform(X_test_fold)\n",
    "\n",
    "    # Set the model parameters\n",
    "    C = 1.0\n",
    "    kernel = 'linear'\n",
    "\n",
    "    # Instantiate the support vector machine model\n",
    "    support_vector_machine_model = SVC(C=C, kernel=kernel)\n",
    "    support_vector_machine_model.fit(X_train_q1, y_train1)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    svm_y_pred_q1 = support_vector_machine_model.predict(X_test_q1)\n",
    "    \n",
    "    # Calculate accuracy and F1 score for this fold\n",
    "    svm_accuracy_q1 = accuracy_score(y_test1, svm_y_pred_q1)\n",
    "    # f1 = f1_score(y_test1, rf_y_pred_q1)\n",
    "    svm_f1_score_q1 = f1_score(y_test1, svm_y_pred_q1, average='macro')\n",
    "    svm_precision_q1 = precision_score(y_test1, svm_y_pred_q1, average=None)\n",
    "    svm_recall_q1 = recall_score(y_test1, svm_y_pred_q1, average= None)\n",
    "\n",
    "    accuracy_scores_svm_q1.append(svm_accuracy_q1)\n",
    "    f1_scores_svm_q1.append(svm_f1_score_q1)\n",
    "    precision_scores_svm_q1.append(svm_precision_q1)\n",
    "    recall_scores_svm_q1.append(svm_recall_q1)\n",
    "    \n",
    "    X_train_list_svm1.append(X_train1)\n",
    "    X_test_list_svm1.append(X_test1)\n",
    "    y_train_list_svm1.append(y_train1)\n",
    "    y_test_list_svm1.append(y_test1)\n",
    "    \n",
    "    \n",
    "# time: 83m 48.4s on 5 FOLD     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pickle Results Load 1: \n",
    "## Note it took \n",
    "\n",
    "import pickle\n",
    "\n",
    "# Create a dictionary to store all the data\n",
    "data_and_scores_svm_q1 = {\n",
    "    'X_train_list_svm1': X_train_list_svm1,\n",
    "    'X_test_list_svm1': X_test_list_svm1,\n",
    "    'y_train_list_svm1': y_train_list_svm1,\n",
    "    'y_test_list_svm1': y_test_list_svm1,\n",
    "    'accuracy_scores_svm_q1': accuracy_scores_svm_q1,\n",
    "    'f1_scores_svm_q1': f1_scores_svm_q1,\n",
    "    'precision_scores_svm_q1': precision_scores_svm_q1,\n",
    "    'recall_scores_svm_q1': recall_scores_svm_q1\n",
    "}\n",
    "\n",
    "# Save the data to a file\n",
    "with open('data_and_scores_svm_q1.pkl', 'wb') as file:\n",
    "    pickle.dump(data_to_save, file)\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the lists and scores from the file\n",
    "with open('data_and_scores_svm_q1.pkl', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "X_train_list_svm1 = loaded_data['X_train_list_svm1']\n",
    "X_test_list_svm1 = loaded_data['X_test_list_svm1']\n",
    "y_train_list_svm1 = loaded_data['y_train_list_svm1']\n",
    "y_test_list_svm1 = loaded_data['y_test_list_svm1']\n",
    "accuracy_scores_svm_q1 = loaded_data['accuracy_scores_svm_q1']\n",
    "f1_scores_svm_q1 = loaded_data['f1_scores_svm_q1']\n",
    "precision_scores_svm_q1 = loaded_data['precision_scores_svm_q1']\n",
    "recall_scores_svm_q1 = loaded_data['recall_scores_svm_q1']\n",
    "\n",
    "# print(recall_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 74 Tim's Version \n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the share_quantile_ranges task.\n",
    "svm_accuracy_q1 = accuracy_score(y_test1, svm_y_pred_q1)\n",
    "svm_precision_q1 = precision_score(y_test1, svm_y_pred_q1, average='macro')\n",
    "svm_recall_q1 = recall_score(y_test1, svm_y_pred_q1, average='macro')\n",
    "svm_f1_score_q1 = f1_score(y_test1, svm_y_pred_q1, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics for the share_quantile_ranges task.\n",
    "svm_model_scores_q1 = np.array([svm_accuracy_q1, svm_precision_q1, svm_recall_q1, svm_f1_score_q1])\n",
    "print('SVM on share_quantile_ranges Task')\n",
    "print(svm_model_scores_q1)\n",
    "print('---------------------------------------------------------')\n",
    "print('SVM accuracy:', svm_accuracy_q1)\n",
    "print('SVM precision:', svm_precision_q1)\n",
    "print('SVM recall:', svm_recall_q1)\n",
    "print('SVM F1 score:', svm_f1_score_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust parameters as appropriate to increase generalization performance using your chosen metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75 Tim's Version\n",
    "\n",
    "### Adjust parameters as appropriate to increase generalization performance using your chosen metric.\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Identify the most important hyperparameters\n",
    "# Define the parameter grid to search over\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Define a parameter grid for the SVM model\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10],\n",
    "}\n",
    "# param_grid = {\n",
    "#     'C': [1, 10],\n",
    "#     'gamma': [0.001, 0.01],\n",
    "# }\n",
    "##################################################################\n",
    "\n",
    "# random_search_svm = RandomizedSearchCV(estimator=svm, param_distributions=param_grid, n_iter=100, cv=5, scoring='f1_macro')\n",
    "random_search_svm1 = RandomizedSearchCV(estimator=svm, param_distributions=param_grid, n_iter=20, cv=3, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "random_search_svm1.fit(X_train1, y_train1)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "results_svm1 = random_search_svm1.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle random search param grid \n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the results as a pickle file\n",
    "with open('results_svm1.pkl', 'wb') as f:\n",
    "  pickle.dump(results_svm1, f)\n",
    "  \n",
    "import pickle\n",
    "\n",
    "# Load the results from the pickle file\n",
    "with open('results_svm1.pkl', 'rb') as f:\n",
    "  results_svm1 = pickle.load(f)\n",
    "\n",
    "# Print the best parameters\n",
    "print(results_svm1['best_params_'])\n",
    "\n",
    "# Print the best score\n",
    "print(results_svm1['best_score_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 78 Tim's Version\n",
    "\n",
    "# Heat Map SVM share_quantile_ranges\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the scores and corresponding hyperparameters\n",
    "scores = results_svm1['mean_test_score']\n",
    "C = [params['C'] for params in results_svm1['params']]\n",
    "gamma = [params['gamma'] for params in results_svm1['params']]\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'gamma': gamma, 'C': C, 'Score': scores})\n",
    "\n",
    "# Pivot the DataFrame to create a 2D grid\n",
    "heatmap_data = df.pivot_table(index='gamma', columns='C', values='Score', aggfunc='mean')\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='viridis')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('gamma')\n",
    "plt.title('Performance Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 79 Tim's Version \n",
    "\n",
    "# Calculate the score on the test set using the best estimator\n",
    "best_model_svm1 = random_search_svm1.best_estimator_\n",
    "best_model_test_set_score_svm1 = best_model_svm1.score(X_test_q1, y_test1)\n",
    "print(\"Best model score for the KNN model on the test set: {:.2f}\".format(best_model_test_set_score_svm1))\n",
    "\n",
    "# The mean accuracy or best CV accuracy over the different splits for this parameter setting\n",
    "best_CV_score_svm1 = random_search_svm1.best_score_\n",
    "print(\"Best CV F1 score for the KNN model: {:.2f}\".format(best_CV_score_svm1))\n",
    "\n",
    "\n",
    "# Accessing the best parameters that were found\n",
    "best_params_svm1_model = random_search_svm1.best_params_\n",
    "print(\"Best parameters: {}\".format(best_params_svm1_model))\n",
    "\n",
    "# Accessing the model with the best parameters trained on the whole training set\n",
    "print(\"Best Estimator: \\n{}\".format(best_model_svm1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80 Tim's Version \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# To ignore a specific type of warning, e.g., DeprecationWarning:\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Extract the best parameters from the random search\n",
    "best_params_svm1_model = random_search_svm1.best_params_\n",
    "\n",
    "####################################################################\n",
    "param_grid_grid_search_svm1 = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10],\n",
    "}\n",
    "####################################################################\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search_svm1 = GridSearchCV(estimator=svm, param_grid=param_grid_grid_search_svm1, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search_svm1.fit(X_train1, y_train1)\n",
    "\n",
    "# Get the results of the grid search\n",
    "grid_search_results_svm1 = grid_search_svm1.cv_results_\n",
    "\n",
    "# Evaluate the model's performance using the test set\n",
    "best_model_svm1_grid_search = grid_search_svm1.best_estimator_\n",
    "best_model_test_set_score_grid_search_svm1 = best_model_svm1_grid_search.score(X_test_q1, y_test1)\n",
    "print(\"Best model CV F1 score for the SVM model on the test set (Grid Search): {:.2f}\".format(best_model_test_set_score_grid_search_svm1))\n",
    "\n",
    "# Accessing the best parameters that were found\n",
    "best_params_svm1_model = grid_search_svm1.best_params_\n",
    "print(\"Best parameters: {}\".format(best_params_svm1_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 81 Matt's Version \n",
    "\n",
    "# Set the model parameters\n",
    "# C = 1.0\n",
    "# kernel = 'linear'\n",
    "\n",
    "# # Create the support vector machine model\n",
    "# support_vector_machine_model = SVC(C=C, kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 82 Matt's Version \n",
    "\n",
    "# Train the support vector machine model on the training set using a linear kernel for the share_quantile_ranges task.\n",
    "# support_vector_machine_model.fit(X_train_q1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 83 Matt's Version \n",
    "\n",
    "# Make predictions on the test data for the share_quantile_ranges task.\n",
    "# svm_y_pred_q1 = support_vector_machine_model.predict(X_test_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 84 Matt's Version \n",
    "\n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the share_quantile_ranges task.\n",
    "# svm_accuracy_q1 = accuracy_score(y_test1, svm_y_pred_q1)\n",
    "# svm_precision_q1 = precision_score(y_test1, svm_y_pred_q1, average='macro')\n",
    "# svm_recall_q1 = recall_score(y_test1, svm_y_pred_q1, average='macro')\n",
    "# svm_f1_score_q1 = f1_score(y_test1, svm_y_pred_q1, average='macro')\n",
    "\n",
    "# # Create an array to store the model evaluation metrics for the share_quantile_ranges task.\n",
    "# svm_model_scores_q1 = np.array([svm_accuracy_q1, svm_precision_q1, svm_recall_q1, svm_f1_score_q1])\n",
    "# print('SVM on share_quantile_range Task')\n",
    "# print(svm_model_scores_q1)\n",
    "# print('---------------------------------------------------------')\n",
    "# print('Support vector machine accuracy:', svm_accuracy_q1)\n",
    "# print('Support vector machine precision:', svm_precision_q1)\n",
    "# print('Support vector machine recall:', svm_recall_q1)\n",
    "# print('Support vector machine F1 score:', svm_f1_score_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2: day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 85 Tim's Version \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# Create a StratifiedKFold object with n_splits=10\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state = random_state)\n",
    "# kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state = random_state)\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state = random_state)\n",
    "\n",
    "# Remove target, related variables, and factor other targets due to them being categorical\n",
    "X0 = pd.get_dummies(df1, columns=['news_category'])\n",
    "X2 = X0.drop(['share_quantile_ranges', 'day_of_week'], axis=1) # Removing target categorical variable and other categorical variables\n",
    "y2 = X0.loc[:,'day_of_week']\n",
    "\n",
    "# Instantiate transformers\n",
    "quantile_transformer = QuantileTransformer(n_quantiles=100, output_distribution='normal')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "f1_scores_svm_q2= []\n",
    "accuracy_scores_svm_q2 = []\n",
    "precision_scores_svm_q2 = []\n",
    "recall_scores_svm_q2 = []\n",
    "\n",
    "# precision_scores, recall_scores = [], []  # Initialize lists to store precision and recall\n",
    "\n",
    "X_train_list_svm2, X_test_list_svm2, y_train_list_svm2, y_test_list_svm2 = [], [], [], []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X2, y2)):\n",
    "    print(f\"Fold {0}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "    X_train2 = np.array(X2.iloc[train_index].to_numpy())\n",
    "    X_test2 = np.array(X2.iloc[test_index].to_numpy())\n",
    "    y_train2 = np.array(y2.iloc[train_index].to_numpy())\n",
    "    y_test2 = np.array(y2.iloc[test_index].to_numpy())\n",
    "\n",
    "    # Scale and Quantile Transform for this fold\n",
    "    # X_train_fold = quantile_transformer.fit_transform(X_train_fold)\n",
    "    # X_test_fold = quantile_transformer.transform(X_test_fold)\n",
    "    X_train_fold2 = scaler.fit_transform(X_train2)\n",
    "    X_test_fold2 = scaler.transform(X_test2)\n",
    "    X_train_q2 = quantile_transformer.fit_transform(X_train_fold2)\n",
    "    X_test_q2 = quantile_transformer.transform(X_test_fold2)\n",
    "\n",
    "    # Set the model parameters\n",
    "    C = 1.0\n",
    "    kernel = 'linear'\n",
    "\n",
    "    # Instantiate the support vector machine model\n",
    "    support_vector_machine_model_2 = SVC(C=C, kernel=kernel)\n",
    "    support_vector_machine_model_2.fit(X_train_q2, y_train2)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    svm_y_pred_q2 = support_vector_machine_model_2.predict(X_test_q2)\n",
    "    \n",
    "    # Calculate accuracy and F1 score for this fold\n",
    "    svm_accuracy_q2 = accuracy_score(y_test2, svm_y_pred_q2)\n",
    "    svm_f1_score_q2 = f1_score(y_test2, svm_y_pred_q2, average='macro')\n",
    "    svm_precision_q2 = precision_score(y_test2, svm_y_pred_q2, average=None)\n",
    "    svm_recall_q2 = recall_score(y_test2, svm_y_pred_q2, average= None)\n",
    "\n",
    "    accuracy_scores_svm_q2.append(svm_accuracy_q2)\n",
    "    accuracy_scores_svm_q2.append(svm_f1_score_q2)\n",
    "    precision_scores_svm_q2.append(svm_precision_q2)\n",
    "    recall_scores_svm_q2.append(svm_recall_q2)\n",
    "    \n",
    "    X_train_list_svm2.append(X_train2)\n",
    "    X_test_list_svm2.append(X_test2)\n",
    "    y_train_list_svm2.append(y_train2)\n",
    "    y_test_list_svm2.append(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pickle Results Load 1: \n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Create a dictionary to store all the data\n",
    "data_and_scores_svm_q2 = {\n",
    "    'X_train_list_svm2': X_train_list_svm2,\n",
    "    'X_test_list_svm2': X_test_list_svm2,\n",
    "    'y_train_list_svm2': y_train_list_svm2,\n",
    "    'y_test_list_svm2': y_test_list_svm2,\n",
    "    'accuracy_scores_svm_q2': accuracy_scores_svm_q2,\n",
    "    'f1_scores_svm_q2': f1_scores_svm_q2,\n",
    "    'precision_scores_svm_q2': precision_scores_svm_q2,\n",
    "    'recall_scores_svm_q2': recall_scores_svm_q2\n",
    "}\n",
    "\n",
    "# Save the data to a file\n",
    "with open('data_and_scores_svm_q2.pkl', 'wb') as file:\n",
    "    pickle.dump(data_to_save, file)\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the lists and scores from the file\n",
    "with open('data_and_scores_svm_q2.pkl', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "X_train_list_svm2 = loaded_data['X_train_list_svm2']\n",
    "X_test_list_svm2 = loaded_data['X_test_list_svm2']\n",
    "y_train_list_svm2 = loaded_data['y_train_list_svm2']\n",
    "y_test_list_svm2 = loaded_data['y_test_list_svm2']\n",
    "accuracy_scores_svm_q2 = loaded_data['accuracy_scores_svm_q2']\n",
    "f1_scores_svm_q2 = loaded_data['f1_scores_svm_q2']\n",
    "precision_scores_svm_q2 = loaded_data['precision_scores_svm_q2']\n",
    "recall_scores_svm_q2 = loaded_data['recall_scores_svm_q2']\n",
    "\n",
    "# print(recall_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 86 Tim's Version\n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the share_quantile_ranges task.\n",
    "svm_accuracy_q2 = accuracy_score(y_test2, svm_y_pred_q2)\n",
    "svm_precision_q2 = precision_score(y_test2, svm_y_pred_q2, average='macro')\n",
    "svm_recall_q2 = recall_score(y_test2, svm_y_pred_q2, average='macro')\n",
    "svm_f1_score_q2 = f1_score(y_test2, svm_y_pred_q2, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics for the share_quantile_ranges task.\n",
    "knn_model_scores_q2 = np.array([svm_accuracy_q2, svm_precision_q2, svm_recall_q2, svm_f1_score_q2])\n",
    "print('SVM on share_quantile_ranges Task')\n",
    "print(svm_model_scores_q2)\n",
    "print('---------------------------------------------------------')\n",
    "print('SVM accuracy:', svm_accuracy_q2)\n",
    "print('SVM precision:', svm_precision_q2)\n",
    "print('SVM recall:', svm_recall_q2)\n",
    "print('SVM F1 score:', svm_f1_score_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust parameters as appropriate to increase generalization performance using your chosen metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 87 Tim's Version \n",
    "\n",
    "### Adjust parameters as appropriate to increase generalization performance using your chosen metric.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "##################################################################\n",
    "# Define a parameter grid for the SVM model\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10],\n",
    "}\n",
    "# param_grid = {\n",
    "#     'C': [1, 10],\n",
    "#     'gamma': [0.001, 0.01],\n",
    "# }\n",
    "\n",
    "####################################################################\n",
    "\n",
    "\n",
    "random_search_svm2 = RandomizedSearchCV(estimator=svm, param_distributions=param_grid, n_iter=20, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "random_search_svm2.fit(X_train2, y_train2)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "results_svm2 = random_search_svm2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle random search param grid \n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the results as a pickle file\n",
    "with open('results_svm2.pkl', 'wb') as f:\n",
    "  pickle.dump(results_svm1, f)\n",
    "  \n",
    "import pickle\n",
    "\n",
    "# Load the results from the pickle file\n",
    "with open('results_svm2.pkl', 'rb') as f:\n",
    "  results_svm2 = pickle.load(f)\n",
    "\n",
    "# Print the best parameters\n",
    "print(results_svm2['best_params_'])\n",
    "\n",
    "# Print the best score\n",
    "print(results_svm2['best_score_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 88 Tim's Version -- move VIZ to appropriate spot \n",
    "\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the scores and corresponding hyperparameters\n",
    "scores = results_svm2['mean_test_score']\n",
    "C = [params['C'] for params in results_svm2['params']]\n",
    "gamma = [params['gamma'] for params in results_svm2['params']]\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'gamma': gamma, 'C': C, 'Score': scores})\n",
    "\n",
    "# Pivot the DataFrame to create a 2D grid\n",
    "heatmap_data = df.pivot_table(index='gamma', columns='C', values='Score', aggfunc='mean')\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='viridis')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('gamma')\n",
    "plt.title('Performance Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 89  Tim's Version\n",
    "\n",
    "\n",
    "# Calculate the score on the test set using the best estimator\n",
    "best_model_svm2 = random_search_svm2.best_estimator_\n",
    "best_model_test_set_score_svm2 = best_model_svm2.score(X_test_q2, y_test2)\n",
    "print(\"Best model score for the KNN model on the test set: {:.2f}\".format(best_model_test_set_score_svm2))\n",
    "\n",
    "# The mean accuracy or best CV accuracy over the different splits for this parameter setting\n",
    "best_CV_score_svm2 = random_search_svm2.best_score_\n",
    "print(\"Best CV F1 score for the KNN model: {:.2f}\".format(best_CV_score_svm2))\n",
    "\n",
    "\n",
    "# Accessing the best parameters that were found\n",
    "best_params_svm2_model = random_search_svm2.best_params_\n",
    "print(\"Best parameters: {}\".format(best_params_svm2_model))\n",
    "\n",
    "# Accessing the model with the best parameters trained on the whole training set\n",
    "print(\"Best Estimator: \\n{}\".format(best_model_svm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90  Tim's Version\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# To ignore a specific type of warning, e.g., DeprecationWarning:\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Extract the best parameters from the random search\n",
    "best_params_svm2_model = random_search_svm2.best_params_\n",
    "\n",
    "####################################################################\n",
    "param_grid_grid_search_svm2 = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10],\n",
    "}\n",
    "####################################################################\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search_svm2 = GridSearchCV(estimator=svm, param_grid=param_grid_grid_search_svm2, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search_svm2.fit(X_train2, y_train2)\n",
    "\n",
    "# Get the results of the grid search\n",
    "grid_search_results_svm2 = grid_search_svm2.cv_results_\n",
    "\n",
    "# Evaluate the model's performance using the test set\n",
    "best_model_svm2_grid_search = grid_search_svm2.best_estimator_\n",
    "best_model_test_set_score_grid_search_svm2 = best_model_svm2_grid_search.score(X_test_q2, y_test2)\n",
    "print(\"Best model CV F1 score for the SVM model on the test set (Grid Search): {:.2f}\".format(best_model_test_set_score_grid_search_svm2))\n",
    "\n",
    "# Accessing the best parameters that were found\n",
    "best_params_svm2_model = grid_search_svm2.best_params_\n",
    "print(\"Best parameters: {}\".format(best_params_svm2_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 91 Matt's Version \n",
    "\n",
    "# Train the support vector machine model on the training set using a linear kernel for the day_of_week task.\n",
    "# support_vector_machine_model.fit(X_train_q2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 92 Matt's Version \n",
    "\n",
    "# Make predictions on the test data for the day_of_week task.\n",
    "# svm_y_pred_q2 = support_vector_machine_model.predict(X_test_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 93 Matt's Version \n",
    "\n",
    "# \n",
    "# \n",
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the day_of_week task.\n",
    "# svm_accuracy_q2 = accuracy_score(y_test2, svm_y_pred_q2)\n",
    "# svm_precision_q2 = precision_score(y_test2, svm_y_pred_q2, average='macro')\n",
    "# svm_recall_q2 = recall_score(y_test2, svm_y_pred_q2, average='macro')\n",
    "# svm_f1_score_q2 = f1_score(y_test2, svm_y_pred_q2, average='macro')\n",
    "\n",
    "# # Create an array to store the model evaluation metrics for the day_of_week task\n",
    "# svm_model_scores_q2 = np.array([svm_accuracy_q2, svm_precision_q2, svm_recall_q2, svm_f1_score_q2])\n",
    "# print('SVM on day_of_week Task')\n",
    "# print(svm_model_scores_q2)\n",
    "# print('---------------------------------------------------------')\n",
    "# print('Support vector machine accuracy:', svm_accuracy_q2)\n",
    "# print('Support vector machine precision:', svm_precision_q2)\n",
    "# print('Support vector machine recall:', svm_recall_q2)\n",
    "# print('Support vector machine F1 score:', svm_f1_score_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"ModelEval4\"></a>\n",
    "# Modeling and Evaluation 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the results using your chosen method of evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use visualizations of the results to bolster the analysis.\n",
    "### Explain any visuals and analyze why they are interesting to someone that might use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COPY OVER VISUALS AND EXPlAIN !!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"ModelEval5\"></a>\n",
    "# Modeling and Evaluation 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discuss the advantages of each model for each classification task, if any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMY \n",
    "\n",
    "\n",
    "## Random Forest:\n",
    "### news category: This task performed the best overall. The Random Forest model is an ensemble learning method ,well suited for large datasets such as the Online News Popularity. This model is robust to outliers and less prone to overfitting due to the model being an ensemble of decision trees running in parallel. \n",
    "### share quantile ranges & day. of week: These tasks did not perform as well as the news catesony, utilizing the news category however they did perform better as compared to the SVM & KNN models.\n",
    "## K-Nearest Neighbors (KNN):\n",
    "### share quantile ranges: For the KNN model this task performed the best.\n",
    "### For all three tasks, the KNN model produced the weakest results.\n",
    "### A disadvantage for the KNN like the SVM is the tuning of the hyperparameters. The large dataset results in the model being sensitive to noise and outliers that may result in the mislabeling of datapoints.\n",
    "## Support Vector Machine (SVM): \n",
    "### share quantile ranges: For the SVM model this task performed the best.\n",
    "\n",
    "\n",
    "#### Overall SVM was the most computationally expensive to run and took a great deal of time to run. KNN was the fastest of the three model types across all tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"TaskEval\"></a>\n",
    "### Is the difference significant with 95% confidence? Use proper statistical comparison methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sqrTask\"></a>\n",
    "#### Task 1: share_quantile_ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37663976 0.37249986 0.37763232 0.37420247]\n",
      "[0.32870838 0.32359307 0.32918026 0.32117773]\n",
      "[0.38256811 0.3741666  0.38430824 0.36638171]\n"
     ]
    }
   ],
   "source": [
    "# QuantileTransformer transformed accuracy scores\n",
    "# Un-Tuned Scores\n",
    "print(rf_model_scores_q1)\n",
    "print(knn_model_scores_q1)\n",
    "print(svm_model_scores_q1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest vs. KNN\n",
      "The difference between the two models is statistically significant.\n",
      "---------------------------------------------------------\n",
      "Random Forest vs. SVM\n",
      "The difference between the two models is not statistically significant.\n",
      "---------------------------------------------------------\n",
      "KNN vs. SVM\n",
      "The difference between the two models is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "# Load the model accuracy scores\n",
    "model1_scores = rf_model_scores_q1\n",
    "model2_scores = knn_model_scores_q1\n",
    "model3_scores = svm_model_scores_q1\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value1 = ttest_rel(model1_scores, model2_scores)\n",
    "\n",
    "print(\"Random Forest vs. KNN\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value1 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value2 = ttest_rel(model1_scores, model3_scores)\n",
    "\n",
    "print(\"Random Forest vs. SVM\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value3 = ttest_rel(model2_scores, model3_scores)\n",
    "\n",
    "print(\"KNN vs. SVM\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"dowTask\"></a>\n",
    "#### Task 2: day_of_week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantileTransformer transformed accuracy scores\n",
    "print(rf_model_scores_q2)\n",
    "print(knn_model_scores_q2)\n",
    "print(svm_model_scores_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model accuracy scores\n",
    "model1_scores = rf_model_scores_q2\n",
    "model2_scores = knn_model_scores_q2\n",
    "model3_scores = svm_model_scores_q2\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value1 = ttest_rel(model1_scores, model2_scores)\n",
    "\n",
    "print(\"Random Forest vs. KNN\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value1 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value2 = ttest_rel(model1_scores, model3_scores)\n",
    "\n",
    "print(\"Random Forest vs. SVM\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value3 = ttest_rel(model2_scores, model3_scores)\n",
    "\n",
    "print(\"KNN vs. SVM\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"ModelEval6\"></a>\n",
    "# Modeling and Evaluation 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which attributes from your analysis are most important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use proper methods discussed in class to evaluate the importance of different attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISCUSS RESULTS FROM FEATURE SELECTION LISTED ATTRIBUTES AT THE BEGINNGING OF THE CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"Deployment\"></a>\n",
    "# Deployment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? \n",
    "### With the ability to predict the popularity of online news articles, Mashable may choose to feature these articles on their platforms. These featured news articles can then generate revenue by allowing sponsors to advertise within them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: How would you measure the model's value if it was used by these parties?\n",
    "\n",
    "### Mashable can monitor sponsor inquiries for advertising within their news articles. An increase in sponsor interest would indicate the value placed on the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ???? Q: How would your deploy your model for interested parties?\n",
    "\n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q: What other data should be collected?\n",
    "### It would be useful to have information about the number of comments associated with a news article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q: How often would the model need to be updated, etc.?\n",
    "\n",
    "### It may be necessary to update the model quarterly because current events and life factors covered in the news are constantly changing. A stagnant model might not accurately predict the popularity of a news article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"Exceptional\"></a>\n",
    "# Exceptional Work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional modeling Using an 80/20 Test Split (rather than a stratified kfold train/test split) applying only StandardScalar Transformed data on Random Forest model for each task (share_quantile_ranges & day_of_week & news_category):\n",
    "The StandardScalar transformed data was taken down the same path as the QuantileTransformer transformed data. There was a seperate running of each task; one using each scale transformer. This was done in order to compare the two and determine which, if either, is better than the other.\n",
    "\n",
    "An additional task was performed using the three models. The 'news_category' task is focused on determining category of news that the article falls under. The SVM model did not take to this task very well. The SVM model runtime is much too long for it to be useful, especially compared to the runtime of the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### StandardScalar Transformed on Random Forest model for each task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1: share_quantile_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the share_quantile_ranges model\n",
    "rf.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set for share_quantile_ranges task\n",
    "rf_y_pred1 = rf.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the share_quantile_ranges task.\n",
    "rf_accuracy1 = accuracy_score(y_test1, rf_y_pred1)\n",
    "rf_precision1 = precision_score(y_test1, rf_y_pred1, average='macro')\n",
    "rf_recall1 = recall_score(y_test1, rf_y_pred1, average='macro')\n",
    "rf_f1_score1 = f1_score(y_test1, rf_y_pred1, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics\n",
    "rf_model_scores1 = np.array([rf_accuracy1, rf_precision1, rf_recall1, rf_f1_score1])\n",
    "\n",
    "# Print the model evaluation metrics\n",
    "print('Random Forest on share_quantile_ranges Task')\n",
    "print(rf_model_scores1)\n",
    "print('---------------------------------------------------------')\n",
    "print('Random Forest accuracy:', rf_accuracy1)\n",
    "print('Random Forest precision:', rf_precision1)\n",
    "print('Random Forest recall:', rf_recall1)\n",
    "print('Random Forest F1 score:', rf_f1_score1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2: day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the day_of_week task\n",
    "rf.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set for day_of_week task\n",
    "rf_y_pred2 = rf.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for day_of_week task.\n",
    "rf_accuracy2 = accuracy_score(y_test2, rf_y_pred2)\n",
    "rf_precision2 = precision_score(y_test2, rf_y_pred2, average='macro')\n",
    "rf_recall2 = recall_score(y_test2, rf_y_pred2, average='macro')\n",
    "rf_f1_score2 = f1_score(y_test2, rf_y_pred2, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics\n",
    "rf_model_scores2 = np.array([rf_accuracy2, rf_precision2, rf_recall2, rf_f1_score2])\n",
    "\n",
    "# Print the model evaluation metrics\n",
    "print('Random Forest on day_of_week Task')\n",
    "print(rf_model_scores2)\n",
    "print('---------------------------------------------------------')\n",
    "print('Random Forest accuracy:', rf_accuracy2)\n",
    "print('Random Forest precision:', rf_precision2)\n",
    "print('Random Forest recall:', rf_recall2)\n",
    "print('Random Forest F1 score:', rf_f1_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Task 3: news_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the news_category task\n",
    "rf.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set for news_category task\n",
    "rf_y_pred3 = rf.predict(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for news_category task.\n",
    "rf_accuracy3 = accuracy_score(y_test3, rf_y_pred3)\n",
    "rf_precision3 = precision_score(y_test3, rf_y_pred3, average='macro')\n",
    "rf_recall3 = recall_score(y_test3, rf_y_pred3, average='macro')\n",
    "rf_f1_score3 = f1_score(y_test3, rf_y_pred3, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics\n",
    "rf_model_scores3 = np.array([rf_accuracy3, rf_precision3, rf_recall3, rf_f1_score3])\n",
    "\n",
    "# Print the model evaluation metrics\n",
    "print('Random Forest on news_category Task')\n",
    "print(rf_model_scores3)\n",
    "print('---------------------------------------------------------')\n",
    "print('Random Forest accuracy:', rf_accuracy3)\n",
    "print('Random Forest precision:', rf_precision3)\n",
    "print('Random Forest recall:', rf_recall3)\n",
    "print('Random Forest F1 score:', rf_f1_score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "##### StandardScalar Transformed on KNN model for each task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1: share_quantile_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for the share_quantile_ranges task.\n",
    "knn.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set for the share_quantile_ranges task.\n",
    "knn_y_pred1 = knn.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the share_quantile_ranges task.\n",
    "knn_accuracy1 = accuracy_score(y_test1, knn_y_pred1)\n",
    "knn_precision1 = precision_score(y_test1, knn_y_pred1, average='macro')\n",
    "knn_recall1 = recall_score(y_test1, knn_y_pred1, average='macro')\n",
    "knn_f1_score1 = f1_score(y_test1, knn_y_pred1, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics for the share_quantile_ranges task.\n",
    "knn_model_scores1 = np.array([knn_accuracy1, knn_precision1, knn_recall1, knn_f1_score1])\n",
    "print('KNN on share_quantile_ranges Task')\n",
    "print(knn_model_scores1)\n",
    "print('---------------------------------------------------------')\n",
    "print('KNN accuracy:', knn_accuracy1)\n",
    "print('KNN precision:', knn_precision1)\n",
    "print('KNN recall:', knn_recall1)\n",
    "print('KNN F1 score:', knn_f1_score1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2: day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for the day_of_week task.\n",
    "knn.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set for the day_of_week task.\n",
    "knn_y_pred2 = knn.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the day_of_week task.\n",
    "knn_accuracy2 = accuracy_score(y_test2, knn_y_pred2)\n",
    "knn_precision2 = precision_score(y_test2, knn_y_pred2, average='macro')\n",
    "knn_recall2 = recall_score(y_test2, knn_y_pred2, average='macro')\n",
    "knn_f1_score2 = f1_score(y_test2, knn_y_pred2, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics the day_of_week task.\n",
    "knn_model_scores2 = np.array([knn_accuracy2, knn_precision2, knn_recall2, knn_f1_score2])\n",
    "print('KNN on day_of_week Task')\n",
    "print(knn_model_scores2)\n",
    "print('---------------------------------------------------------')\n",
    "print('KNN accuracy:', knn_accuracy2)\n",
    "print('KNN precision:', knn_precision2)\n",
    "print('KNN recall:', knn_recall2)\n",
    "print('KNN F1 score:', knn_f1_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Task 3: news_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for the news_category task.\n",
    "knn.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set for the news_category task.\n",
    "knn_y_pred3 = knn.predict(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the news_category task.\n",
    "knn_accuracy3 = accuracy_score(y_test3, knn_y_pred3)\n",
    "knn_precision3 = precision_score(y_test3, knn_y_pred3, average='macro')\n",
    "knn_recall3 = recall_score(y_test3, knn_y_pred3, average='macro')\n",
    "knn_f1_score3 = f1_score(y_test3, knn_y_pred3, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics for the news_category task.\n",
    "knn_model_scores3 = np.array([knn_accuracy3, knn_precision3, knn_recall3, knn_f1_score3])\n",
    "print('KNN on news_category Task')\n",
    "print(knn_model_scores3)\n",
    "print('---------------------------------------------------------')\n",
    "print('KNN accuracy:', knn_accuracy3)\n",
    "print('KNN precision:', knn_precision3)\n",
    "print('KNN recall:', knn_recall3)\n",
    "print('KNN F1 score:', knn_f1_score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "##### StandardScalar Transformed on SVM model for each task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1: share_quantile_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the support vector machine model on the training set using a linear kernel for the share_quantile_ranges task.\n",
    "support_vector_machine_model.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data for the share_quantile_ranges task.\n",
    "svm_y_pred1 = support_vector_machine_model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the share_quantile_ranges task.\n",
    "svm_accuracy1 = accuracy_score(y_test1, svm_y_pred1)\n",
    "svm_precision1 = precision_score(y_test1, svm_y_pred1, average='macro')\n",
    "svm_recall1 = recall_score(y_test1, svm_y_pred1, average='macro')\n",
    "svm_f1_score1 = f1_score(y_test1, svm_y_pred1, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics for the share_quantile_ranges task.\n",
    "svm_model_scores1 = np.array([svm_accuracy1, svm_precision1, svm_recall1, svm_f1_score1])\n",
    "print('SVM on share_quantile_range Task')\n",
    "print(svm_model_scores1)\n",
    "print('---------------------------------------------------------')\n",
    "print('Support vector machine accuracy:', svm_accuracy1)\n",
    "print('Support vector machine precision:', svm_precision1)\n",
    "print('Support vector machine recall:', svm_recall1)\n",
    "print('Support vector machine F1 score:', svm_f1_score1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2: day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the support vector machine model on the training set using a linear kernel for the day_of_week task.\n",
    "support_vector_machine_model.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data for the day_of_week task.\n",
    "svm_y_pred2 = support_vector_machine_model.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the day_of_week task.\n",
    "svm_accuracy2 = accuracy_score(y_test2, svm_y_pred2)\n",
    "svm_precision2 = precision_score(y_test2, svm_y_pred2, average='macro')\n",
    "svm_recall2 = recall_score(y_test2, svm_y_pred2, average='macro')\n",
    "svm_f1_score2 = f1_score(y_test2, svm_y_pred2, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics for the day_of_week task\n",
    "svm_model_scores2 = np.array([svm_accuracy2, svm_precision2, svm_recall2, svm_f1_score2])\n",
    "print('SVM on day_of_week Task')\n",
    "print(svm_model_scores2)\n",
    "print('---------------------------------------------------------')\n",
    "print('Support vector machine accuracy:', svm_accuracy2)\n",
    "print('Support vector machine precision:', svm_precision2)\n",
    "print('Support vector machine recall:', svm_recall2)\n",
    "print('Support vector machine F1 score:', svm_f1_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Task 3: news_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: The SVM model with the target task news_category was too computationally expensive to run in a reasonable time, however the code below is functional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the support vector machine model on the training set using a linear kernel for the news_category task.\n",
    "# support_vector_machine_model.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data for the news_category task.\n",
    "# svm_y_pred3 = support_vector_machine_model.predict(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the news_category task.\n",
    "# svm_accuracy3 = accuracy_score(y_test3, svm_y_pred3)\n",
    "# svm_precision3 = precision_score(y_test3, svm_y_pred3, average='macro')\n",
    "# svm_recall3 = recall_score(y_test3, svm_y_pred3, average='macro')\n",
    "# svm_f1_score3 = f1_score(y_test3, svm_y_pred3, average='macro')\n",
    "\n",
    "# # Create an array to store the model evaluation metrics for the news_category task\n",
    "# svm_model_scores3 = np.array([svm_accuracy3, svm_precision3, svm_recall3, svm_f1_score3])\n",
    "# print('SVM on news_category Task')\n",
    "# print(svm_model_scores3)\n",
    "# print('---------------------------------------------------------')\n",
    "# print('Support vector machine accuracy:', svm_accuracy3)\n",
    "# print('Support vector machine precision:', svm_precision3)\n",
    "# print('Support vector machine recall:', svm_recall3)\n",
    "# print('Support vector machine F1 score:', svm_f1_score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"#ncTask\"></a>\n",
    "##### QuantileTransformer transformed for each model on 'news_category' task "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the news_category task\n",
    "rf.fit(X_train_q3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set for news_category task\n",
    "rf_y_pred_q3 = rf.predict(X_test_q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for news_category task.\n",
    "rf_accuracy_q3 = accuracy_score(y_test3, rf_y_pred_q3)\n",
    "rf_precision_q3 = precision_score(y_test3, rf_y_pred_q3, average='macro')\n",
    "rf_recall_q3 = recall_score(y_test3, rf_y_pred_q3, average='macro')\n",
    "rf_f1_score_q3 = f1_score(y_test3, rf_y_pred_q3, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics\n",
    "rf_model_scores_q3 = np.array([rf_accuracy_q3, rf_precision_q3, rf_recall_q3, rf_f1_score_q3])\n",
    "\n",
    "# Print the model evaluation metrics\n",
    "print('Random Forest on news_category Task')\n",
    "print(rf_model_scores_q3)\n",
    "print('---------------------------------------------------------')\n",
    "print('Random Forest accuracy:', rf_accuracy_q3)\n",
    "print('Random Forest precision:', rf_precision_q3)\n",
    "print('Random Forest recall:', rf_recall_q3)\n",
    "print('Random Forest F1 score:', rf_f1_score_q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for the news_category task.\n",
    "knn.fit(X_train_q3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set for the news_category task.\n",
    "knn_y_pred_q3 = knn.predict(X_test_q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the news_category task.\n",
    "knn_accuracy_q3 = accuracy_score(y_test3, knn_y_pred_q3)\n",
    "knn_precision_q3 = precision_score(y_test3, knn_y_pred_q3, average='macro')\n",
    "knn_recall_q3 = recall_score(y_test3, knn_y_pred_q3, average='macro')\n",
    "knn_f1_score_q3 = f1_score(y_test3, knn_y_pred_q3, average='macro')\n",
    "\n",
    "# Create an array to store the model evaluation metrics for the news_category task.\n",
    "knn_model_scores_q3 = np.array([knn_accuracy_q3, knn_precision_q3, knn_recall_q3, knn_f1_score_q3])\n",
    "print('KNN on news_category Task')\n",
    "print(knn_model_scores_q3)\n",
    "print('---------------------------------------------------------')\n",
    "print('KNN accuracy:', knn_accuracy_q3)\n",
    "print('KNN precision:', knn_precision_q3)\n",
    "print('KNN recall:', knn_recall_q3)\n",
    "print('KNN F1 score:', knn_f1_score_q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM\n",
    "This model did not run in a timely manner and was dropped. As mentioned before the SVM models for the news_category tasks took markedly longer than their counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the support vector machine model on the training set using a linear kernel for the news_category task.\n",
    "# support_vector_machine_model.fit(X_train_q3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions on the test data for the news_category task.\n",
    "# svm_y_pred_q3 = support_vector_machine_model.predict(X_test_q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the accuracy, precision, recall, and F1 score of the model on the test data for the news_category task.\n",
    "# svm_accuracy_q3 = accuracy_score(y_test3, svm_y_pred_q3)\n",
    "# svm_precision_q3 = precision_score(y_test3, svm_y_pred_q3, average='macro')\n",
    "# svm_recall_q3 = recall_score(y_test3, svm_y_pred_q3, average='macro')\n",
    "# svm_f1_score_q3 = f1_score(y_test3, svm_y_pred_q3, average='macro')\n",
    "\n",
    "# # Create an array to store the model evaluation metrics for the news_category task\n",
    "# svm_model_scores_q3 = np.array([svm_accuracy_q3, svm_precision_q3, svm_recall_q3, svm_f1_score_q3])\n",
    "# print('SVM on news_category Task')\n",
    "# print(svm_model_scores_q3)\n",
    "# print('---------------------------------------------------------')\n",
    "# print('Support vector machine accuracy:', svm_accuracy_q3)\n",
    "# print('Support vector machine precision:', svm_precision_q3)\n",
    "# print('Support vector machine recall:', svm_recall_q3)\n",
    "# print('Support vector machine F1 score:', svm_f1_score_q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "## Comparing the StandardScalar transformed models' performance on each task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: share_quantile_ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScalar transformed accuracy scores\n",
    "print(rf_model_scores1)\n",
    "print(knn_model_scores1)\n",
    "print(svm_model_scores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model accuracy scores\n",
    "model1_scores = rf_model_scores1\n",
    "model2_scores = knn_model_scores1\n",
    "model3_scores = svm_model_scores1\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value1 = ttest_rel(model1_scores, model2_scores)\n",
    "\n",
    "print(\"Random Forest vs. KNN\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value1 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value2 = ttest_rel(model1_scores, model3_scores)\n",
    "\n",
    "print(\"Random Forest vs. SVM\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value3 = ttest_rel(model2_scores, model3_scores)\n",
    "\n",
    "print(\"KNN vs. SVM\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScalar transformed accuracy scores\n",
    "print(rf_model_scores2)\n",
    "print(knn_model_scores2)\n",
    "print(svm_model_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model accuracy scores\n",
    "model1_scores = rf_model_scores2\n",
    "model2_scores = knn_model_scores2\n",
    "model3_scores = svm_model_scores2\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value1 = ttest_rel(model1_scores, model2_scores)\n",
    "\n",
    "print(\"Random Forest vs. KNN\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value1 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value2 = ttest_rel(model1_scores, model3_scores)\n",
    "\n",
    "print(\"Random Forest vs. SVM\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value3 = ttest_rel(model2_scores, model3_scores)\n",
    "\n",
    "print(\"KNN vs. SVM\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: news_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScalar transformed accuracy scores\n",
    "print(rf_model_scores3)\n",
    "print(knn_model_scores3)\n",
    "# print(svm_model_scores_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model accuracy scores\n",
    "model1_scores = rf_model_scores3\n",
    "model2_scores = knn_model_scores3\n",
    "# model3_scores = svm_model_scores3\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value1 = ttest_rel(model1_scores, model2_scores)\n",
    "\n",
    "print(\"Random Forest vs. KNN\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value1 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# # Perform a paired t-test\n",
    "# t_statistic, p_value2 = ttest_rel(model1_scores, model3_scores)\n",
    "\n",
    "# print(\"Random Forest vs. SVM\")\n",
    "# # Check if the difference is significant with 95% confidence\n",
    "# if p_value2 < 0.05:\n",
    "#   print(\"The difference between the two models is statistically significant.\")\n",
    "# else:\n",
    "#   print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "# print('---------------------------------------------------------')\n",
    "\n",
    "# # Perform a paired t-test\n",
    "# t_statistic, p_value3 = ttest_rel(model2_scores, model3_scores)\n",
    "\n",
    "# print(\"KNN vs. SVM\")\n",
    "# # Check if the difference is significant with 95% confidence\n",
    "# if p_value2 < 0.05:\n",
    "#   print(\"The difference between the two models is statistically significant.\")\n",
    "# else:\n",
    "#   print(\"The difference between the two models is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "## Comparing the removed news_category task QuantileTransformer Transformed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantileTransformer transformed accuracy scores\n",
    "print(rf_model_scores_q3) # share_quantile_ranges task\n",
    "print(knn_model_scores_q3) # day_of_week task\n",
    "# print(svm_model_scores_q3) # news_category task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model accuracy scores\n",
    "model1_scores = rf_model_scores_q3\n",
    "model2_scores = knn_model_scores_q3\n",
    "# model3_scores = svm_model_scores_q3\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value1 = ttest_rel(model1_scores, model2_scores)\n",
    "\n",
    "print(\"Random Forest vs. KNN\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value1 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# # Perform a paired t-test\n",
    "# t_statistic, p_value2 = ttest_rel(model1_scores, model3_scores)\n",
    "\n",
    "# print(\"Random Forest vs. SVM\")\n",
    "# # Check if the difference is significant with 95% confidence\n",
    "# if p_value2 < 0.05:\n",
    "#   print(\"The difference between the two models is statistically significant.\")\n",
    "# else:\n",
    "#   print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "# print('---------------------------------------------------------')\n",
    "\n",
    "# # Perform a paired t-test\n",
    "# t_statistic, p_value3 = ttest_rel(model2_scores, model3_scores)\n",
    "\n",
    "# print(\"KNN vs. SVM\")\n",
    "# # Check if the difference is significant with 95% confidence\n",
    "# if p_value2 < 0.05:\n",
    "#   print(\"The difference between the two models is statistically significant.\")\n",
    "# else:\n",
    "#   print(\"The difference between the two models is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    " ## Comparing the two scaling methods in Modeling and Evaluation 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"ScalerEval\"></a>\n",
    "## The following section of code evaluates whether there is a statistically significant difference between transformation types StandardScalar & QuantileTransformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"RFEval\"></a>\n",
    "### Random Forest Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScalar transformed accuracy scores\n",
    "print(rf_model_scores1) # share_quantile_ranges task\n",
    "print(rf_model_scores2) # day_of_week task\n",
    "print(rf_model_scores3) # news_category task\n",
    "\n",
    "# QuantileTransformer transformed accuracy scores\n",
    "print(rf_model_scores_q1) # share_quantile_ranges task\n",
    "print(rf_model_scores_q2) # day_of_week task\n",
    "print(rf_model_scores_q3) # news_category task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model accuracy scores for StandardScalar transformed\n",
    "model1_scores = rf_model_scores1\n",
    "model2_scores = rf_model_scores2\n",
    "model3_scores = rf_model_scores3\n",
    "\n",
    "# Load the model accuracy scores for QuantileTransformer transformed\n",
    "model4_scores = rf_model_scores_q1\n",
    "model5_scores = rf_model_scores_q2\n",
    "model6_scores = rf_model_scores_q3\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value1 = ttest_rel(model1_scores, model4_scores)\n",
    "print(\"Random Forest Models\")\n",
    "print(\"StandardScalar vs. QuantileTransformation on share_quantile_ranges task\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value1 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value2 = ttest_rel(model2_scores, model5_scores)\n",
    "\n",
    "print(\"StandardScalar vs. QuantileTransformation on day_of_week task\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value3 = ttest_rel(model3_scores, model6_scores)\n",
    "\n",
    "print(\"StandardScalar vs. QuantileTransformation on news_category task\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"KNNEval\"></a>\n",
    "\n",
    "### KNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScalar transformed accuracy scores\n",
    "print(knn_model_scores1) # share_quantile_ranges task\n",
    "print(knn_model_scores2) # day_of_week task\n",
    "print(knn_model_scores3) # news_category task\n",
    "\n",
    "# QuantileTransformer transformed accuracy scores\n",
    "print(knn_model_scores_q1) # share_quantile_ranges task\n",
    "print(knn_model_scores_q2) # day_of_week task\n",
    "print(knn_model_scores_q3) # news_category task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model accuracy scores for StandardScalar transformed\n",
    "model1_scores = knn_model_scores1\n",
    "model2_scores = knn_model_scores2\n",
    "model3_scores = knn_model_scores3\n",
    "\n",
    "# Load the model accuracy scores for QuantileTransformer transformed\n",
    "model4_scores = knn_model_scores_q1\n",
    "model5_scores = knn_model_scores_q2\n",
    "model6_scores = knn_model_scores_q3\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value1 = ttest_rel(model1_scores, model4_scores)\n",
    "print(\"Random Forest Models\")\n",
    "print(\"StandardScalar vs. QuantileTransformation on share_quantile_ranges task\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value1 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value2 = ttest_rel(model2_scores, model5_scores)\n",
    "\n",
    "print(\"StandardScalar vs. QuantileTransformation on day_of_week task\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value3 = ttest_rel(model3_scores, model6_scores)\n",
    "\n",
    "print(\"StandardScalar vs. QuantileTransformation on news_category task\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"SVMEval\"></a>\n",
    "\n",
    "### SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScalar transformed accuracy scores\n",
    "print(svm_model_scores1) # share_quantile_ranges task\n",
    "print(svm_model_scores2) # day_of_week task\n",
    "# print(svm_model_scores1) # news_category task\n",
    "\n",
    "# QuantileTransformer transformed accuracy scores\n",
    "print(svm_model_scores_q1) # share_quantile_ranges task\n",
    "print(svm_model_scores_q2) # day_of_week task\n",
    "# print(svm_model_scores_q3) # news_category task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model accuracy scores for StandardScalar transformed\n",
    "model1_scores = svm_model_scores1\n",
    "model2_scores = svm_model_scores2\n",
    "# model3_scores = svm_model_scores3\n",
    "\n",
    "# Load the model accuracy scores for QuantileTransformer transformed\n",
    "model4_scores = svm_model_scores_q1\n",
    "model5_scores = svm_model_scores_q2\n",
    "# model6_scores = svm_model_scores_q3\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value1 = ttest_rel(model1_scores, model4_scores)\n",
    "print(\"Random Forest Models\")\n",
    "print(\"StandardScalar vs. QuantileTransformation on share_quantile_ranges task\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value1 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Perform a paired t-test\n",
    "t_statistic, p_value2 = ttest_rel(model2_scores, model5_scores)\n",
    "\n",
    "print(\"StandardScalar vs. QuantileTransformation on day_of_week task\")\n",
    "# Check if the difference is significant with 95% confidence\n",
    "if p_value2 < 0.05:\n",
    "  print(\"The difference between the two models is statistically significant.\")\n",
    "else:\n",
    "  print(\"The difference between the two models is not statistically significant.\")\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# # Perform a paired t-test\n",
    "# t_statistic, p_value3 = ttest_rel(model3_scores, model6_scores)\n",
    "\n",
    "# print(\"StandardScalar vs. QuantileTransformation on news_category task\")\n",
    "# # Check if the difference is significant with 95% confidence\n",
    "# if p_value2 < 0.05:\n",
    "#   print(\"The difference between the two models is statistically significant.\")\n",
    "# else:\n",
    "#   print(\"The difference between the two models is not statistically significant.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
